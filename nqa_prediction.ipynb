{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NQ&A Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NQA Utils Loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "from scripts import nqa_utils\n",
    "from scripts.nqa_utils import Answer, AnswerType\n",
    "from scripts import bert_modeling as modeling\n",
    "from scripts import bert_tokenization\n",
    "from scripts import albert\n",
    "from scripts import albert_tokenization\n",
    "from scripts.models import build_model\n",
    "\n",
    "import collections\n",
    "from collections import OrderedDict, namedtuple\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "import absl\n",
    "import sys\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()\n",
    "    keys_list = [keys for keys in flags_dict]\n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(absl.flags.FLAGS)\n",
    "\n",
    "flags = absl.flags\n",
    "\n",
    "### Main Model Flags ###\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"model\", \"bert\",\n",
    "    \"The name of model to use. Choose from ['bert', 'albert'].\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"config_file\", \"models/bert_joint_baseline/bert_config.json\",\n",
    "    \"The config json file corresponding to the pre-trained BERT/ALBERT model. \"\n",
    "    \"This specifies the model architecture.\")\n",
    "\n",
    "flags.DEFINE_string(\"vocab_file\", \"models/bert_joint_baseline/vocab-nq.txt\",\n",
    "                    \"The vocabulary file that the ALBERT/BERT model was trained on.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"init_checkpoint\", \"models/bert_joint_baseline/tf2_bert_joint.ckpt\",\n",
    "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_seq_length\", 384,\n",
    "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
    "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
    "    \"than this will be padded.\")\n",
    "\n",
    "flags.DEFINE_integer(\"predict_batch_size\", 1,\n",
    "                     \"Total batch size for predictions.\")\n",
    "\n",
    "### Second Model Flags ###\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"second_model\", \"albert\",\n",
    "    \"The name of model to use. Choose from ['albert', 'bert'].\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"second_config_file\", \"models/albert_xxl/config.json\",\n",
    "    \"The config json file corresponding to the pre-trained BERT/ALBERT model. \"\n",
    "    \"This specifies the model architecture.\")\n",
    "\n",
    "flags.DEFINE_string(\"second_vocab_file\", \"models/albert_xxl/vocab/modified-30k-clean.model\",\n",
    "                    \"The vocabulary file that the ALBERT/BERT model was trained on.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"second_init_checkpoint\", \"models/albert_xxl/albert_finetuned.h5\",\n",
    "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"second_max_seq_length\", 384,\n",
    "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
    "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
    "    \"than this will be padded.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"second_batch_size\", 1,\n",
    "    \"Batch size when running verifier predictions.\")\n",
    "\n",
    "### Other Flags ###\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"output_dir\", \"output/\",\n",
    "    \"The output directory where the model checkpoints will be written.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"train_file\", \"data/simplified-nq-dev.jsonl\",\n",
    "    \"NQ json for predictions. E.g., dev-v1.1.jsonl.gz or test-v1.1.jsonl.gz\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"log_dir\", \"logs/\",\n",
    "    \"Where logs, specifically Tensorboard logs, will be saved to.\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"do_lower_case\", True,\n",
    "    \"Whether to lower case the input text. Should be True for uncased \"\n",
    "    \"models and False for cased models.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"doc_stride\", 128,\n",
    "    \"When splitting up a long document into chunks, how much stride to \"\n",
    "    \"take between chunks.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_query_length\", 64,\n",
    "    \"The maximum number of tokens for the question. Questions longer than \"\n",
    "    \"this will be truncated to this length.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_train\", False, \"Whether to run training.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_predict\", True, \"Whether to run eval on the dev set.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_answer_length\", 30,\n",
    "    \"The maximum length of an answer that can be generated. This is needed \"\n",
    "    \"because the start and end predictions are not conditioned on one another.\")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"include_unknowns\", 1.0,\n",
    "    \"If positive, probability of including answers of type `UNKNOWN`.\")\n",
    "\n",
    "absl.flags.DEFINE_string(\n",
    "    \"gcp_project\", None,\n",
    "    \"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n",
    "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
    "    \"metadata.\")\n",
    "\n",
    "# TODO(Edan): Look at nested contents too at some point\n",
    "# Around 5% of long answers are nested, and around 50% of questions have\n",
    "# long answers\n",
    "# This means that this setting alone restricts us from a correct answer\n",
    "# around 2.5% of the time\n",
    "flags.DEFINE_boolean(\n",
    "    \"skip_nested_contexts\", True,\n",
    "    \"Completely ignore context that are not top level nodes in the page.\")\n",
    "\n",
    "flags.DEFINE_integer(\"max_contexts\", 48,\n",
    "                     \"Maximum number of contexts to output for an example.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_position\", 50,\n",
    "    \"Maximum context position for which to generate special tokens.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"n_examples\", 200,\n",
    "    \"Number of examples to read from files.\")\n",
    "\n",
    "flags.DEFINE_boolean(\n",
    "    \"test_post_processing\", True,\n",
    "    \"If true, training data will be predicted for instead of eval data,\"\n",
    "    \"and the predictions will be used to tune the post processing algorithm.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"tokens_per_small_example\", 105*10, # On average about 10 features\n",
    "    \"The amount of tokens allowed on average for an example to be considered \"\n",
    "    \"small. Small examples are run directly through ALBERT-xxl.\")\n",
    "\n",
    "### Currently Not In Use ###\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_features_per_small_example\", 15,\n",
    "    \"The amount of features allowed for a small example before being truncated.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_features_per_example\", 65,\n",
    "    \"The amount of features allowed for an example before being truncated.\")\n",
    "\n",
    "## Special flags - do not change\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"predict_file\", \"/kaggle/input/tensorflow2-question-answering/simplified-nq-test.jsonl\",\n",
    "    \"NQ json for predictions. E.g., dev-v1.1.jsonl.gz or test-v1.1.jsonl.gz\")\n",
    "flags.DEFINE_boolean(\"logtostderr\", True, \"Logs to stderr\")\n",
    "flags.DEFINE_boolean(\"undefok\", True, \"it's okay to be undefined\")\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_string('HistoryManager.hist_file', '', 'kernel')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS(sys.argv) # Parse the flags\n",
    "\n",
    "N_TRAIN_EXAMPLES = 307373"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(scores):\n",
    "    print('Total Score', '\\n', scores[0], '\\n')\n",
    "    print('Long Answer Score', '\\n', scores[1], '\\n')\n",
    "    print('Short Answer Score', '\\n', scores[2], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict File: data/simplified-nq-dev.jsonl\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.test_post_processing:\n",
    "    input_file = FLAGS.train_file\n",
    "    actual_answers = nqa_utils.get_actual_answers(input_file, FLAGS.n_examples)\n",
    "else:\n",
    "    input_file = FLAGS.predict_file\n",
    "    \n",
    "candidates_dict = nqa_utils.read_candidates(input_file, n=FLAGS.n_examples)\n",
    "\n",
    "print(\"Predict File:\", input_file)\n",
    "\n",
    "eval_examples = nqa_utils.read_nq_examples(\n",
    "      input_file=input_file, is_training=FLAGS.test_post_processing, n=FLAGS.n_examples)\n",
    "\n",
    "id_to_example = {}\n",
    "for example in eval_examples:\n",
    "    id_to_example[example.example_id] = example\n",
    "\n",
    "raw_examples = next(nqa_utils.raw_data_generator(input_file, FLAGS.n_examples))\n",
    "raw_examples = [dict(row) for _, row in raw_examples.iterrows()]\n",
    "\n",
    "final_answers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Part 1: ALBERT Small Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Small Examples: 72\n",
      "# Features: 681\n"
     ]
    }
   ],
   "source": [
    "### Get the Small Examples ###\n",
    "\n",
    "small_examples = []\n",
    "remaining_examples = []\n",
    "\n",
    "n_total_tokens = 0\n",
    "n_total_examples = 0\n",
    "sorted_examples = sorted(eval_examples, key=lambda x: len(x.doc_tokens))\n",
    "for example in sorted_examples:\n",
    "    n_tokens = len(example.doc_tokens)\n",
    "    n_total_tokens += n_tokens\n",
    "    n_total_examples += 1\n",
    "    \n",
    "    if n_total_examples and n_total_tokens and \\\n",
    "        n_total_tokens / n_total_examples >= FLAGS.tokens_per_small_example:\n",
    "        break\n",
    "        \n",
    "small_examples = sorted_examples[:n_total_examples]\n",
    "remaining_examples = sorted_examples[n_total_examples:]\n",
    "# small_examples = eval_examples\n",
    "\n",
    "if FLAGS.second_model == 'bert':\n",
    "    tokenizer_small = bert_tokenization.FullTokenizer(\n",
    "        vocab_file=FLAGS.second_vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
    "    lowercase = False\n",
    "elif FLAGS.second_model == 'albert':\n",
    "    tokenizer_small = albert_tokenization.FullTokenizer(\n",
    "        None, spm_model_file=FLAGS.second_vocab_file)\n",
    "    lowercase = True\n",
    "\n",
    "def append_feature_small(feature):\n",
    "    eval_features_small.append(feature)\n",
    "    eval_writer_small.process_feature(feature)\n",
    "\n",
    "eval_writer_small = nqa_utils.FeatureWriter(\n",
    "  filename=os.path.join(FLAGS.output_dir, \"eval_small.tf_record\"),\n",
    "  is_training=FLAGS.test_post_processing)\n",
    "eval_features_small = []\n",
    "\n",
    "nqa_utils.convert_examples_to_features(\n",
    "  examples=small_examples,\n",
    "  tokenizer=tokenizer_small,\n",
    "  is_training=FLAGS.test_post_processing,\n",
    "  output_fn=append_feature_small,\n",
    "  lowercase=lowercase)\n",
    "\n",
    "eval_writer_small.close()\n",
    "eval_filename_small = eval_writer_small.filename\n",
    "\n",
    "print('# Small Examples:', len(small_examples))\n",
    "print('# Features:', len(eval_features_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model and Run Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"albert\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "albert_model (AlbertModel)      ((None, 4096), (None 222622336   input_ids[0][0]                  \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "td_seq (TDense)                 (None, 384, 2)       8194        albert_model[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split (TensorFlowOp [(None, 384, 1), (No 0           td_seq[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_start_logits (Tenso [(None, 384)]        0           tf_op_layer_split[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_end_logits (TensorF [(None, 384)]        0           tf_op_layer_split[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "ans_type_logits (TDense)        (None, 5)            20485       albert_model[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 222,651,015\n",
      "Trainable params: 222,651,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model(model_name=FLAGS.second_model,\n",
    "                    config_file=FLAGS.second_config_file,\n",
    "                    max_seq_length=FLAGS.second_max_seq_length,\n",
    "                    init_ckpt=FLAGS.second_init_checkpoint)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = np.ceil(eval_writer_small.num_features / FLAGS.second_batch_size)\n",
    "generator = nqa_utils.data_generator(eval_filename_small, FLAGS.second_batch_size)\n",
    "\n",
    "preds_small = model.predict(generator, steps=n_steps)\n",
    "final_answers.update(preds_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NQA Utils Loaded!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'scripts.nqa_utils' from '/home/ejmejm/MLProjects/kaggle-nqa/scripts/nqa_utils.py'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(nqa_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Score \n",
      " F1 = 0.702 | Recall = 0.678 | Precision = 0.727 | TP = 40 | FP = 19 | FN = 15 | TN = 70 \n",
      "\n",
      "Long Answer Score \n",
      " F1 = 0.708 | Recall = 0.697 | Precision = 0.719 | TP = 23 | FP = 10 | FN = 9 | TN = 30 \n",
      "\n",
      "Short Answer Score \n",
      " F1 = 0.694 | Recall = 0.654 | Precision = 0.739 | TP = 17 | FP = 9 | FN = 6 | TN = 40 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    'ans_type_conf_weight': 0.1,\n",
    "    'start_pos_conf_weight': 0.45,\n",
    "    'end_pos_conf_weight': 0.45,\n",
    "    'conf_bias': 0.0,\n",
    "    'conf_threshold': 0.94\n",
    "}\n",
    "\n",
    "answers_small = nqa_utils.compute_answers(preds_small, candidates_dict,\\\n",
    "                                          eval_features_small, small_examples,\n",
    "                                          id_to_example, weights)\n",
    "final_answers.update(answers_small)\n",
    "\n",
    "if FLAGS.test_post_processing:\n",
    "    print_scores(nqa_utils.score_preds(raw_examples, answers_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Part 2: BERT-Joint Remaining Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Remaning Examples: 128\n",
      "# Features: 4734\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.model == 'bert':\n",
    "    tokenizer = bert_tokenization.FullTokenizer(\n",
    "        vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
    "elif FLAGS.model == 'albert':\n",
    "    tokenizer = albert_tokenization.FullTokenizer(\n",
    "        None, spm_model_file=FLAGS.vocab_file)\n",
    "\n",
    "eval_writer = nqa_utils.FeatureWriter(\n",
    "  filename=os.path.join(FLAGS.output_dir, \"eval_remaining.tf_record\"),\n",
    "  is_training=FLAGS.test_post_processing)\n",
    "eval_features = []\n",
    "\n",
    "def append_feature(feature):\n",
    "    eval_features.append(feature)\n",
    "    eval_writer.process_feature(feature)\n",
    "\n",
    "nqa_utils.convert_examples_to_features(\n",
    "  examples=remaining_examples,\n",
    "  tokenizer=tokenizer,\n",
    "  is_training=FLAGS.test_post_processing,\n",
    "  output_fn=append_feature)\n",
    "eval_writer.close()\n",
    "eval_filename = eval_writer.filename\n",
    "\n",
    "print('# Remaning Examples:', len(remaining_examples))\n",
    "print('# Features:', len(eval_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nf_map = {}\n",
    "# for f in eval_features:\n",
    "#     if f.example_index in nf_map:\n",
    "#         nf_map[f.example_index] += 1\n",
    "#     else:\n",
    "#         nf_map[f.example_index] = 1\n",
    "\n",
    "# n_tokens_to_features = []\n",
    "# for example in eval_examples:\n",
    "#     n_tokens = len(example.doc_tokens)\n",
    "#     n_features = nf_map[example.example_id]\n",
    "#     n_tokens_to_features.append((n_tokens, n_features))\n",
    "    \n",
    "# print(pd.Series([x[0] / x[1] for x in n_tokens_to_features]).describe())\n",
    "\n",
    "# sns.scatterplot([x[0] for x in n_tokens_to_features], [x[1] for x in n_tokens_to_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bert_baseline\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BertModel)                ((None, 1024), (None 335141888   input_ids[0][0]                  \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "td_seq (TDense)                 (None, 384, 2)       2050        bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split (TensorFlowOp [(None, 384, 1), (No 0           td_seq[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_start_logits (Tenso [(None, 384)]        0           tf_op_layer_split[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_end_logits (TensorF [(None, 384)]        0           tf_op_layer_split[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "ans_type_logits (TDense)        (None, 5)            5125        bert[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 335,149,063\n",
      "Trainable params: 335,149,063\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(model_name=FLAGS.model,\n",
    "                    config_file=FLAGS.config_file,\n",
    "                    max_seq_length=FLAGS.max_seq_length,\n",
    "                    init_ckpt=FLAGS.init_checkpoint)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = np.ceil(eval_writer.num_features / FLAGS.predict_batch_size)\n",
    "generator = data_generator(eval_filename, FLAGS.predict_batch_size)\n",
    "\n",
    "preds = model.predict_generator(generator, steps=n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejmejm/anaconda3/envs/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:147: UserWarning: Original to document index mapping could not be resolved!\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    'ans_type_conf_weight': 0.4,\n",
    "    'start_pos_conf_weight': 0.3,\n",
    "    'end_pos_conf_weight': 0.3,\n",
    "    'conf_bias': 0.0,\n",
    "    'conf_threshold': 0.97\n",
    "}\n",
    "\n",
    "answers = compute_answers(preds, candidates_dict, eval_features, eval_examples, id_to_example, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Micro-F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.5315068493150685\n",
      "Recall: 0.9238095238095239\n",
      "Precision: 0.3730769230769231\n",
      "{'TP': 97, 'FP': 163, 'FN': 8, 'FP_WA': 56, 'FP_NA': 107}\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.test_post_processing:\n",
    "    micro_f1, recall, precision, details = score_preds(actual_answers, answers)\n",
    "\n",
    "    print(f'Micro F1 Score: {micro_f1}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TP = 95   FP = 165   FN = 7   TN = 133   F1 = 0.52',\n",
       " 'TP = 62   FP = 90   FN = 4   TN = 44   F1 = 0.57',\n",
       " 'TP = 33   FP = 75   FN = 3   TN = 89   F1 = 0.46')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_preds_2(raw_examples, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search to Select the Best Parameters for Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    default_range = np.arange(0, 1.05, 0.5)\n",
    "\n",
    "    weight_ranges = OrderedDict({\n",
    "            'ans_type_conf_weight': [0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "            'start_pos_conf_weight': [0, 0.25, 0.5, 0.75, 1.0],\n",
    "            'end_pos_conf_weight': [0, 0.25, 0.5, 0.75, 1.0],\n",
    "            'conf_bias': [-0.5, -0.25, 0, 0.25, 0.5],\n",
    "            'conf_threshold': [0.5]\n",
    "        })\n",
    "\n",
    "    combinations = list(itertools.product(*[weight_ranges[k] for k in weight_ranges.keys()]))\n",
    "\n",
    "    actual_answers = get_actual_answers(FLAGS.train_file, FLAGS.n_examples)\n",
    "\n",
    "    results = {}\n",
    "    for weight_vals in tqdm.tqdm(combinations):\n",
    "        weights = {}\n",
    "        for weight_name, weight_val in zip(weight_ranges.keys(), weight_vals):\n",
    "                weights[weight_name] = weight_val\n",
    "\n",
    "        tmp_answers = compute_answers(preds, candidates_dict, eval_features, weights)\n",
    "        micro_f1, recall, precision, _ = score_preds(actual_answers, tmp_answers)\n",
    "        results[weight_vals] = (micro_f1, recall, precision)\n",
    "        \n",
    "    sr = sorted(results.items(), key=lambda x: x[1][0], reverse=True)\n",
    "    print(sr[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to explore (WIP)\n",
    "- Can we accurately order the answers in terms of confidence?\n",
    "- Is a series of segments all with answers a good predictor for an actual answer in that block?\n",
    "- What does the general spread of probabilities look like when there is an answer?\n",
    "- What about the spread of probabilities when there is no answer?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- If 1, 2, and 3 are in a row, choose the middle one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_range(first, second):\n",
    "    return first[0] >= second[0] and first[1] <= second[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 5  3 15 12  0  2  1  0  0  6  0 14 11  0 10  0  0  0  0  9 13  8  7  4\n",
      "  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 0 2 1 0 5 0 6 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 3 2 7 6 8 9 0 5 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 2 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 0 4 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 2 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  9  0  0  0  0  0\n",
      "  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  1  2  0  0  0\n",
      "  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  8  4  5]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 4 3 0 0]\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[ 1  0  7  5  0  6  8 10  0  3  4  2  0 11  9  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0  2  5  4 12  0  0  0  0  0  0  0  0 10  8  9  0  0  0  0  0  0  0  0\n",
      "  0  0  0  1  3  0  0  0  0  0  0  6  7 11  0  0  0  0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 4 2 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 5 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 4 0 3 0 5 2 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3]\n",
      "[0 0 0]\n",
      "\n",
      "[1 2 0]\n",
      "[0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 3 1 4 0 5 2 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3 4 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0  2  1  5 10  0  0 11  0  0  9  6  8  3  4  7  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 3 0 0 0 0 0 0 2 6 4 5 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 2 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "\n",
      "[4 3 2 1 0 0 6 5 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "\n",
      "[0 5 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "\n",
      "[0 0 0 4 6 5 3 1 2 0 0]\n",
      "[0 0 0 0 0 0 0 1 1 0 0]\n",
      "\n",
      "[6 4 5 7 1 3 2 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1]\n",
      "[1]\n",
      "\n",
      "[0 0 0 0 2 3 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 3 0 0 0 0 0 4 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 3 4 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 4 0 3 1 2 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3 0 0 0]\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 0 0 0]\n",
      "[0 1 0 0 0]\n",
      "\n",
      "[2 1 0 0]\n",
      "[0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 3 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "\n",
      "[1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0]\n",
      "[1 0]\n",
      "\n",
      "[0 2 0 1 0]\n",
      "[0 0 0 0 0]\n",
      "\n",
      "[0 0 2 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[4 2 1 3 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 5 0 4 2 1 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 2 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 2 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 3 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 2 1 0 0 0 0 0 0 0 5 4 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\n",
      "[4 1 2 3 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 6 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0]\n",
      "\n",
      "[3 0 0 1 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 2 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 4 0 0 0 0 0 5 3 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 4 0 0 2 1 3 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 5 4 0 7 6 3 2 1 0 8 0 0 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1]\n",
      "[0]\n",
      "\n",
      "[2 1 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "\n",
      "[3 2 1 8 7 6 5 4 0 0]\n",
      "[0 1 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 2 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[4 1 5 3 2 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[3 1 0 0 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 5]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 2 1 0]\n",
      "[0 0 0 0 0]\n",
      "\n",
      "[5 1 2 3 4 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0]\n",
      "\n",
      "[1 3 4 2 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 3 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 4 0 0 0 0]\n",
      "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 4 3 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0]\n",
      "[1 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 2 3 1 0 0 0 0 4 5 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 7 3 4 2 5 0 0 0 6 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 6  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8 13 12  0 14 10\n",
      "  0  5  1  2  0  9 11  7  0  0  0  0  0  0  0  0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 0 0 3 2 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 2 1 0 0 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 0 0]\n",
      "\n",
      "[ 0  0  0  0  0  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  6  5  0  0  4  2  0  8\n",
      "  0  0  0 10  7  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 4 2 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 3 0 0 0 0 0 0 1 2 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 5 0 3 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 4 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[5 4 1 2 0 3 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 4 3 1 0 0 0 2]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 0 0 0 0]\n",
      "[1 1 0 0 0 0]\n",
      "\n",
      "[1 2 0 0]\n",
      "[0 0 0 0]\n",
      "\n",
      "[ 1  3  4  5  0  0  8  0  7  0  0  0  9  2  0  0  0  0  0  0 10  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  6]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[3 2 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 2 0]\n",
      "[0 0 0 0 0 0 0]\n",
      "\n",
      "[6 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 3 5 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1]\n",
      "[1]\n",
      "\n",
      "[0 0 3 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 2 3 1 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 7 5 0 0 0 0 0 3\n",
      " 2 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 3 0 4]\n",
      "[0 0 0 0 0]\n",
      "\n",
      "[2 1 0]\n",
      "[1 1 0]\n",
      "\n",
      "[2 1 0 0 0 0]\n",
      "[1 1 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 1 4 2 3 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[1 0 2 0 3 0 4 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 0 1 0]\n",
      "[0 0 0 0]\n",
      "\n",
      "[1 5 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 3\n",
      " 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[1 2]\n",
      "[1 0]\n",
      "\n",
      "[0 3 0 0 0 0 0 0 4 2 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "\n",
      "[1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 5  4  2  9  1  3  6  7 12  8 13 10  0  0  0  0  0 11  0  0  0  0  0  0\n",
      "  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 6 5 7 2 4 3 8 0]\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 4 5 6 3 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Avg # features per example: 20.135\n"
     ]
    }
   ],
   "source": [
    "avg_n_features = 0\n",
    "ordering_reg_data = [] # (predicted rank of answer, whether there actually is answer at that feature)\n",
    "n_preds_data = [] # (percent of features that predict an answer, whether there is actually an answer)\n",
    "\n",
    "for example_id in answers.keys():\n",
    "    pred_answer = answers[example_id]\n",
    "    actual_answer = actual_answers[example_id]\n",
    "    \n",
    "    if not pred_answer['ordered_entries']:\n",
    "        continue\n",
    "    \n",
    "    avg_n_features += id_to_example[example_id].n_features\n",
    "    entries_pred = np.zeros(id_to_example[example_id].n_features, dtype=np.int32)\n",
    "    actual_oh = np.zeros(id_to_example[example_id].n_features, dtype=np.int32)\n",
    "    for entry_idx, entry in enumerate(pred_answer['ordered_entries']):\n",
    "        feature = entry['feature']\n",
    "        entries_pred[feature.doc_span_index] = entry_idx + 1\n",
    "        \n",
    "        tok_to_orig_map = entry['feature'].token_to_orig_map\n",
    "        feature_min_idx = min(tok_to_orig_map.values(), key=lambda x: x if x != -1 else 99999)\n",
    "        feature_max_idx = max(tok_to_orig_map.values())\n",
    "        target_answers = actual_answer['long_answers']\n",
    "        if isinstance(actual_answer['short_answers'], tuple):\n",
    "            target_answers = actual_answer['short_answers']\n",
    "        if target_answers:\n",
    "            for tgt in target_answers:\n",
    "                if in_range(tgt, (feature_min_idx, feature_max_idx)):\n",
    "                    actual_oh[feature.doc_span_index] = 1\n",
    "                    break\n",
    "     \n",
    "    percent_preds = len(pred_answer['ordered_entries']) / id_to_example[example_id].n_features\n",
    "    exists_answer = int(1 in actual_oh)\n",
    "    n_preds_data.append((percent_preds, exists_answer))\n",
    "    \n",
    "    for x, y in zip(entries_pred, actual_oh):\n",
    "        if x != 0 or y != 0:\n",
    "            ordering_reg_data.append((x, y))\n",
    "    \n",
    "    print(entries_pred)\n",
    "    print(actual_oh)\n",
    "    print()\n",
    "\n",
    "print('Avg # features per example:', avg_n_features / len(answers.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9e6063a190>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot([x[0] for x in ordering_reg_data], [x[1] for x in ordering_reg_data], s=100, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9e60572050>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot([x[0] for x in n_preds_data], [x[1] for x in n_preds_data], s=100, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features for the Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples (2): 152\n",
      "# Features (2): 473\n",
      "**Features**\n",
      "\n",
      "answer_text\n",
      "answer_type\n",
      "doc_span_index\n",
      "end_position\n",
      "example_index\n",
      "input_ids\n",
      "input_mask\n",
      "segment_ids\n",
      "start_position\n",
      "token_is_max_context\n",
      "token_to_orig_map\n",
      "tokens\n",
      "unique_id\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.do_predict:\n",
    "    if FLAGS.second_model == 'bert':\n",
    "        tokenizer_2 = bert_tokenization.FullTokenizer(\n",
    "            vocab_file=FLAGS.second_vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
    "    elif FLAGS.second_model == 'albert':\n",
    "        tokenizer_2 = albert_tokenization.FullTokenizer(\n",
    "            None, spm_model_file=FLAGS.second_vocab_file)\n",
    "\n",
    "    if FLAGS.test_post_processing:\n",
    "        input_file = FLAGS.train_file\n",
    "    else:\n",
    "        input_file = FLAGS.predict_file\n",
    "\n",
    "    eval_writer_2 = nqa_utils.FeatureWriter(\n",
    "      filename=os.path.join(FLAGS.output_dir, \"eval_2.tf_record\"),\n",
    "      is_training=FLAGS.test_post_processing)\n",
    "    eval_features_2 = []\n",
    "    \n",
    "    def append_feature_2(feature):\n",
    "        eval_features_2.append(feature)\n",
    "        eval_writer_2.process_feature(feature)\n",
    "    \n",
    "    # Limit examples to only those that are not unknown answers\n",
    "    eval_examples_2 = [example for example in eval_examples if answers[example.example_id]['long_answer']]\n",
    "\n",
    "    for target_rank in range(8):\n",
    "        # Get the document token index ranges of the desired answers\n",
    "        n_extra_tokens = 30\n",
    "        answer_ranges = []\n",
    "        curr_examples = []\n",
    "        for example in eval_examples_2:\n",
    "            answer = answers[example.example_id]\n",
    "            if target_rank >= len(answer['ordered_entries']):\n",
    "                continue\n",
    "            entry = answer['ordered_entries'][target_rank]\n",
    "\n",
    "            doc_start_idx = entry['doc_tokens_start_idx']\n",
    "            doc_end_idx = entry['doc_tokens_end_idx']\n",
    "\n",
    "            answer_ranges.append((max(0, doc_start_idx - n_extra_tokens),\n",
    "                                  min(len(example.doc_tokens), doc_end_idx + n_extra_tokens)))\n",
    "            \n",
    "            curr_examples.append(example)\n",
    "\n",
    "        convert_partial_examples_to_features(\n",
    "            examples=eval_examples_2,\n",
    "            ranges=answer_ranges,\n",
    "            tokenizer=tokenizer_2,\n",
    "            is_training=FLAGS.test_post_processing,\n",
    "            output_fn=append_feature_2)\n",
    "\n",
    "    eval_writer_2.close()\n",
    "    eval_filename_2 = eval_writer_2.filename\n",
    "\n",
    "    print('# Examples (2):', len(eval_examples_2))\n",
    "    print('# Features (2):', len(eval_features_2))\n",
    "\n",
    "    print('**Features**\\n')\n",
    "\n",
    "    for e in dir(eval_features_2[0]):\n",
    "        if not e.startswith('__'):\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"albert\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "albert_model (AlbertModel)      ((None, 4096), (None 222622336   input_ids[0][0]                  \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "td_seq (TDense)                 (None, 384, 2)       8194        albert_model[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split (TensorFlowOp [(None, 384, 1), (No 0           td_seq[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_start_logits (Tenso [(None, 384)]        0           tf_op_layer_split[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_end_logits (TensorF [(None, 384)]        0           tf_op_layer_split[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "ans_type_logits (TDense)        (None, 5)            20485       albert_model[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 222,651,015\n",
      "Trainable params: 222,651,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model(model_name=FLAGS.second_model,\n",
    "                    config_file=FLAGS.second_config_file,\n",
    "                    max_seq_length=FLAGS.second_max_seq_length,\n",
    "                    init_ckpt=FLAGS.second_init_checkpoint)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Predictions with the Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = np.ceil(eval_writer_2.num_features / FLAGS.second_batch_size)\n",
    "generator = data_generator(eval_filename_2, FLAGS.second_batch_size)\n",
    "\n",
    "preds_2 = model.predict(generator, steps=n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute New Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.662379421221865\n",
      "Recall: 0.824\n",
      "Precision: 0.553763440860215\n",
      "{'TP': 103, 'FP': 83, 'FN': 22, 'FP_WA': 36, 'FP_NA': 47}\n",
      "\n",
      "TP = 101   FP = 85   FN = 21   TN = 193   F1 = 0.66\n",
      "TP = 60   FP = 45   FN = 15   TN = 80   F1 = 0.67\n",
      "TP = 41   FP = 40   FN = 6   TN = 113   F1 = 0.64\n"
     ]
    }
   ],
   "source": [
    "invalid_input_ids_2 = tokenizer_2.convert_tokens_to_ids(['[Q]', '[SEP]', '[CLS]', '[PAD]'])\n",
    "\n",
    "weights_2 = {\n",
    "    'ans_type_conf_weight': 0.6,\n",
    "    'start_pos_conf_weight': 0.3,\n",
    "    'end_pos_conf_weight': 0.1,\n",
    "    'conf_bias': 0.0,\n",
    "    'conf_threshold': 0.8\n",
    "}\n",
    "\n",
    "second_answers = compute_answers(preds_2, \n",
    "                                 candidates_dict, \n",
    "                                 eval_features_2, \n",
    "                                 eval_examples_2, \n",
    "                                 id_to_example,\n",
    "                                 weights=weights_2,\n",
    "                                invalid_input_ids=invalid_input_ids_2)\n",
    "\n",
    "final_answers = copy.copy(answers)\n",
    "final_answers.update(second_answers)\n",
    "\n",
    "if FLAGS.test_post_processing:\n",
    "#     actual_answers = get_actual_answers(FLAGS.train_file, FLAGS.n_examples)\n",
    "    micro_f1, recall, precision, details = score_preds(actual_answers, final_answers)\n",
    "\n",
    "    print(f'Micro F1 Score: {micro_f1}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(details)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    for x in score_preds_2(raw_examples, final_answers):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'long_answer': (2861, 2943), 'short_answer': (2893, 2906)},\n",
       " {'long_answer': (176, 245), 'short_answer': (238, 240)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (75, 186), 'short_answer': (85, 86)},\n",
       " {'long_answer': (946, 1147), 'short_answer': (972, 973)},\n",
       " {'long_answer': (83, 406), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (323, 379), 'short_answer': (360, 364)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (603, 655), 'short_answer': (651, 653)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (723, 827), 'short_answer': (739, 740)},\n",
       " {'long_answer': (3524, 3608), 'short_answer': (3534, 3535)},\n",
       " {'long_answer': (66, 155), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (245, 335), 'short_answer': (246, 249)},\n",
       " {'long_answer': (1338, 1485), 'short_answer': None},\n",
       " {'long_answer': (516, 600), 'short_answer': (597, 598)},\n",
       " {'long_answer': (191, 392), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (620, 670), 'short_answer': (645, 647)},\n",
       " {'long_answer': (484, 545), 'short_answer': (508, 510)},\n",
       " {'long_answer': (113, 168), 'short_answer': (153, 155)},\n",
       " {'long_answer': (584, 704), 'short_answer': (682, 684)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (594, 699), 'short_answer': (636, 637)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (755, 831), 'short_answer': (783, 796)},\n",
       " {'long_answer': (1032, 1138), 'short_answer': (1042, 1058)},\n",
       " {'long_answer': (195, 282), 'short_answer': (270, 271)},\n",
       " {'long_answer': (1089, 1451), 'short_answer': (1292, 1295)},\n",
       " {'long_answer': (203, 271), 'short_answer': None},\n",
       " {'long_answer': (468, 627), 'short_answer': (588, 594)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (787, 967), 'short_answer': (799, 802)},\n",
       " {'long_answer': (122, 281), 'short_answer': (123, 127)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (729, 857), 'short_answer': (733, 737)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (505, 621), 'short_answer': (529, 542)},\n",
       " {'long_answer': (1080, 1137), 'short_answer': (1123, 1125)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (49, 177), 'short_answer': (62, 63)},\n",
       " {'long_answer': (99, 313), 'short_answer': (110, 112)},\n",
       " {'long_answer': (167, 214), 'short_answer': (193, 195)},\n",
       " {'long_answer': (97, 176), 'short_answer': (102, 103)},\n",
       " {'long_answer': (1225, 1285), 'short_answer': None},\n",
       " {'long_answer': (749, 883), 'short_answer': (821, 822)},\n",
       " {'long_answer': (617, 836), 'short_answer': (618, 621)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (905, 1007), 'short_answer': (952, 956)},\n",
       " {'long_answer': (1532, 1661), 'short_answer': None},\n",
       " {'long_answer': (524, 604), 'short_answer': (527, 530)},\n",
       " {'long_answer': (198, 3038), 'short_answer': (245, 247)},\n",
       " {'long_answer': (809, 940), 'short_answer': 'YES'},\n",
       " {'long_answer': (1533, 1821), 'short_answer': (1779, 1780)},\n",
       " {'long_answer': (379, 463), 'short_answer': (421, 422)},\n",
       " {'long_answer': (255, 326), 'short_answer': 'YES'},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (586, 730), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (105, 216), 'short_answer': (174, 175)},\n",
       " {'long_answer': (1363, 2023), 'short_answer': (1995, 2007)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (406, 699), 'short_answer': (435, 447)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (250, 352), 'short_answer': (263, 269)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (933, 1041), 'short_answer': (994, 995)},\n",
       " {'long_answer': (1726, 1765), 'short_answer': (1727, 1738)},\n",
       " {'long_answer': (284, 296), 'short_answer': (293, 294)},\n",
       " {'long_answer': (980, 1084), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (16, 562), 'short_answer': (343, 344)},\n",
       " {'long_answer': (205, 264), 'short_answer': (214, 217)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (616, 693), 'short_answer': (627, 629)},\n",
       " {'long_answer': (628, 699), 'short_answer': (643, 654)},\n",
       " {'long_answer': (240, 364), 'short_answer': (241, 244)},\n",
       " {'long_answer': (634, 759), 'short_answer': (643, 653)},\n",
       " {'long_answer': (91, 194), 'short_answer': None},\n",
       " {'long_answer': (96, 199), 'short_answer': (97, 99)},\n",
       " {'long_answer': (1734, 2056), 'short_answer': (1744, 1746)},\n",
       " {'long_answer': (38, 103), 'short_answer': (90, 96)},\n",
       " {'long_answer': (3474, 3512), 'short_answer': (3489, 3493)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (1645, 1738), 'short_answer': (1695, 1696)},\n",
       " {'long_answer': (584, 853), 'short_answer': None},\n",
       " {'long_answer': (347, 438), 'short_answer': (431, 437)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (985, 1049), 'short_answer': (1035, 1041)},\n",
       " {'long_answer': (900, 1020), 'short_answer': None},\n",
       " {'long_answer': (208, 247), 'short_answer': (225, 229)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (32, 136), 'short_answer': (45, 47)},\n",
       " {'long_answer': (2214, 2761), 'short_answer': (2233, 2236)},\n",
       " {'long_answer': (442, 489), 'short_answer': None},\n",
       " {'long_answer': (65, 730), 'short_answer': (429, 432)},\n",
       " {'long_answer': (882, 1021), 'short_answer': None},\n",
       " {'long_answer': (584, 769), 'short_answer': None},\n",
       " {'long_answer': (209, 286), 'short_answer': (229, 239)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (573, 780), 'short_answer': (574, 602)},\n",
       " {'long_answer': (251, 373), 'short_answer': (258, 259)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (366, 633), 'short_answer': (383, 384)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (229, 532), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (83, 159), 'short_answer': (91, 93)},\n",
       " {'long_answer': (434, 608), 'short_answer': (444, 445)},\n",
       " {'long_answer': (248, 329), 'short_answer': None},\n",
       " {'long_answer': (801, 943), 'short_answer': None},\n",
       " {'long_answer': (898, 931), 'short_answer': (925, 929)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (5132, 5221), 'short_answer': (5181, 5184)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (270, 417), 'short_answer': None},\n",
       " {'long_answer': (305, 470), 'short_answer': (355, 358)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (260, 369), 'short_answer': (287, 289)},\n",
       " {'long_answer': (259, 373), 'short_answer': (260, 262)},\n",
       " {'long_answer': (314, 551), 'short_answer': None},\n",
       " {'long_answer': (523, 636), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (1628, 1797), 'short_answer': (1653, 1654)},\n",
       " {'long_answer': (370, 474), 'short_answer': (372, 374)},\n",
       " {'long_answer': (69, 110), 'short_answer': (91, 94)},\n",
       " {'long_answer': (411, 518), 'short_answer': None},\n",
       " {'long_answer': (300, 495), 'short_answer': None},\n",
       " {'long_answer': (75, 113), 'short_answer': (76, 80)},\n",
       " {'long_answer': (1542, 1839), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (788, 846), 'short_answer': (838, 840)},\n",
       " {'long_answer': (141, 219), 'short_answer': (209, 210)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (281, 383), 'short_answer': (312, 315)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (3520, 3626), 'short_answer': (3583, 3599)}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{k: v for k, v in a.items() if k in ('short_answer', 'long_answer')} for a in second_answers.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has answer percent: 67.11%\n",
      "Long answer agreement: 83.33%\n",
      "Short answer agreement: 60.76%\n"
     ]
    }
   ],
   "source": [
    "simple_answers = [{k: v for k, v in a.items() if k in ('short_answer', 'long_answer')} \\\n",
    "    for a in second_answers.values()]\n",
    "\n",
    "has_ans_perc = sum([1 for a in simple_answers if a['long_answer']]) / len(simple_answers)\n",
    "print('Has answer percent: {:.2f}%'.format(has_ans_perc * 100))\n",
    "\n",
    "n_la = 0\n",
    "n_sa = 0\n",
    "n_la_matches = 0\n",
    "n_sa_matches = 0\n",
    "for example_id in second_answers.keys():\n",
    "    answer1 = answers[example_id]\n",
    "    answer2 = second_answers[example_id]\n",
    "    if answer2['long_answer']:\n",
    "        n_la += 1\n",
    "        if answer1['long_answer'] == answer2['long_answer']:\n",
    "            n_la_matches += 1\n",
    "            \n",
    "    if answer2['short_answer']:\n",
    "        n_sa += 1\n",
    "        if answer1['short_answer'] == answer2['short_answer']:\n",
    "            n_sa_matches += 1\n",
    "            \n",
    "print('Long answer agreement: {:.2f}%'.format(n_la_matches/n_la * 100))\n",
    "print('Short answer agreement: {:.2f}%'.format(n_sa_matches/n_sa * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.6179401993355482\n",
      "Recall: 0.775\n",
      "Precision: 0.5138121546961326\n",
      "{'TP': 93, 'FP': 88, 'FN': 27, 'FP_WA': 41, 'FP_NA': 47}\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.test_post_processing:\n",
    "    actual_answers = get_actual_answers(FLAGS.train_file, FLAGS.n_examples)\n",
    "    micro_f1, recall, precision, details = score_preds(actual_answers, final_answers)\n",
    "\n",
    "    print(f'Micro F1 Score: {micro_f1}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for Postprocessing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    weight_ranges = OrderedDict({\n",
    "            'ans_type_conf_weight': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7],\n",
    "            'start_pos_conf_weight': [-0.1, 0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "            'end_pos_conf_weight': [-0.1, 0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "            'conf_bias': [-0.2, -0.1, 0, 0.1, 0.2],\n",
    "            'conf_threshold': [0.5]\n",
    "        })\n",
    "\n",
    "    combinations = list(itertools.product(*[weight_ranges[k] for k in weight_ranges.keys()]))\n",
    "\n",
    "    actual_answers = get_actual_answers(FLAGS.train_file, FLAGS.n_examples)\n",
    "\n",
    "    results = {}\n",
    "    for weight_vals in tqdm.tqdm(combinations):\n",
    "        weights_2 = {}\n",
    "        for weight_name, weight_val in zip(weight_ranges.keys(), weight_vals):\n",
    "                weights_2[weight_name] = weight_val\n",
    "                \n",
    "        tmp_answers = compute_answers(preds_2, \n",
    "                                      candidates_dict, \n",
    "                                      eval_features_2, \n",
    "                                      eval_examples_2, \n",
    "                                      id_to_example,\n",
    "                                      weights=weights_2,\n",
    "                                      invalid_input_ids=invalid_input_ids_2)\n",
    "        tmp_final_answers = copy.copy(answers)\n",
    "        tmp_final_answers.update(tmp_answers)\n",
    "        \n",
    "        micro_f1, recall, precision, _ = score_preds(actual_answers, tmp_final_answers)\n",
    "        results[weight_vals] = (micro_f1, recall, precision)\n",
    "        \n",
    "    sr = sorted(results.items(), key=lambda x: x[1][0], reverse=True)\n",
    "    print(sr[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Joint Baseline\n",
    "    - F1: 0.564\n",
    "    - Recall: 0.850\n",
    "    - Precision: 0.422\n",
    "    \n",
    "    On 2000 dev examples:\n",
    "    - F1: 0.524\n",
    "    \n",
    "### BERT Joint + ALBERT Finetuned\n",
    "    - F1: 0.628\n",
    "    - Recall: 0.667\n",
    "    - Precision: 0.593\n",
    "    \n",
    "    On 2000 dev examples:\n",
    "    \n",
    "    'ans_type_conf_weight': 0.6,\n",
    "    'start_pos_conf_weight': 0.3,\n",
    "    'end_pos_conf_weight': 0.1,\n",
    "    'conf_bias': 0.0,\n",
    "    'conf_threshold': 0.8\n",
    "        \n",
    "    - F1: 0.613\n",
    "    \n",
    "### ALBERT Finetuned\n",
    "    - F1: 0.791\n",
    "    - Recall: 0.895\n",
    "    - Precision: 0.708"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Create a Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(answers):\n",
    "    submission_data = []\n",
    "\n",
    "    # Loop through answers in alphabetic order of example_ids\n",
    "    # This is how it's sorted in the sample submission\n",
    "    for example_id, answer in sorted(answers.items(), key=lambda x: x[0]):\n",
    "        long_answer_text = ''\n",
    "        if isinstance(answer['long_answer'], tuple):\n",
    "            long_answer_text = f'{answer[\"long_answer\"][0]}:{answer[\"long_answer\"][1]}'\n",
    "        else:\n",
    "            assert answer['long_answer'] is None, 'Invalid type of long answer!'\n",
    "            assert answer['short_answer'] is None, 'Cannot have a short answer with no long answer!'\n",
    "        long_answer_row = [f'{example_id}_long', long_answer_text]\n",
    "\n",
    "        short_answer_text = ''\n",
    "        if isinstance(answer['short_answer'], tuple):\n",
    "            short_answer_text = f'{answer[\"short_answer\"][0]}:{answer[\"short_answer\"][1]}'\n",
    "        elif answer['short_answer'] in ('YES', 'NO'):\n",
    "            short_answer_text = answer['short_answer']\n",
    "        else:\n",
    "            assert answer['short_answer'] is None, 'Invalid type of short answer!'\n",
    "        short_answer_row = [f'{example_id}_short', short_answer_text]\n",
    "\n",
    "        submission_data.append(long_answer_row)\n",
    "        submission_data.append(short_answer_row)\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_data, columns=['example_id', 'PredictionString'])\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Save the Submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FLAGS.test_post_processing:\n",
    "    submission_df = create_submission(answers)\n",
    "    print(submission_df.head())\n",
    "    submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
