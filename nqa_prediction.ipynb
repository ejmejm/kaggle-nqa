{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NQ&A Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "from scripts import tf2_0_baseline_w_bert_translated_to_tf2_0 as tf2baseline # Oliviera's script\n",
    "from scripts.tf2_0_baseline_w_bert_translated_to_tf2_0 import Answer, AnswerType\n",
    "from scripts import bert_modeling as modeling\n",
    "from scripts import bert_tokenization\n",
    "from scripts import albert\n",
    "from scripts import albert_tokenization\n",
    "from scripts.models import build_model\n",
    "\n",
    "import collections\n",
    "from collections import OrderedDict, namedtuple\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "import absl\n",
    "import sys\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()\n",
    "    keys_list = [keys for keys in flags_dict]\n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(absl.flags.FLAGS)\n",
    "\n",
    "flags = absl.flags\n",
    "\n",
    "### Main Model Flags ###\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"model\", \"bert\",\n",
    "    \"The name of model to use. Choose from ['bert', 'albert'].\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"config_file\", \"models/bert_joint_baseline/bert_config.json\",\n",
    "    \"The config json file corresponding to the pre-trained BERT/ALBERT model. \"\n",
    "    \"This specifies the model architecture.\")\n",
    "\n",
    "flags.DEFINE_string(\"vocab_file\", \"models/bert_joint_baseline/vocab-nq.txt\",\n",
    "                    \"The vocabulary file that the ALBERT/BERT model was trained on.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"init_checkpoint\", \"models/bert_joint_baseline/tf2_bert_joint.ckpt\",\n",
    "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_seq_length\", 384,\n",
    "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
    "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
    "    \"than this will be padded.\")\n",
    "\n",
    "flags.DEFINE_integer(\"predict_batch_size\", 1,\n",
    "                     \"Total batch size for predictions.\")\n",
    "\n",
    "### Second Model Flags ###\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"second_model\", \"albert\",\n",
    "    \"The name of model to use. Choose from ['albert', 'bert'].\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"second_config_file\", \"models/albert_xxl/config.json\",\n",
    "    \"The config json file corresponding to the pre-trained BERT/ALBERT model. \"\n",
    "    \"This specifies the model architecture.\")\n",
    "\n",
    "flags.DEFINE_string(\"second_vocab_file\", \"models/albert_xxl/vocab/modified-30k-clean.model\",\n",
    "                    \"The vocabulary file that the ALBERT/BERT model was trained on.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"second_init_checkpoint\", \"models/albert_xxl/albert_finetuned.h5\",\n",
    "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"second_max_seq_length\", 384,\n",
    "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
    "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
    "    \"than this will be padded.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"second_batch_size\", 1,\n",
    "    \"Batch size when running verifier predictions.\")\n",
    "\n",
    "### Other Flags ###\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"output_dir\", \"output/\",\n",
    "    \"The output directory where the model checkpoints will be written.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"train_file\", \"data/simplified-nq-dev.jsonl\",\n",
    "    \"NQ json for predictions. E.g., dev-v1.1.jsonl.gz or test-v1.1.jsonl.gz\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"log_dir\", \"logs/\",\n",
    "    \"Where logs, specifically Tensorboard logs, will be saved to.\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"do_lower_case\", True,\n",
    "    \"Whether to lower case the input text. Should be True for uncased \"\n",
    "    \"models and False for cased models.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"doc_stride\", 128,\n",
    "    \"When splitting up a long document into chunks, how much stride to \"\n",
    "    \"take between chunks.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_query_length\", 64,\n",
    "    \"The maximum number of tokens for the question. Questions longer than \"\n",
    "    \"this will be truncated to this length.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_train\", False, \"Whether to run training.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_predict\", True, \"Whether to run eval on the dev set.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_answer_length\", 30,\n",
    "    \"The maximum length of an answer that can be generated. This is needed \"\n",
    "    \"because the start and end predictions are not conditioned on one another.\")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"include_unknowns\", 1.0,\n",
    "    \"If positive, probability of including answers of type `UNKNOWN`.\")\n",
    "\n",
    "absl.flags.DEFINE_string(\n",
    "    \"gcp_project\", None,\n",
    "    \"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n",
    "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
    "    \"metadata.\")\n",
    "\n",
    "# TODO(Edan): Look at nested contents too at some point\n",
    "# Around 5% of long answers are nested, and around 50% of questions have\n",
    "# long answers\n",
    "# This means that this setting alone restricts us from a correct answer\n",
    "# around 2.5% of the time\n",
    "flags.DEFINE_boolean(\n",
    "    \"skip_nested_contexts\", True,\n",
    "    \"Completely ignore context that are not top level nodes in the page.\")\n",
    "\n",
    "flags.DEFINE_integer(\"max_contexts\", 48,\n",
    "                     \"Maximum number of contexts to output for an example.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_position\", 50,\n",
    "    \"Maximum context position for which to generate special tokens.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"n_examples\", 200,\n",
    "    \"Number of examples to read from files.\")\n",
    "\n",
    "flags.DEFINE_boolean(\n",
    "    \"test_post_processing\", True,\n",
    "    \"If true, training data will be predicted for instead of eval data,\"\n",
    "    \"and the predictions will be used to tune the post processing algorithm.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"tokens_per_small_example\", 105*10, # On average about 10 features\n",
    "    \"The amount of tokens allowed on average for an example to be considered \"\n",
    "    \"small. Small examples are run directly through ALBERT-xxl.\")\n",
    "\n",
    "### Currently Not In Use ###\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_features_per_small_example\", 15,\n",
    "    \"The amount of features allowed for a small example before being truncated.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_features_per_example\", 65,\n",
    "    \"The amount of features allowed for an example before being truncated.\")\n",
    "\n",
    "## Special flags - do not change\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"predict_file\", \"/kaggle/input/tensorflow2-question-answering/simplified-nq-test.jsonl\",\n",
    "    \"NQ json for predictions. E.g., dev-v1.1.jsonl.gz or test-v1.1.jsonl.gz\")\n",
    "flags.DEFINE_boolean(\"logtostderr\", True, \"Logs to stderr\")\n",
    "flags.DEFINE_boolean(\"undefok\", True, \"it's okay to be undefined\")\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_string('HistoryManager.hist_file', '', 'kernel')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS(sys.argv) # Parse the flags\n",
    "\n",
    "N_TRAIN_EXAMPLES = 307373"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_partial_nq_examples(input_file, is_training, n=-1, from_back=False):\n",
    "    \"\"\"Read a NQ json file into a list of NqExample.\"\"\"\n",
    "    input_paths = tf.io.gfile.glob(input_file)\n",
    "    input_data = []\n",
    "\n",
    "    def _open(path):\n",
    "        if path.endswith(\".gz\"):\n",
    "            return gzip.GzipFile(fileobj=tf.io.gfile.GFile(path, \"rb\"))\n",
    "        else:\n",
    "            return tf.io.gfile.GFile(path, \"r\")\n",
    "\n",
    "    n_skip = 0\n",
    "    if from_back and n > 0:\n",
    "        n_skip = N_TRAIN_EXAMPLES - n\n",
    "\n",
    "    for path in input_paths:\n",
    "        absl.logging.info(\"Reading: %s\", path)\n",
    "        with _open(path) as input_file:\n",
    "            for _ in range(n_skip):\n",
    "                input_file.readline()\n",
    "            for index, line in enumerate(input_file):\n",
    "                if n > -1 and index >= n:\n",
    "                        break\n",
    "                input_data.append(tf2baseline.create_example_from_jsonl(line))\n",
    "\n",
    "    examples = []\n",
    "    for entry in input_data:\n",
    "        examples.extend(tf2baseline.read_nq_entry(entry, is_training))\n",
    "    return examples\n",
    "\n",
    "tf2baseline.read_nq_examples = read_partial_nq_examples\n",
    "\n",
    "def read_partial_candidates_from_one_split(input_path, n=-1, from_back=False):\n",
    "    \"\"\"Read candidates from a single jsonl file.\"\"\"\n",
    "    candidates_dict = {}\n",
    "    if input_path.endswith(\".gz\"):\n",
    "        with gzip.GzipFile(fileobj=tf.io.gfile.GFile(input_path, \"rb\")) as input_file:\n",
    "            absl.logging.info(\"Reading examples from: %s\", input_path)\n",
    "\n",
    "            n_skip = 0\n",
    "            if from_back and n > 0:\n",
    "                n_skip = N_TRAIN_EXAMPLES - n\n",
    "\n",
    "            for _ in range(n_skip):\n",
    "                input_file.readline()\n",
    "        \n",
    "            for index, line in enumerate(input_file):\n",
    "                if n > -1 and index >= n:\n",
    "                        break\n",
    "\n",
    "                e = json.loads(line)\n",
    "                candidates_dict[e[\"example_id\"]] = e[\"long_answer_candidates\"]\n",
    "    else:\n",
    "        with tf.io.gfile.GFile(input_path, \"r\") as input_file:\n",
    "            absl.logging.info(\"Reading examples from: %s\", input_path)\n",
    "            \n",
    "            n_skip = 0\n",
    "            if from_back and n > 0:\n",
    "                n_skip = N_TRAIN_EXAMPLES - n\n",
    "\n",
    "            for _ in range(n_skip):\n",
    "                input_file.readline()\n",
    "            \n",
    "            for index, line in enumerate(input_file):\n",
    "                if n > -1 and index >= n:\n",
    "                        break\n",
    "                        \n",
    "                e = json.loads(line)\n",
    "                candidates_dict[e[\"example_id\"]] = e[\"long_answer_candidates\"]\n",
    "                \n",
    "    return candidates_dict\n",
    "\n",
    "tf2baseline.read_candidates_from_one_split = read_partial_candidates_from_one_split\n",
    "\n",
    "def read_partial_candidates(input_pattern, n=-1, from_back=False):\n",
    "    \"\"\"Read candidates with real multiple processes.\"\"\"\n",
    "    input_paths = tf.io.gfile.glob(input_pattern)\n",
    "\n",
    "    if from_back and n > 0:\n",
    "        assert len(input_paths) == 1\n",
    "\n",
    "    final_dict = {}\n",
    "    for i, input_path in enumerate(input_paths):\n",
    "        final_dict.update(tf2baseline.read_candidates_from_one_split(input_path, n=n-len(final_dict.keys()),\n",
    "                                                                     from_back=from_back))\n",
    "        if len(final_dict.keys()) >= n:\n",
    "                break\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "tf2baseline.read_candidates = read_partial_candidates\n",
    "\n",
    "def raw_data_generator(path, chunk_size=1000, from_back=False):\n",
    "        \"\"\"Reads raw JSON examples to a DataFrame\"\"\"\n",
    "        curr_pos = 0\n",
    "        last_line = False\n",
    "        with open(path, 'rt') as f:\n",
    "                \n",
    "                n_skip = 0\n",
    "                if from_back and chunk_size > 0:\n",
    "                    n_skip = N_TRAIN_EXAMPLES - chunk_size\n",
    "\n",
    "                for _ in range(n_skip):\n",
    "                    f.readline()\n",
    "            \n",
    "                while not last_line:\n",
    "                        df = []\n",
    "                        for i in range(curr_pos, curr_pos+chunk_size):\n",
    "                                line = f.readline()\n",
    "                                if line is None:\n",
    "                                        last_line = True\n",
    "                                        break\n",
    "                                df.append(json.loads(line))\n",
    "                        curr_pos = i + 1\n",
    "                        yield pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_features = {\n",
    "    \"unique_ids\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    \"input_ids\": tf.io.FixedLenFeature([FLAGS.max_seq_length], tf.int64),\n",
    "    \"input_mask\": tf.io.FixedLenFeature([FLAGS.max_seq_length], tf.int64),\n",
    "    \"segment_ids\": tf.io.FixedLenFeature([FLAGS.max_seq_length], tf.int64),\n",
    "}\n",
    "if FLAGS.do_train:\n",
    "    name_to_features[\"start_positions\"] = tf.io.FixedLenFeature([], tf.int64)\n",
    "    name_to_features[\"end_positions\"] = tf.io.FixedLenFeature([], tf.int64)\n",
    "    name_to_features[\"answer_types\"] = tf.io.FixedLenFeature([], tf.int64)\n",
    "\n",
    "def decode_record(record, name_to_features):\n",
    "    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "    example = tf.io.parse_single_example(serialized=record, features=name_to_features)\n",
    "\n",
    "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "    # So cast all int64 to int32.\n",
    "    for name in list(example.keys()):\n",
    "        t = example[name]\n",
    "        if t.dtype == tf.int64:\n",
    "            t = tf.cast(t, dtype=tf.int32)\n",
    "        example[name] = t\n",
    "\n",
    "    return example\n",
    "\n",
    "def data_generator(eval_filename, batch_size=32, n_samples=-1, seed=42):\n",
    "    \"\"\"The actual input function.\"\"\"\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(eval_filename)\n",
    "    if FLAGS.do_train:\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.shuffle(buffer_size=5000, seed=seed)\n",
    "        \n",
    "    dataset = dataset.map(lambda r: decode_record(r, name_to_features))\n",
    "    dataset = dataset.batch(batch_size=batch_size, drop_remainder=False)\n",
    "    \n",
    "    data_iter = iter(dataset)\n",
    "    sample_idx = 0\n",
    "    while sample_idx < n_samples or n_samples == -1:\n",
    "        try:\n",
    "            examples = next(data_iter)\n",
    "        except StopIteration:\n",
    "            break\n",
    "            \n",
    "        cutoff_amt = batch_size\n",
    "        if n_samples > -1:\n",
    "            cutoff_amt = min(cutoff_amt, n_samples - sample_idx)\n",
    "        sample_idx += cutoff_amt\n",
    "    \n",
    "        for k, v in examples.items():\n",
    "            examples[k] = v[:cutoff_amt]\n",
    "        \n",
    "        inputs = {\n",
    "            # 'unique_id': examples['unique_ids'],\n",
    "            'input_ids': examples['input_ids'],\n",
    "            'input_mask': examples['input_mask'],\n",
    "            'segment_ids': examples['segment_ids']\n",
    "        }\n",
    "\n",
    "        if FLAGS.do_train:\n",
    "            targets = {\n",
    "                'tf_op_layer_start_logits': examples['start_positions'],\n",
    "                'tf_op_layer_end_logits': examples['end_positions'],\n",
    "                'ans_type_logits': examples['answer_types'],\n",
    "            }\n",
    "\n",
    "            yield inputs, targets\n",
    "        else:\n",
    "            yield inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Computing Answers from Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid\n",
    "def logits_to_probs(x):\n",
    "    return np.exp(x) / (np.exp(x) + 1)\n",
    "\n",
    "def get_candidate_span(entry):\n",
    "    return (entry['candidates'][entry['candidate_idx']]['start_token'],\n",
    "            entry['candidates'][entry['candidate_idx']]['end_token'])\n",
    "\n",
    "def check_entry_in_candidates(entry):\n",
    "    \"\"\"Checks if the entry start and ending tokens fall into a candidate.\n",
    "        Returns the candidate index, or -1 if none is found.\"\"\"\n",
    "    if not FLAGS.skip_nested_contexts:\n",
    "        raise NotImplementedError('Nested contexts have not been implemented for predictions yet!')\n",
    "    else:\n",
    "        for cand_idx, candidate in enumerate(entry['candidates']):\n",
    "            if not candidate['top_level']:\n",
    "                continue\n",
    "            if entry['orig_start'] >= candidate['start_token'] and \\\n",
    "                entry['orig_end'] <= candidate['end_token']:\n",
    "                return cand_idx\n",
    "    return -1\n",
    "\n",
    "def compute_answers(preds, candidates_dict, features,\n",
    "                    examples, id_to_examples, weights={},\n",
    "                    invalid_input_ids=[]):\n",
    "    default_weights = {\n",
    "        'ans_type_conf_weight': 0.4,\n",
    "        'start_pos_conf_weight': 0.3,\n",
    "        'end_pos_conf_weight': 0.3,\n",
    "        'conf_bias': 0.0,\n",
    "        'conf_threshold': 0.98\n",
    "    }\n",
    "    \n",
    "    for k, v in default_weights.items():\n",
    "        if k not in weights:\n",
    "            weights[k] = v\n",
    "    \n",
    "    ### Get variables needed for post processing ###\n",
    "    start_token_probs = logits_to_probs(preds[0])\n",
    "    end_token_probs = logits_to_probs(preds[1])\n",
    "    ans_type_probs = logits_to_probs(preds[2])\n",
    "    candidates_dict = {int(k): v for k, v in candidates_dict.items()}\n",
    "\n",
    "    ### Create doc span groups ###\n",
    "    \n",
    "    doc_span_groups = {}\n",
    "    for i, feature in enumerate(features):\n",
    "        example_idx = feature.example_index\n",
    "        if example_idx not in doc_span_groups:\n",
    "            doc_span_groups[example_idx] = []\n",
    "\n",
    "        group_data = {\n",
    "            'start_tokens_probs': start_token_probs[i],\n",
    "            'end_tokens_probs': end_token_probs[i],\n",
    "            'ans_type_probs': ans_type_probs[i],\n",
    "            'candidates': candidates_dict[example_idx],\n",
    "            'feature': features[i],\n",
    "            'doc_tokens_map': id_to_examples[example_idx].doc_tokens_map\n",
    "        }\n",
    "\n",
    "        doc_span_groups[example_idx].append(group_data)\n",
    "    \n",
    "    ### Compute answers ###\n",
    "        \n",
    "    answers = {} # Maps example_ids to long and short answers\n",
    "    for example_id, group in doc_span_groups.items():\n",
    "        example = id_to_example[example_id]\n",
    "        example.n_features = len(group)\n",
    "        doc_to_orig = example.doc_tokens_map\n",
    "        \n",
    "        assert doc_to_orig is not None\n",
    "        \n",
    "        # Reverse doc_to_orig to create orig_to_doc\n",
    "        orig_to_doc = {}\n",
    "        for doc_token_idx, orig_tok_idx in enumerate(doc_to_orig):\n",
    "            orig_to_doc[orig_tok_idx] = doc_token_idx\n",
    "        orig_to_doc[-1] = -1\n",
    "        example.orig_to_doc = orig_to_doc\n",
    "        \n",
    "        # This loop just gathers the non-unknown, valid predictions\n",
    "        valid_entries = []\n",
    "        for entry in group:\n",
    "            try:\n",
    "                # Converting logits to answer values\n",
    "                entry['start_token_idx'] = np.argmax(entry['start_tokens_probs'])\n",
    "                entry['end_token_idx'] = np.argmax(entry['end_tokens_probs'])\n",
    "                entry['ans_type_idx'] = np.argmax(entry['ans_type_probs'])\n",
    "\n",
    "                entry['start_pos_prob'] = entry['start_tokens_probs'][entry['start_token_idx']]\n",
    "                entry['end_pos_prob'] = entry['end_tokens_probs'][entry['end_token_idx']]\n",
    "                entry['ans_type_prob'] = entry['ans_type_probs'][entry['ans_type_idx']]\n",
    "\n",
    "                # Calculating probability of the chosen answer type\n",
    "                entry['prob'] = weights['conf_bias'] + \\\n",
    "                                entry['start_pos_prob'] * weights['start_pos_conf_weight'] + \\\n",
    "                                entry['end_pos_prob'] * weights['end_pos_conf_weight'] + \\\n",
    "                                entry['ans_type_prob'] * weights['ans_type_conf_weight']\n",
    "\n",
    "                # Filter out entries with invalid answers\n",
    "                if entry['end_token_idx'] < entry['start_token_idx'] or \\\n",
    "                    (entry['end_token_idx'] - entry['start_token_idx'] > FLAGS.max_answer_length and \\\n",
    "                     entry['ans_type_idx'] == AnswerType.SHORT) or \\\n",
    "                    entry['feature'].segment_ids[entry['start_token_idx']] == 0 or \\\n",
    "                    entry['feature'].segment_ids[entry['end_token_idx']] == 0 or \\\n",
    "                    entry['feature'].input_mask[entry['start_token_idx']] == 0 or \\\n",
    "                    entry['feature'].input_mask[entry['end_token_idx']] == 0 or \\\n",
    "                    entry['feature'].input_ids[entry['start_token_idx']] in invalid_input_ids or \\\n",
    "                    entry['feature'].input_ids[entry['end_token_idx']] in invalid_input_ids or \\\n",
    "                    entry['ans_type_idx'] == AnswerType.UNKNOWN or \\\n",
    "                    entry['prob'] < weights['conf_threshold']:\n",
    "                    continue\n",
    "                    \n",
    "                # Getting indices of tokens in original document\n",
    "                tok_to_orig_map = entry['feature'].token_to_orig_map\n",
    "                \n",
    "                entry['orig_start'] = tok_to_orig_map[entry['start_token_idx']]\n",
    "                entry['orig_end'] = tok_to_orig_map[entry['end_token_idx']] + 1\n",
    "\n",
    "                entry['doc_tokens_start_idx'] = -1\n",
    "                entry['doc_tokens_end_idx'] = -1\n",
    "\n",
    "                # Getting indices of tokens in preprocessed document\n",
    "                if entry['orig_start'] in orig_to_doc:\n",
    "                    entry['doc_tokens_start_idx'] = orig_to_doc[entry['orig_start']]\n",
    "                else:\n",
    "                    # I'm not sure if this resolution works\n",
    "#                     print('Resolving orig_to_doc missing index, but resolution method may be flawed!')\n",
    "                    target = entry['orig_start']\n",
    "                    for key in sorted(orig_to_doc.keys()):\n",
    "                        if key > target:\n",
    "                            entry['doc_tokens_start_idx'] = orig_to_doc[key]\n",
    "                            break\n",
    "\n",
    "                if entry['orig_end'] in orig_to_doc:\n",
    "                    entry['doc_tokens_end_idx'] = orig_to_doc[entry['orig_end'] - 1] + 1\n",
    "                else:\n",
    "                    # I'm not sure if this resolution works\n",
    "#                     print('Resolving orig_to_doc missing index, but resolution method may be flawed!')\n",
    "                    target = entry['orig_end'] - 1\n",
    "                    for key in sorted(orig_to_doc.keys(), reverse=True):\n",
    "                        if key < target:\n",
    "                            entry['doc_tokens_end_idx'] = orig_to_doc[key] + 1\n",
    "                            break\n",
    "\n",
    "                if entry['doc_tokens_start_idx'] == -1 or entry['doc_tokens_end_idx'] == -1 \\\n",
    "                   or entry['doc_tokens_end_idx'] == 0:\n",
    "                    warnings.warn('Original to document index mapping could not be resolved!')\n",
    "                    continue\n",
    "\n",
    "                entry['candidate_idx'] = check_entry_in_candidates(entry)\n",
    "                if entry['candidate_idx'] == -1:\n",
    "                    continue\n",
    "\n",
    "                valid_entries.append(entry)\n",
    "            except:\n",
    "                warning.warn(\"Unexpected while parsing features:\", sys.exc_info()[0])\n",
    "\n",
    "        long_answer = None\n",
    "        short_answer = None\n",
    "        doc_tokens_span = None\n",
    "        ordered_entries = None\n",
    "            \n",
    "        if len(valid_entries) > 0:\n",
    "            # TODO(Edan): I think I should probably prioritize short answers\n",
    "            # over long answers because both can be right, but most long answer\n",
    "            # also have short answers\n",
    "            # I could also look at if other probabilities are also high,\n",
    "            # ideally only a single entry should have a high logit\n",
    "            # Ammend: not only one entry, but one and the ones near it\n",
    "            ordered_entries = sorted(valid_entries, key=lambda e: e['prob'], reverse=True)\n",
    "            best_entry = ordered_entries[0]\n",
    "            if best_entry['ans_type_idx'] == AnswerType.LONG:\n",
    "                long_answer = get_candidate_span(best_entry)\n",
    "            elif best_entry['ans_type_idx'] == AnswerType.SHORT:\n",
    "                long_answer = get_candidate_span(best_entry)\n",
    "                short_answer = (best_entry['orig_start'], best_entry['orig_end'])\n",
    "            elif best_entry['ans_type_idx'] == AnswerType.YES:\n",
    "                long_answer = get_candidate_span(best_entry)\n",
    "                short_answer = 'YES'\n",
    "            elif best_entry['ans_type_idx'] == AnswerType.NO:\n",
    "                long_answer = get_candidate_span(best_entry)\n",
    "                short_answer = 'NO'\n",
    "            else:\n",
    "                raise ValueError('Entry should not have AnswerType UNKNOWN or other!')\n",
    "                \n",
    "            doc_tokens_start = best_entry['doc_tokens_start_idx']\n",
    "            doc_tokens_end = best_entry['doc_tokens_end_idx']\n",
    "            doc_tokens_span = (doc_tokens_start, doc_tokens_end)\n",
    "        \n",
    "        answers[example_id] = {'long_answer': long_answer,\n",
    "                               'short_answer': short_answer,\n",
    "                               'doc_tokens_span': doc_tokens_span,\n",
    "                               'ordered_entries': ordered_entries}\n",
    "\n",
    "    return answers\n",
    "\n",
    "def get_actual_answers(file_path, n, from_back=False):\n",
    "    raw_generator = raw_data_generator(file_path, n, from_back)\n",
    "    raw_data = next(raw_generator)\n",
    "    \n",
    "    actual_answers = {}\n",
    "    for _, entry in raw_data.iterrows():\n",
    "        long_answer = entry['annotations'][0]['long_answer']\n",
    "        short_answers = entry['annotations'][0]['short_answers']\n",
    "        \n",
    "        la_spans = []\n",
    "        if long_answer['start_token'] != -1 and long_answer['end_token'] != -1:\n",
    "            la_spans = [(long_answer['start_token'], long_answer['end_token'])]\n",
    "        \n",
    "        sa_spans = []\n",
    "        for short_answer in short_answers:\n",
    "            sa_spans.append((short_answer['start_token'], short_answer['end_token']))\n",
    "            \n",
    "        if entry['annotations'][0]['yes_no_answer'] != 'NONE':\n",
    "            sa_spans.append(entry['annotations'][0]['yes_no_answer'])\n",
    "        \n",
    "        answer_entry = {\n",
    "            'long_answers': la_spans,\n",
    "            'short_answers': sa_spans\n",
    "        }\n",
    "        actual_answers[entry['example_id']] = answer_entry\n",
    "        \n",
    "    return actual_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for the Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_partial_example(example, start_idx, end_idx, tokenizer, is_training, lowercase=True, fit_span=True):\n",
    "    \"\"\"Converts a single NqExample into a list of InputFeatures.\n",
    "    \n",
    "    Start and end indices are given by the preprocessed document indices.\n",
    "    \"\"\"\n",
    "    # QUERY\n",
    "    query_tokens = []\n",
    "    query_tokens.append(\"[Q]\")\n",
    "    query_tokens.extend(tf2baseline.tokenize(tokenizer, example.questions[-1]))\n",
    "    if len(query_tokens) > FLAGS.max_query_length:\n",
    "        query_tokens = query_tokens[-FLAGS.max_query_length:]\n",
    "\n",
    "    # The -3 accounts for [CLS], [SEP] and [SEP]\n",
    "    max_tokens_for_doc = FLAGS.max_seq_length - len(query_tokens) - 3\n",
    "    \n",
    "    part_doc_tokens = example.doc_tokens[start_idx:end_idx]\n",
    "    part_doc_tokens_map = None\n",
    "    if example.doc_tokens_map:\n",
    "        part_doc_tokens_map = example.doc_tokens_map[start_idx:end_idx]\n",
    "    \n",
    "    tok_to_orig_index = [] # Tokenized doc to original doc\n",
    "    orig_to_tok_index = [-1] * start_idx # Preprocessed doc to tokenized doc mapping\n",
    "    all_doc_tokens = []\n",
    "    features = []\n",
    "    for (i, token) in enumerate(part_doc_tokens, start_idx):\n",
    "        if lowercase and not (token.startswith('[') and token.endswith(']')):\n",
    "            token = token.lower()\n",
    "        \n",
    "        orig_to_tok_index.append(len(all_doc_tokens))\n",
    "        sub_tokens = tf2baseline.tokenize(tokenizer, token)\n",
    "        tok_to_orig_index.extend([i] * len(sub_tokens))\n",
    "        all_doc_tokens.extend(sub_tokens)\n",
    "\n",
    "    if fit_span:\n",
    "        # Even though it's a partial example, we might as well fill up the doc span\n",
    "        i = end_idx\n",
    "        while i < len(example.doc_tokens):\n",
    "            if len(all_doc_tokens) == max_tokens_for_doc or \\\n",
    "               (len(all_doc_tokens) > max_tokens_for_doc and \\\n",
    "               (len(all_doc_tokens) - max_tokens_for_doc) % 128 == 0):\n",
    "                break\n",
    "\n",
    "            token = example.doc_tokens[i]\n",
    "            if lowercase and not (token.startswith('[') and token.endswith(']')):\n",
    "                token = token.lower()\n",
    "\n",
    "            orig_to_tok_index.append(len(all_doc_tokens))\n",
    "            sub_tokens = tf2baseline.tokenize(tokenizer, token)\n",
    "            for sub_token in sub_tokens:\n",
    "                tok_to_orig_index.append(i)\n",
    "                all_doc_tokens.append(sub_token)\n",
    "                if len(all_doc_tokens) == max_tokens_for_doc or \\\n",
    "                   (len(all_doc_tokens) > max_tokens_for_doc and \\\n",
    "                   (len(all_doc_tokens) - max_tokens_for_doc) % 128 == 0):\n",
    "                    break\n",
    "            i += 1\n",
    "        \n",
    "    orig_to_tok_index.extend([-1] * (len(example.doc_tokens) - len(all_doc_tokens)))\n",
    "\n",
    "    # `tok_to_orig_index` maps wordpiece indices to indices of whitespace\n",
    "    # tokenized word tokens in the contexts. The word tokens might themselves\n",
    "    # correspond to word tokens in a larger document, with the mapping given\n",
    "    # by `doc_tokens_map`.\n",
    "    if example.doc_tokens_map:\n",
    "        tok_to_orig_index = [\n",
    "            example.doc_tokens_map[index] for index in tok_to_orig_index\n",
    "        ]\n",
    "\n",
    "    # We can have documents that are longer than the maximum sequence length.\n",
    "    # To deal with this we do a sliding window approach, where we take chunks\n",
    "    # of up to our max length with a stride of `doc_stride`.\n",
    "    _DocSpan = namedtuple(  # pylint: disable=invalid-name\n",
    "        \"DocSpan\", [\"start\", \"length\"])\n",
    "    doc_spans = []\n",
    "    start_offset = 0\n",
    "    while start_offset < len(all_doc_tokens):\n",
    "        length = len(all_doc_tokens) - start_offset\n",
    "        length = min(length, max_tokens_for_doc)\n",
    "        doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "        if start_offset + length == len(all_doc_tokens):\n",
    "            break\n",
    "        start_offset += min(length, FLAGS.doc_stride)\n",
    "    \n",
    "    for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
    "        tokens = []\n",
    "        token_to_orig_map = {}\n",
    "        token_is_max_context = {}\n",
    "        segment_ids = []\n",
    "        tokens.append(\"[CLS]\")\n",
    "        segment_ids.append(0)\n",
    "        tokens.extend(query_tokens)\n",
    "        segment_ids.extend([0] * len(query_tokens))\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(0)\n",
    "\n",
    "        for i in range(doc_span.length):\n",
    "            split_token_index = doc_span.start + i\n",
    "            token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]\n",
    "\n",
    "            is_max_context = tf2baseline.check_is_max_context(doc_spans, doc_span_index,\n",
    "                split_token_index)\n",
    "            token_is_max_context[len(tokens)] = is_max_context\n",
    "            tokens.append(all_doc_tokens[split_token_index])\n",
    "            segment_ids.append(1)\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(1)\n",
    "        assert len(tokens) == len(segment_ids)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (FLAGS.max_seq_length - len(input_ids))\n",
    "        input_ids.extend(padding)\n",
    "        input_mask.extend(padding)\n",
    "        segment_ids.extend(padding)\n",
    "\n",
    "        assert len(input_ids) == FLAGS.max_seq_length\n",
    "        assert len(input_mask) == FLAGS.max_seq_length\n",
    "        assert len(segment_ids) == FLAGS.max_seq_length\n",
    "\n",
    "        start_position = -1\n",
    "        end_position = -1\n",
    "        answer_type = -1\n",
    "        answer_text = \"\"\n",
    "\n",
    "        feature = tf2baseline.InputFeatures(\n",
    "            unique_id=-1,\n",
    "            example_index=-1,\n",
    "            doc_span_index=doc_span_index,\n",
    "            tokens=tokens,\n",
    "            token_to_orig_map=token_to_orig_map,\n",
    "            token_is_max_context=token_is_max_context,\n",
    "            input_ids=input_ids,\n",
    "            input_mask=input_mask,\n",
    "            segment_ids=segment_ids,\n",
    "            start_position=start_position,\n",
    "            end_position=end_position,\n",
    "            answer_text=answer_text,\n",
    "            answer_type=answer_type)\n",
    "\n",
    "        features.append(feature)\n",
    "\n",
    "    return features\n",
    "\n",
    "def convert_partial_examples_to_features(examples, ranges, tokenizer, is_training, output_fn):\n",
    "    \"\"\"Converts a list of NqExamples into InputFeatures.\"\"\"\n",
    "    num_spans_to_ids = collections.defaultdict(list)\n",
    "\n",
    "    for example, idx_range in zip(examples, ranges):\n",
    "        example_index = example.example_id\n",
    "        features = convert_partial_example(example, idx_range[0], idx_range[1], tokenizer, is_training)\n",
    "        num_spans_to_ids[len(features)].append(example.qas_id)\n",
    "\n",
    "        for feature in features:\n",
    "            feature.example_index = example_index\n",
    "            feature.unique_id = feature.example_index + feature.doc_span_index\n",
    "            output_fn(feature)\n",
    "\n",
    "    return num_spans_to_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Types\n",
    "- UNKNOWN = 0\n",
    "- YES = 1\n",
    "- NO = 2\n",
    "- SHORT = 3\n",
    "- LONG = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Computing the Micro-F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_preds(actual_answers, pred_answers):\n",
    "    if set(actual_answers.keys()) != set(answers.keys()):\n",
    "        raise ValueError('Actual answers and answers must contain the same example_id keys!')\n",
    "    \n",
    "    TP = 0 # True positives\n",
    "    FP = 0 # False positives\n",
    "    FN = 0 # False negatives\n",
    "    \n",
    "    FP_NA = 0 # False positives where there was no answer\n",
    "    FP_WA = 0 # False positives where an answer existed\n",
    "    for example_id in actual_answers.keys():\n",
    "        actual_las = actual_answers[example_id]['long_answers']\n",
    "        actual_sas = actual_answers[example_id]['short_answers']\n",
    "        \n",
    "        pred_la = pred_answers[example_id]['long_answer']\n",
    "        pred_sa = pred_answers[example_id]['short_answer']\n",
    "        \n",
    "        if pred_la in actual_las:\n",
    "            TP += 1\n",
    "        elif pred_la and pred_la not in actual_las:\n",
    "            FP += 1\n",
    "            if actual_las:\n",
    "                FP_WA += 1\n",
    "            else:\n",
    "                FP_NA += 1\n",
    "        elif not pred_la and actual_las:\n",
    "            FN += 1\n",
    "            \n",
    "        if pred_sa in actual_sas:\n",
    "            TP += 1\n",
    "        elif pred_sa and pred_sa not in actual_las:\n",
    "            FP += 1\n",
    "            if actual_sas:\n",
    "                FP_WA += 1\n",
    "            else:\n",
    "                FP_NA += 1\n",
    "        elif not pred_sa and actual_sas:\n",
    "            FN += 1\n",
    "\n",
    "    details = {\n",
    "        'TP': TP,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'FP_WA': FP_WA,\n",
    "        'FP_NA': FP_NA\n",
    "    }\n",
    "    \n",
    "    if TP == 0:\n",
    "        return 0, 0, 0, details\n",
    "    \n",
    "    recall = TP / (TP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    micro_f1 = 2 * precision * recall / (precision + recall)\n",
    "    return micro_f1, recall, precision, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_annotations(example):\n",
    "    longs = [('%s:%s' % (l['start_token'],l['end_token']))\n",
    "                for l in [a['long_answer'] for a in example['annotations']]\n",
    "                if not l['candidate_index'] == -1\n",
    "            ]\n",
    "    return longs #list of long annotations\n",
    "\n",
    "def short_annotations(example):\n",
    "    shorts = [('%s:%s' % (s['start_token'],s['end_token']))\n",
    "                  for s in \n",
    "                  # sum(list_of_lists, []) is not very efficient gives an easy flat map for short lists\n",
    "                  sum([a['short_answers'] for a in example['annotations']], [])\n",
    "             ]\n",
    "    return shorts #list of short annotations\n",
    "\n",
    "def yes_nos(example):\n",
    "    return [\n",
    "        yesno for yesno in [a['yes_no_answer'] for a in example['annotations']]\n",
    "        if not yesno == 'NONE'\n",
    "    ]\n",
    "\n",
    "class Score():\n",
    "    def __init__(self):\n",
    "        self.TP = 0\n",
    "        self.FP = 0\n",
    "        self.FN = 0\n",
    "        self.TN = 0\n",
    "    def F1(self):\n",
    "        return 2 * self.TP / (2 * self.TP + self.FP + self.FN)\n",
    "    def increment(self, prediction, annotations, yes_nos):\n",
    "        if prediction in yes_nos:\n",
    "            print(prediction, yes_nos)\n",
    "            self.TP += 1\n",
    "        elif len(prediction) > 0:\n",
    "            if prediction in annotations:\n",
    "                self.TP += 1\n",
    "            else:\n",
    "                self.FP += 1\n",
    "        elif len(annotations) == 0:\n",
    "            self.TN += 1\n",
    "        else:\n",
    "            self.FN +=1\n",
    "    def scores(self):\n",
    "        recall = \n",
    "        return 'TP = {}   FP = {}   FN = {}   TN = {}   Recall = {:.3f}  Precision = {:.3f}   F1 = {:.3f}'.format(\n",
    "            self.TP, self.FP, self.FN, self.TN, recall, precision, self.F1())\n",
    "\n",
    "def score_preds_2(raw_examples, answers):\n",
    "    long_score = Score()\n",
    "    short_score = Score()\n",
    "    total_score = Score()\n",
    "\n",
    "    for example in raw_examples:\n",
    "        la = answers[example['example_id']]['long_answer']\n",
    "        sa = answers[example['example_id']]['short_answer']\n",
    "        \n",
    "        long_pred = ''\n",
    "        if la:\n",
    "            long_pred = '{}:{}'.format(la[0], la[1])\n",
    "        long_score.increment(long_pred, long_annotations(example), [])\n",
    "        total_score.increment(long_pred, long_annotations(example), [])\n",
    "        \n",
    "        short_pred = ''\n",
    "        if sa:\n",
    "            short_pred = '{}:{}'.format(sa[0], sa[1])\n",
    "        short_score.increment(short_pred, short_annotations(example), yes_nos(example))\n",
    "        total_score.increment(short_pred, short_annotations(example), [])\n",
    "        \n",
    "    return total_score.scores(), long_score.scores(), short_score.scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict File: data/simplified-nq-dev.jsonl\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.test_post_processing:\n",
    "    input_file = FLAGS.train_file\n",
    "    actual_answers = get_actual_answers(input_file, FLAGS.n_examples)\n",
    "else:\n",
    "    input_file = FLAGS.predict_file\n",
    "    \n",
    "candidates_dict = tf2baseline.read_candidates(input_file, n=FLAGS.n_examples)\n",
    "\n",
    "print(\"Predict File:\", input_file)\n",
    "\n",
    "eval_examples = tf2baseline.read_nq_examples(\n",
    "      input_file=input_file, is_training=FLAGS.test_post_processing, n=FLAGS.n_examples)\n",
    "\n",
    "raw_examples = next(raw_data_generator(input_file, FLAGS.n_examples))\n",
    "raw_examples = [dict(row) for _, row in raw_examples.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Part 1: ALBERT Small Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Small Examples: 72\n",
      "# Features: 681\n"
     ]
    }
   ],
   "source": [
    "### Get the Small Examples ###\n",
    "\n",
    "small_examples = []\n",
    "remaining_examples = []\n",
    "\n",
    "n_total_tokens = 0\n",
    "n_total_examples = 0\n",
    "sorted_examples = sorted(eval_examples, key=lambda x: len(x.doc_tokens))\n",
    "for example in sorted_examples:\n",
    "    n_tokens = len(example.doc_tokens)\n",
    "    n_total_tokens += n_tokens\n",
    "    n_total_examples += 1\n",
    "    \n",
    "    if n_total_examples and n_total_tokens and \\\n",
    "        n_total_tokens / n_total_examples >= FLAGS.tokens_per_small_example:\n",
    "        break\n",
    "        \n",
    "small_examples = sorted_examples[:n_total_examples]\n",
    "remaining_examples = sorted_examples[n_total_examples:]\n",
    "# small_examples = eval_examples\n",
    "\n",
    "if FLAGS.second_model == 'bert':\n",
    "    tokenizer_small = bert_tokenization.FullTokenizer(\n",
    "        vocab_file=FLAGS.second_vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
    "    lowercase = False\n",
    "elif FLAGS.second_model == 'albert':\n",
    "    tokenizer_small = albert_tokenization.FullTokenizer(\n",
    "        None, spm_model_file=FLAGS.second_vocab_file)\n",
    "    lowercase = True\n",
    "\n",
    "def append_feature_small(feature):\n",
    "    eval_features_small.append(feature)\n",
    "    eval_writer_small.process_feature(feature)\n",
    "\n",
    "eval_writer_small = tf2baseline.FeatureWriter(\n",
    "  filename=os.path.join(FLAGS.output_dir, \"eval_small.tf_record\"),\n",
    "  is_training=FLAGS.test_post_processing)\n",
    "eval_features_small = []\n",
    "\n",
    "tf2baseline.convert_examples_to_features(\n",
    "  examples=small_examples,\n",
    "  tokenizer=tokenizer_small,\n",
    "  is_training=FLAGS.test_post_processing,\n",
    "  output_fn=append_feature_small,\n",
    "  lowercase=lowercase)\n",
    "\n",
    "eval_writer_small.close()\n",
    "eval_filename_small = eval_writer_small.filename\n",
    "\n",
    "print('# Small Examples:', len(small_examples))\n",
    "print('# Features:', len(eval_features_small))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model and Run Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"albert\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "albert_model (AlbertModel)      ((None, 4096), (None 222622336   input_ids[0][0]                  \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "td_seq (TDense)                 (None, 384, 2)       8194        albert_model[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split (TensorFlowOp [(None, 384, 1), (No 0           td_seq[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_start_logits (Tenso [(None, 384)]        0           tf_op_layer_split[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_end_logits (TensorF [(None, 384)]        0           tf_op_layer_split[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "ans_type_logits (TDense)        (None, 5)            20485       albert_model[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 222,651,015\n",
      "Trainable params: 222,651,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model(model_name=FLAGS.second_model,\n",
    "                    config_file=FLAGS.second_config_file,\n",
    "                    max_seq_length=FLAGS.second_max_seq_length,\n",
    "                    init_ckpt=FLAGS.second_init_checkpoint)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = np.ceil(eval_writer_small.num_features / FLAGS.second_batch_size)\n",
    "generator = data_generator(eval_filename_small, FLAGS.second_batch_size)\n",
    "\n",
    "preds_small = model.predict(generator, steps=n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Part 2: BERT-Joint Remaining Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Predict File: data/simplified-nq-dev.jsonl\n",
      "# Small Examples: 85\n",
      "# Features: 3841\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.model == 'bert':\n",
    "    tokenizer = bert_tokenization.FullTokenizer(\n",
    "        vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
    "elif FLAGS.model == 'albert':\n",
    "    tokenizer = albert_tokenization.FullTokenizer(\n",
    "        None, spm_model_file=FLAGS.vocab_file)\n",
    "\n",
    "# This is actually quite slow, tokenization takes a non-negligible amount of time\n",
    "eval_examples = tf2baseline.read_nq_examples(\n",
    "      input_file=input_file, is_training=FLAGS.test_post_processing, n=FLAGS.n_examples)\n",
    "\n",
    "#     for e in eval_examples:\n",
    "#         for i in range(len(e.doc_tokens)):\n",
    "#             if not (e.doc_tokens[i].startswith('[') and e.doc_tokens[i].endswith(']')):\n",
    "#                 e.doc_tokens[i] = e.doc_tokens[i].lower()\n",
    "\n",
    "eval_writer = tf2baseline.FeatureWriter(\n",
    "  filename=os.path.join(FLAGS.output_dir, \"eval.tf_record\"),\n",
    "  is_training=FLAGS.test_post_processing)\n",
    "eval_features = []\n",
    "\n",
    "def append_feature(feature):\n",
    "    eval_features.append(feature)\n",
    "    eval_writer.process_feature(feature)\n",
    "\n",
    "num_spans_to_ids = tf2baseline.convert_examples_to_features(\n",
    "  examples=eval_examples,\n",
    "  tokenizer=tokenizer,\n",
    "  is_training=FLAGS.test_post_processing,\n",
    "  output_fn=append_feature)\n",
    "eval_writer.close()\n",
    "eval_filename = eval_writer.filename\n",
    "\n",
    "print('# Small Examples:', len(small_examples))\n",
    "print('# Features:', len(eval_features_small))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    200.000000\n",
      "mean     109.559028\n",
      "std       17.265728\n",
      "min       74.608696\n",
      "25%      100.926136\n",
      "50%      105.880195\n",
      "75%      112.610390\n",
      "max      194.500000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fde8e6c3390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nf_map = {}\n",
    "# for f in eval_features:\n",
    "#     if f.example_index in nf_map:\n",
    "#         nf_map[f.example_index] += 1\n",
    "#     else:\n",
    "#         nf_map[f.example_index] = 1\n",
    "\n",
    "# n_tokens_to_features = []\n",
    "# for example in eval_examples:\n",
    "#     n_tokens = len(example.doc_tokens)\n",
    "#     n_features = nf_map[example.example_id]\n",
    "#     n_tokens_to_features.append((n_tokens, n_features))\n",
    "    \n",
    "# print(pd.Series([x[0] / x[1] for x in n_tokens_to_features]).describe())\n",
    "\n",
    "# sns.scatterplot([x[0] for x in n_tokens_to_features], [x[1] for x in n_tokens_to_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **eval_features**\n",
    "- `doc_span_index`: Which index this span is in the set that makes up one question-article pair\n",
    "- `example_index`: Index of the example \n",
    "- `input_mask`: 0 if a token is padding, otherwise 1 for each token in the article\n",
    "- `segment_ids`: Tokens that are part of a question are 0 ([CLS], [Q], ..., [SEP])\n",
    "- `inpud_ids`: Token ids of the article\n",
    "    - 0 -> [PAD]\n",
    "    - 101 -> [CLS]\n",
    "    - 102 -> [SEP]\n",
    "    - 103 -> [MASK]\n",
    "    - 104 -> [Q]\n",
    "    - 105 -> [YES]\n",
    "    - 106 -> [NO]\n",
    "    - 107 -> [NoLongAnswer]\n",
    "    - 108 -> [NoShortAnswer]\n",
    "- `token_is_max_context`: False if this token will appear again in the next document span due to a sliding window being used, and True otherwise\n",
    "- `token_to_orig_map`: Maps the tokens in `tokens` and `input_ids` to the actual token indices in the original document\n",
    "- `tokens`: A list of tokens making up the document span\n",
    "- `unique_id`: A unique id number for this article (NOT this document span) \n",
    "\n",
    "*Note - mappings are 0 indexed and exlude tokens that are part of the question (those can be identified from segment ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bert_baseline\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BertModel)                ((None, 1024), (None 335141888   input_ids[0][0]                  \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "td_seq (TDense)                 (None, 384, 2)       2050        bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split (TensorFlowOp [(None, 384, 1), (No 0           td_seq[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_start_logits (Tenso [(None, 384)]        0           tf_op_layer_split[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_end_logits (TensorF [(None, 384)]        0           tf_op_layer_split[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "ans_type_logits (TDense)        (None, 5)            5125        bert[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 335,149,063\n",
      "Trainable params: 335,149,063\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(model_name=FLAGS.model,\n",
    "                    config_file=FLAGS.config_file,\n",
    "                    max_seq_length=FLAGS.max_seq_length,\n",
    "                    init_ckpt=FLAGS.init_checkpoint)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = np.ceil(eval_writer.num_features / FLAGS.predict_batch_size)\n",
    "generator = data_generator(eval_filename, FLAGS.predict_batch_size)\n",
    "\n",
    "preds = model.predict_generator(generator, steps=n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejmejm/anaconda3/envs/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:147: UserWarning: Original to document index mapping could not be resolved!\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    'ans_type_conf_weight': 0.4,\n",
    "    'start_pos_conf_weight': 0.3,\n",
    "    'end_pos_conf_weight': 0.3,\n",
    "    'conf_bias': 0.0,\n",
    "    'conf_threshold': 0.97\n",
    "}\n",
    "\n",
    "\n",
    "id_to_example = {}\n",
    "for example in eval_examples:\n",
    "    id_to_example[example.example_id] = example\n",
    "\n",
    "answers = compute_answers(preds, candidates_dict, eval_features, eval_examples, id_to_example, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Micro-F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.5315068493150685\n",
      "Recall: 0.9238095238095239\n",
      "Precision: 0.3730769230769231\n",
      "{'TP': 97, 'FP': 163, 'FN': 8, 'FP_WA': 56, 'FP_NA': 107}\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.test_post_processing:\n",
    "    micro_f1, recall, precision, details = score_preds(actual_answers, answers)\n",
    "\n",
    "    print(f'Micro F1 Score: {micro_f1}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('TP = 95   FP = 165   FN = 7   TN = 133   F1 = 0.52',\n",
       " 'TP = 62   FP = 90   FN = 4   TN = 44   F1 = 0.57',\n",
       " 'TP = 33   FP = 75   FN = 3   TN = 89   F1 = 0.46')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_preds_2(raw_examples, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search to Select the Best Parameters for Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    default_range = np.arange(0, 1.05, 0.5)\n",
    "\n",
    "    weight_ranges = OrderedDict({\n",
    "            'ans_type_conf_weight': [0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "            'start_pos_conf_weight': [0, 0.25, 0.5, 0.75, 1.0],\n",
    "            'end_pos_conf_weight': [0, 0.25, 0.5, 0.75, 1.0],\n",
    "            'conf_bias': [-0.5, -0.25, 0, 0.25, 0.5],\n",
    "            'conf_threshold': [0.5]\n",
    "        })\n",
    "\n",
    "    combinations = list(itertools.product(*[weight_ranges[k] for k in weight_ranges.keys()]))\n",
    "\n",
    "    actual_answers = get_actual_answers(FLAGS.train_file, FLAGS.n_examples)\n",
    "\n",
    "    results = {}\n",
    "    for weight_vals in tqdm.tqdm(combinations):\n",
    "        weights = {}\n",
    "        for weight_name, weight_val in zip(weight_ranges.keys(), weight_vals):\n",
    "                weights[weight_name] = weight_val\n",
    "\n",
    "        tmp_answers = compute_answers(preds, candidates_dict, eval_features, weights)\n",
    "        micro_f1, recall, precision, _ = score_preds(actual_answers, tmp_answers)\n",
    "        results[weight_vals] = (micro_f1, recall, precision)\n",
    "        \n",
    "    sr = sorted(results.items(), key=lambda x: x[1][0], reverse=True)\n",
    "    print(sr[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to explore (WIP)\n",
    "- Can we accurately order the answers in terms of confidence?\n",
    "- Is a series of segments all with answers a good predictor for an actual answer in that block?\n",
    "- What does the general spread of probabilities look like when there is an answer?\n",
    "- What about the spread of probabilities when there is no answer?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- If 1, 2, and 3 are in a row, choose the middle one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_range(first, second):\n",
    "    return first[0] >= second[0] and first[1] <= second[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 5  3 15 12  0  2  1  0  0  6  0 14 11  0 10  0  0  0  0  9 13  8  7  4\n",
      "  0  0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 0 2 1 0 5 0 6 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 3 2 7 6 8 9 0 5 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 2 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 0 4 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 2 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  9  0  0  0  0  0\n",
      "  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  1  2  0  0  0\n",
      "  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  8  4  5]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 4 3 0 0]\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[ 1  0  7  5  0  6  8 10  0  3  4  2  0 11  9  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0  2  5  4 12  0  0  0  0  0  0  0  0 10  8  9  0  0  0  0  0  0  0  0\n",
      "  0  0  0  1  3  0  0  0  0  0  0  6  7 11  0  0  0  0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 4 2 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 5 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 4 0 3 0 5 2 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3]\n",
      "[0 0 0]\n",
      "\n",
      "[1 2 0]\n",
      "[0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 3 1 4 0 5 2 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3 4 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 0  2  1  5 10  0  0 11  0  0  9  6  8  3  4  7  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 3 0 0 0 0 0 0 2 6 4 5 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 2 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n",
      "\n",
      "[4 3 2 1 0 0 6 5 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "\n",
      "[0 5 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "\n",
      "[0 0 0 4 6 5 3 1 2 0 0]\n",
      "[0 0 0 0 0 0 0 1 1 0 0]\n",
      "\n",
      "[6 4 5 7 1 3 2 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1]\n",
      "[1]\n",
      "\n",
      "[0 0 0 0 2 3 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 3 0 0 0 0 0 4 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 3 4 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 4 0 3 1 2 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 3 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3 0 0 0]\n",
      "[0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 0 0 0]\n",
      "[0 1 0 0 0]\n",
      "\n",
      "[2 1 0 0]\n",
      "[0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 3 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "\n",
      "[1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0]\n",
      "[1 0]\n",
      "\n",
      "[0 2 0 1 0]\n",
      "[0 0 0 0 0]\n",
      "\n",
      "[0 0 2 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[4 2 1 3 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 5 0 4 2 1 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 2 0 1 0 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 1 2 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 1 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 3 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 2 1 0 0 0 0 0 0 0 5 4 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "\n",
      "[4 1 2 3 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 6 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0]\n",
      "\n",
      "[3 0 0 1 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 2 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 4 0 0 0 0 0 5 3 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 4 0 0 2 1 3 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 5 4 0 7 6 3 2 1 0 8 0 0 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1]\n",
      "[0]\n",
      "\n",
      "[2 1 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "\n",
      "[3 2 1 8 7 6 5 4 0 0]\n",
      "[0 1 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 2 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[4 1 5 3 2 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[3 1 0 0 0 0 0 0 0 0 2 0 4 0 0 0 0 0 0 5]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 2 1 0]\n",
      "[0 0 0 0 0]\n",
      "\n",
      "[5 1 2 3 4 0 0 0 0]\n",
      "[0 0 1 1 0 0 0 0 0]\n",
      "\n",
      "[1 3 4 2 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 3 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 4 0 0 0 0]\n",
      "[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 4 3 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0]\n",
      "[1 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 2 3 1 0 0 0 0 4 5 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 7 3 4 2 5 0 0 0 6 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 6  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8 13 12  0 14 10\n",
      "  0  5  1  2  0  9 11  7  0  0  0  0  0  0  0  0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 0 0 3 2 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 2 1 0 0 0 0 0 0]\n",
      "[0 1 1 0 0 0 0 0 0]\n",
      "\n",
      "[ 0  0  0  0  0  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  6  5  0  0  4  2  0  8\n",
      "  0  0  0 10  7  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 4 2 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 3 0 0 0 0 0 0 1 2 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 5 0 3 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 4 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[5 4 1 2 0 3 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 4 3 1 0 0 0 2]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 0 0 0 0]\n",
      "[1 1 0 0 0 0]\n",
      "\n",
      "[1 2 0 0]\n",
      "[0 0 0 0]\n",
      "\n",
      "[ 1  3  4  5  0  0  8  0  7  0  0  0  9  2  0  0  0  0  0  0 10  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  6]\n",
      "[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[3 2 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 2 0]\n",
      "[0 0 0 0 0 0 0]\n",
      "\n",
      "[6 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 4 3 5 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1]\n",
      "[1]\n",
      "\n",
      "[0 0 3 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 2 3 1 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 7 5 0 0 0 0 0 3\n",
      " 2 1 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 1 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 3 0 4]\n",
      "[0 0 0 0 0]\n",
      "\n",
      "[2 1 0]\n",
      "[1 1 0]\n",
      "\n",
      "[2 1 0 0 0 0]\n",
      "[1 1 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 1 4 2 3 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[3 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[1 0 2 0 3 0 4 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 0 1 0]\n",
      "[0 0 0 0]\n",
      "\n",
      "[1 5 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 3\n",
      " 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "[1 2]\n",
      "[1 0]\n",
      "\n",
      "[0 3 0 0 0 0 0 0 4 2 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 1 1 0]\n",
      "\n",
      "[1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[ 5  4  2  9  1  3  6  7 12  8 13 10  0  0  0  0  0 11  0  0  0  0  0  0\n",
      "  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 6 5 7 2 4 3 8 0]\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 4 5 6 3 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[1 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Avg # features per example: 20.135\n"
     ]
    }
   ],
   "source": [
    "avg_n_features = 0\n",
    "ordering_reg_data = [] # (predicted rank of answer, whether there actually is answer at that feature)\n",
    "n_preds_data = [] # (percent of features that predict an answer, whether there is actually an answer)\n",
    "\n",
    "for example_id in answers.keys():\n",
    "    pred_answer = answers[example_id]\n",
    "    actual_answer = actual_answers[example_id]\n",
    "    \n",
    "    if not pred_answer['ordered_entries']:\n",
    "        continue\n",
    "    \n",
    "    avg_n_features += id_to_example[example_id].n_features\n",
    "    entries_pred = np.zeros(id_to_example[example_id].n_features, dtype=np.int32)\n",
    "    actual_oh = np.zeros(id_to_example[example_id].n_features, dtype=np.int32)\n",
    "    for entry_idx, entry in enumerate(pred_answer['ordered_entries']):\n",
    "        feature = entry['feature']\n",
    "        entries_pred[feature.doc_span_index] = entry_idx + 1\n",
    "        \n",
    "        tok_to_orig_map = entry['feature'].token_to_orig_map\n",
    "        feature_min_idx = min(tok_to_orig_map.values(), key=lambda x: x if x != -1 else 99999)\n",
    "        feature_max_idx = max(tok_to_orig_map.values())\n",
    "        target_answers = actual_answer['long_answers']\n",
    "        if isinstance(actual_answer['short_answers'], tuple):\n",
    "            target_answers = actual_answer['short_answers']\n",
    "        if target_answers:\n",
    "            for tgt in target_answers:\n",
    "                if in_range(tgt, (feature_min_idx, feature_max_idx)):\n",
    "                    actual_oh[feature.doc_span_index] = 1\n",
    "                    break\n",
    "     \n",
    "    percent_preds = len(pred_answer['ordered_entries']) / id_to_example[example_id].n_features\n",
    "    exists_answer = int(1 in actual_oh)\n",
    "    n_preds_data.append((percent_preds, exists_answer))\n",
    "    \n",
    "    for x, y in zip(entries_pred, actual_oh):\n",
    "        if x != 0 or y != 0:\n",
    "            ordering_reg_data.append((x, y))\n",
    "    \n",
    "    print(entries_pred)\n",
    "    print(actual_oh)\n",
    "    print()\n",
    "\n",
    "print('Avg # features per example:', avg_n_features / len(answers.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9e6063a190>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot([x[0] for x in ordering_reg_data], [x[1] for x in ordering_reg_data], s=100, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9e60572050>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot([x[0] for x in n_preds_data], [x[1] for x in n_preds_data], s=100, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features for the Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Examples (2): 152\n",
      "# Features (2): 473\n",
      "**Features**\n",
      "\n",
      "answer_text\n",
      "answer_type\n",
      "doc_span_index\n",
      "end_position\n",
      "example_index\n",
      "input_ids\n",
      "input_mask\n",
      "segment_ids\n",
      "start_position\n",
      "token_is_max_context\n",
      "token_to_orig_map\n",
      "tokens\n",
      "unique_id\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.do_predict:\n",
    "    if FLAGS.second_model == 'bert':\n",
    "        tokenizer_2 = bert_tokenization.FullTokenizer(\n",
    "            vocab_file=FLAGS.second_vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
    "    elif FLAGS.second_model == 'albert':\n",
    "        tokenizer_2 = albert_tokenization.FullTokenizer(\n",
    "            None, spm_model_file=FLAGS.second_vocab_file)\n",
    "\n",
    "    if FLAGS.test_post_processing:\n",
    "        input_file = FLAGS.train_file\n",
    "    else:\n",
    "        input_file = FLAGS.predict_file\n",
    "\n",
    "    eval_writer_2 = tf2baseline.FeatureWriter(\n",
    "      filename=os.path.join(FLAGS.output_dir, \"eval_2.tf_record\"),\n",
    "      is_training=FLAGS.test_post_processing)\n",
    "    eval_features_2 = []\n",
    "    \n",
    "    def append_feature_2(feature):\n",
    "        eval_features_2.append(feature)\n",
    "        eval_writer_2.process_feature(feature)\n",
    "    \n",
    "    # Limit examples to only those that are not unknown answers\n",
    "    eval_examples_2 = [example for example in eval_examples if answers[example.example_id]['long_answer']]\n",
    "\n",
    "    for target_rank in range(8):\n",
    "        # Get the document token index ranges of the desired answers\n",
    "        n_extra_tokens = 30\n",
    "        answer_ranges = []\n",
    "        curr_examples = []\n",
    "        for example in eval_examples_2:\n",
    "            answer = answers[example.example_id]\n",
    "            if target_rank >= len(answer['ordered_entries']):\n",
    "                continue\n",
    "            entry = answer['ordered_entries'][target_rank]\n",
    "\n",
    "            doc_start_idx = entry['doc_tokens_start_idx']\n",
    "            doc_end_idx = entry['doc_tokens_end_idx']\n",
    "\n",
    "            answer_ranges.append((max(0, doc_start_idx - n_extra_tokens),\n",
    "                                  min(len(example.doc_tokens), doc_end_idx + n_extra_tokens)))\n",
    "            \n",
    "            curr_examples.append(example)\n",
    "\n",
    "        convert_partial_examples_to_features(\n",
    "            examples=eval_examples_2,\n",
    "            ranges=answer_ranges,\n",
    "            tokenizer=tokenizer_2,\n",
    "            is_training=FLAGS.test_post_processing,\n",
    "            output_fn=append_feature_2)\n",
    "\n",
    "    eval_writer_2.close()\n",
    "    eval_filename_2 = eval_writer_2.filename\n",
    "\n",
    "    print('# Examples (2):', len(eval_examples_2))\n",
    "    print('# Features (2):', len(eval_features_2))\n",
    "\n",
    "    print('**Features**\\n')\n",
    "\n",
    "    for e in dir(eval_features_2[0]):\n",
    "        if not e.startswith('__'):\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"albert\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "albert_model (AlbertModel)      ((None, 4096), (None 222622336   input_ids[0][0]                  \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "td_seq (TDense)                 (None, 384, 2)       8194        albert_model[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split (TensorFlowOp [(None, 384, 1), (No 0           td_seq[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_start_logits (Tenso [(None, 384)]        0           tf_op_layer_split[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_end_logits (TensorF [(None, 384)]        0           tf_op_layer_split[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "ans_type_logits (TDense)        (None, 5)            20485       albert_model[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 222,651,015\n",
      "Trainable params: 222,651,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = build_model(model_name=FLAGS.second_model,\n",
    "                    config_file=FLAGS.second_config_file,\n",
    "                    max_seq_length=FLAGS.second_max_seq_length,\n",
    "                    init_ckpt=FLAGS.second_init_checkpoint)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Predictions with the Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = np.ceil(eval_writer_2.num_features / FLAGS.second_batch_size)\n",
    "generator = data_generator(eval_filename_2, FLAGS.second_batch_size)\n",
    "\n",
    "preds_2 = model.predict(generator, steps=n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute New Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.662379421221865\n",
      "Recall: 0.824\n",
      "Precision: 0.553763440860215\n",
      "{'TP': 103, 'FP': 83, 'FN': 22, 'FP_WA': 36, 'FP_NA': 47}\n",
      "\n",
      "TP = 101   FP = 85   FN = 21   TN = 193   F1 = 0.66\n",
      "TP = 60   FP = 45   FN = 15   TN = 80   F1 = 0.67\n",
      "TP = 41   FP = 40   FN = 6   TN = 113   F1 = 0.64\n"
     ]
    }
   ],
   "source": [
    "invalid_input_ids_2 = tokenizer_2.convert_tokens_to_ids(['[Q]', '[SEP]', '[CLS]', '[PAD]'])\n",
    "\n",
    "weights_2 = {\n",
    "    'ans_type_conf_weight': 0.6,\n",
    "    'start_pos_conf_weight': 0.3,\n",
    "    'end_pos_conf_weight': 0.1,\n",
    "    'conf_bias': 0.0,\n",
    "    'conf_threshold': 0.8\n",
    "}\n",
    "\n",
    "second_answers = compute_answers(preds_2, \n",
    "                                 candidates_dict, \n",
    "                                 eval_features_2, \n",
    "                                 eval_examples_2, \n",
    "                                 id_to_example,\n",
    "                                 weights=weights_2,\n",
    "                                invalid_input_ids=invalid_input_ids_2)\n",
    "\n",
    "final_answers = copy.copy(answers)\n",
    "final_answers.update(second_answers)\n",
    "\n",
    "if FLAGS.test_post_processing:\n",
    "#     actual_answers = get_actual_answers(FLAGS.train_file, FLAGS.n_examples)\n",
    "    micro_f1, recall, precision, details = score_preds(actual_answers, final_answers)\n",
    "\n",
    "    print(f'Micro F1 Score: {micro_f1}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(details)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    for x in score_preds_2(raw_examples, final_answers):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'long_answer': (2861, 2943), 'short_answer': (2893, 2906)},\n",
       " {'long_answer': (176, 245), 'short_answer': (238, 240)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (75, 186), 'short_answer': (85, 86)},\n",
       " {'long_answer': (946, 1147), 'short_answer': (972, 973)},\n",
       " {'long_answer': (83, 406), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (323, 379), 'short_answer': (360, 364)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (603, 655), 'short_answer': (651, 653)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (723, 827), 'short_answer': (739, 740)},\n",
       " {'long_answer': (3524, 3608), 'short_answer': (3534, 3535)},\n",
       " {'long_answer': (66, 155), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (245, 335), 'short_answer': (246, 249)},\n",
       " {'long_answer': (1338, 1485), 'short_answer': None},\n",
       " {'long_answer': (516, 600), 'short_answer': (597, 598)},\n",
       " {'long_answer': (191, 392), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (620, 670), 'short_answer': (645, 647)},\n",
       " {'long_answer': (484, 545), 'short_answer': (508, 510)},\n",
       " {'long_answer': (113, 168), 'short_answer': (153, 155)},\n",
       " {'long_answer': (584, 704), 'short_answer': (682, 684)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (594, 699), 'short_answer': (636, 637)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (755, 831), 'short_answer': (783, 796)},\n",
       " {'long_answer': (1032, 1138), 'short_answer': (1042, 1058)},\n",
       " {'long_answer': (195, 282), 'short_answer': (270, 271)},\n",
       " {'long_answer': (1089, 1451), 'short_answer': (1292, 1295)},\n",
       " {'long_answer': (203, 271), 'short_answer': None},\n",
       " {'long_answer': (468, 627), 'short_answer': (588, 594)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (787, 967), 'short_answer': (799, 802)},\n",
       " {'long_answer': (122, 281), 'short_answer': (123, 127)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (729, 857), 'short_answer': (733, 737)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (505, 621), 'short_answer': (529, 542)},\n",
       " {'long_answer': (1080, 1137), 'short_answer': (1123, 1125)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (49, 177), 'short_answer': (62, 63)},\n",
       " {'long_answer': (99, 313), 'short_answer': (110, 112)},\n",
       " {'long_answer': (167, 214), 'short_answer': (193, 195)},\n",
       " {'long_answer': (97, 176), 'short_answer': (102, 103)},\n",
       " {'long_answer': (1225, 1285), 'short_answer': None},\n",
       " {'long_answer': (749, 883), 'short_answer': (821, 822)},\n",
       " {'long_answer': (617, 836), 'short_answer': (618, 621)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (905, 1007), 'short_answer': (952, 956)},\n",
       " {'long_answer': (1532, 1661), 'short_answer': None},\n",
       " {'long_answer': (524, 604), 'short_answer': (527, 530)},\n",
       " {'long_answer': (198, 3038), 'short_answer': (245, 247)},\n",
       " {'long_answer': (809, 940), 'short_answer': 'YES'},\n",
       " {'long_answer': (1533, 1821), 'short_answer': (1779, 1780)},\n",
       " {'long_answer': (379, 463), 'short_answer': (421, 422)},\n",
       " {'long_answer': (255, 326), 'short_answer': 'YES'},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (586, 730), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (105, 216), 'short_answer': (174, 175)},\n",
       " {'long_answer': (1363, 2023), 'short_answer': (1995, 2007)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (406, 699), 'short_answer': (435, 447)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (250, 352), 'short_answer': (263, 269)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (933, 1041), 'short_answer': (994, 995)},\n",
       " {'long_answer': (1726, 1765), 'short_answer': (1727, 1738)},\n",
       " {'long_answer': (284, 296), 'short_answer': (293, 294)},\n",
       " {'long_answer': (980, 1084), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (16, 562), 'short_answer': (343, 344)},\n",
       " {'long_answer': (205, 264), 'short_answer': (214, 217)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (616, 693), 'short_answer': (627, 629)},\n",
       " {'long_answer': (628, 699), 'short_answer': (643, 654)},\n",
       " {'long_answer': (240, 364), 'short_answer': (241, 244)},\n",
       " {'long_answer': (634, 759), 'short_answer': (643, 653)},\n",
       " {'long_answer': (91, 194), 'short_answer': None},\n",
       " {'long_answer': (96, 199), 'short_answer': (97, 99)},\n",
       " {'long_answer': (1734, 2056), 'short_answer': (1744, 1746)},\n",
       " {'long_answer': (38, 103), 'short_answer': (90, 96)},\n",
       " {'long_answer': (3474, 3512), 'short_answer': (3489, 3493)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (1645, 1738), 'short_answer': (1695, 1696)},\n",
       " {'long_answer': (584, 853), 'short_answer': None},\n",
       " {'long_answer': (347, 438), 'short_answer': (431, 437)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (985, 1049), 'short_answer': (1035, 1041)},\n",
       " {'long_answer': (900, 1020), 'short_answer': None},\n",
       " {'long_answer': (208, 247), 'short_answer': (225, 229)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (32, 136), 'short_answer': (45, 47)},\n",
       " {'long_answer': (2214, 2761), 'short_answer': (2233, 2236)},\n",
       " {'long_answer': (442, 489), 'short_answer': None},\n",
       " {'long_answer': (65, 730), 'short_answer': (429, 432)},\n",
       " {'long_answer': (882, 1021), 'short_answer': None},\n",
       " {'long_answer': (584, 769), 'short_answer': None},\n",
       " {'long_answer': (209, 286), 'short_answer': (229, 239)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (573, 780), 'short_answer': (574, 602)},\n",
       " {'long_answer': (251, 373), 'short_answer': (258, 259)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (366, 633), 'short_answer': (383, 384)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (229, 532), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (83, 159), 'short_answer': (91, 93)},\n",
       " {'long_answer': (434, 608), 'short_answer': (444, 445)},\n",
       " {'long_answer': (248, 329), 'short_answer': None},\n",
       " {'long_answer': (801, 943), 'short_answer': None},\n",
       " {'long_answer': (898, 931), 'short_answer': (925, 929)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (5132, 5221), 'short_answer': (5181, 5184)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (270, 417), 'short_answer': None},\n",
       " {'long_answer': (305, 470), 'short_answer': (355, 358)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (260, 369), 'short_answer': (287, 289)},\n",
       " {'long_answer': (259, 373), 'short_answer': (260, 262)},\n",
       " {'long_answer': (314, 551), 'short_answer': None},\n",
       " {'long_answer': (523, 636), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (1628, 1797), 'short_answer': (1653, 1654)},\n",
       " {'long_answer': (370, 474), 'short_answer': (372, 374)},\n",
       " {'long_answer': (69, 110), 'short_answer': (91, 94)},\n",
       " {'long_answer': (411, 518), 'short_answer': None},\n",
       " {'long_answer': (300, 495), 'short_answer': None},\n",
       " {'long_answer': (75, 113), 'short_answer': (76, 80)},\n",
       " {'long_answer': (1542, 1839), 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (788, 846), 'short_answer': (838, 840)},\n",
       " {'long_answer': (141, 219), 'short_answer': (209, 210)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (281, 383), 'short_answer': (312, 315)},\n",
       " {'long_answer': None, 'short_answer': None},\n",
       " {'long_answer': (3520, 3626), 'short_answer': (3583, 3599)}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{k: v for k, v in a.items() if k in ('short_answer', 'long_answer')} for a in second_answers.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has answer percent: 67.11%\n",
      "Long answer agreement: 83.33%\n",
      "Short answer agreement: 60.76%\n"
     ]
    }
   ],
   "source": [
    "simple_answers = [{k: v for k, v in a.items() if k in ('short_answer', 'long_answer')} \\\n",
    "    for a in second_answers.values()]\n",
    "\n",
    "has_ans_perc = sum([1 for a in simple_answers if a['long_answer']]) / len(simple_answers)\n",
    "print('Has answer percent: {:.2f}%'.format(has_ans_perc * 100))\n",
    "\n",
    "n_la = 0\n",
    "n_sa = 0\n",
    "n_la_matches = 0\n",
    "n_sa_matches = 0\n",
    "for example_id in second_answers.keys():\n",
    "    answer1 = answers[example_id]\n",
    "    answer2 = second_answers[example_id]\n",
    "    if answer2['long_answer']:\n",
    "        n_la += 1\n",
    "        if answer1['long_answer'] == answer2['long_answer']:\n",
    "            n_la_matches += 1\n",
    "            \n",
    "    if answer2['short_answer']:\n",
    "        n_sa += 1\n",
    "        if answer1['short_answer'] == answer2['short_answer']:\n",
    "            n_sa_matches += 1\n",
    "            \n",
    "print('Long answer agreement: {:.2f}%'.format(n_la_matches/n_la * 100))\n",
    "print('Short answer agreement: {:.2f}%'.format(n_sa_matches/n_sa * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.6179401993355482\n",
      "Recall: 0.775\n",
      "Precision: 0.5138121546961326\n",
      "{'TP': 93, 'FP': 88, 'FN': 27, 'FP_WA': 41, 'FP_NA': 47}\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.test_post_processing:\n",
    "    actual_answers = get_actual_answers(FLAGS.train_file, FLAGS.n_examples)\n",
    "    micro_f1, recall, precision, details = score_preds(actual_answers, final_answers)\n",
    "\n",
    "    print(f'Micro F1 Score: {micro_f1}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search for Postprocessing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    weight_ranges = OrderedDict({\n",
    "            'ans_type_conf_weight': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7],\n",
    "            'start_pos_conf_weight': [-0.1, 0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "            'end_pos_conf_weight': [-0.1, 0.0, 0.1, 0.2, 0.3, 0.4],\n",
    "            'conf_bias': [-0.2, -0.1, 0, 0.1, 0.2],\n",
    "            'conf_threshold': [0.5]\n",
    "        })\n",
    "\n",
    "    combinations = list(itertools.product(*[weight_ranges[k] for k in weight_ranges.keys()]))\n",
    "\n",
    "    actual_answers = get_actual_answers(FLAGS.train_file, FLAGS.n_examples)\n",
    "\n",
    "    results = {}\n",
    "    for weight_vals in tqdm.tqdm(combinations):\n",
    "        weights_2 = {}\n",
    "        for weight_name, weight_val in zip(weight_ranges.keys(), weight_vals):\n",
    "                weights_2[weight_name] = weight_val\n",
    "                \n",
    "        tmp_answers = compute_answers(preds_2, \n",
    "                                      candidates_dict, \n",
    "                                      eval_features_2, \n",
    "                                      eval_examples_2, \n",
    "                                      id_to_example,\n",
    "                                      weights=weights_2,\n",
    "                                      invalid_input_ids=invalid_input_ids_2)\n",
    "        tmp_final_answers = copy.copy(answers)\n",
    "        tmp_final_answers.update(tmp_answers)\n",
    "        \n",
    "        micro_f1, recall, precision, _ = score_preds(actual_answers, tmp_final_answers)\n",
    "        results[weight_vals] = (micro_f1, recall, precision)\n",
    "        \n",
    "    sr = sorted(results.items(), key=lambda x: x[1][0], reverse=True)\n",
    "    print(sr[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Joint Baseline\n",
    "    - F1: 0.564\n",
    "    - Recall: 0.850\n",
    "    - Precision: 0.422\n",
    "    \n",
    "    On 2000 dev examples:\n",
    "    - F1: 0.524\n",
    "    \n",
    "### BERT Joint + ALBERT Finetuned\n",
    "    - F1: 0.628\n",
    "    - Recall: 0.667\n",
    "    - Precision: 0.593\n",
    "    \n",
    "    On 2000 dev examples:\n",
    "    \n",
    "    'ans_type_conf_weight': 0.6,\n",
    "    'start_pos_conf_weight': 0.3,\n",
    "    'end_pos_conf_weight': 0.1,\n",
    "    'conf_bias': 0.0,\n",
    "    'conf_threshold': 0.8\n",
    "        \n",
    "    - F1: 0.613\n",
    "    \n",
    "### ALBERT Finetuned\n",
    "    - F1: 0.791\n",
    "    - Recall: 0.895\n",
    "    - Precision: 0.708"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Create a Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(answers):\n",
    "    submission_data = []\n",
    "\n",
    "    # Loop through answers in alphabetic order of example_ids\n",
    "    # This is how it's sorted in the sample submission\n",
    "    for example_id, answer in sorted(answers.items(), key=lambda x: x[0]):\n",
    "        long_answer_text = ''\n",
    "        if isinstance(answer['long_answer'], tuple):\n",
    "            long_answer_text = f'{answer[\"long_answer\"][0]}:{answer[\"long_answer\"][1]}'\n",
    "        else:\n",
    "            assert answer['long_answer'] is None, 'Invalid type of long answer!'\n",
    "            assert answer['short_answer'] is None, 'Cannot have a short answer with no long answer!'\n",
    "        long_answer_row = [f'{example_id}_long', long_answer_text]\n",
    "\n",
    "        short_answer_text = ''\n",
    "        if isinstance(answer['short_answer'], tuple):\n",
    "            short_answer_text = f'{answer[\"short_answer\"][0]}:{answer[\"short_answer\"][1]}'\n",
    "        elif answer['short_answer'] in ('YES', 'NO'):\n",
    "            short_answer_text = answer['short_answer']\n",
    "        else:\n",
    "            assert answer['short_answer'] is None, 'Invalid type of short answer!'\n",
    "        short_answer_row = [f'{example_id}_short', short_answer_text]\n",
    "\n",
    "        submission_data.append(long_answer_row)\n",
    "        submission_data.append(short_answer_row)\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_data, columns=['example_id', 'PredictionString'])\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Save the Submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FLAGS.test_post_processing:\n",
    "    submission_df = create_submission(answers)\n",
    "    print(submission_df.head())\n",
    "    submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
