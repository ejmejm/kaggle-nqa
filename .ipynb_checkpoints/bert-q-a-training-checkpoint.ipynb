{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Q&A Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF 2.0 Baseline Loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# import tf2_0_baseline_w_bert as tf2baseline # old script\n",
    "from scripts import tf2_0_baseline_w_bert_translated_to_tf2_0 as tf2baseline # Oliviera's script\n",
    "from scripts import bert_modeling as modeling\n",
    "from scripts import bert_optimization as optimization\n",
    "from scripts import bert_tokenization as tokenization\n",
    "import tqdm\n",
    "import json\n",
    "import absl\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "tf2baseline.FLAGS.include_unknowns = 1./3.\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ejmejm/anaconda3/envs/tf2/lib/python3.7/site-packages/ipykernel_launcher.py']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()\n",
    "    keys_list = [keys for keys in flags_dict]\n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(absl.flags.FLAGS)\n",
    "\n",
    "flags = absl.flags\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"bert_config_file\", \"/kaggle/input/bertjointbaseline/bert_config.json\",\n",
    "    \"The config json file corresponding to the pre-trained BERT model. \"\n",
    "    \"This specifies the model architecture.\")\n",
    "\n",
    "flags.DEFINE_string(\"vocab_file\", \"./data/vocab-nq.txt\",\n",
    "                    \"The vocabulary file that the BERT model was trained on.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"output_dir\", \"./output/\",\n",
    "    \"The output directory where the model checkpoints will be written.\")\n",
    "\n",
    "flags.DEFINE_string(\"train_precomputed_file\", \"/kaggle/input/qa-train-record/train.tf_record\",\n",
    "                    \"Precomputed tf records for training.\")\n",
    "\n",
    "flags.DEFINE_integer(\"train_num_precomputed\", 6000,\n",
    "                     \"Number of precomputed tf records for training.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"output_prediction_file\", \"tf2_bert_finetuned.ckpt\",\n",
    "    \"Where to save finetuned checkpoints to.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"output_ckeckpoint\", \"predictions.json\",\n",
    "    \"Where to print predictions in NQ prediction format, to be passed to\"\n",
    "    \"natural_questions.nq_eval.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"log_dir\", \"/kaggle/working/logs/\",\n",
    "    \"Where logs, specifically Tensorboard logs, will be saved to.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"init_checkpoint\", \"/kaggle/input/bert-q-a-convert-weights-to-2-0/tf2_bert_joint.ckpt\",\n",
    "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"do_lower_case\", True,\n",
    "    \"Whether to lower case the input text. Should be True for uncased \"\n",
    "    \"models and False for cased models.\")\n",
    "\n",
    "# This should be changed to 512 at some point,\n",
    "# as training was done with that value, it may\n",
    "# not make a big difference though\n",
    "flags.DEFINE_integer(\n",
    "    \"max_seq_length\", 384,\n",
    "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
    "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
    "    \"than this will be padded.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"doc_stride\", 128,\n",
    "    \"When splitting up a long document into chunks, how much stride to \"\n",
    "    \"take between chunks.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_query_length\", 64,\n",
    "    \"The maximum number of tokens for the question. Questions longer than \"\n",
    "    \"this will be truncated to this length.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_train\", True, \"Whether to run training.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_predict\", False, \"Whether to run eval on the dev set.\")\n",
    "\n",
    "flags.DEFINE_integer(\"train_batch_size\", 2, \"Total batch size for training.\")\n",
    "\n",
    "flags.DEFINE_integer(\"predict_batch_size\", 8,\n",
    "                     \"Total batch size for predictions.\")\n",
    "\n",
    "flags.DEFINE_float(\"learning_rate\", 5e-5, \"The initial learning rate for Adam.\")\n",
    "\n",
    "flags.DEFINE_integer(\"num_train_epochs\", 3,\n",
    "                   \"Total number of training epochs to perform.\")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"warmup_proportion\", 0.1,\n",
    "    \"Proportion of training to perform linear learning rate warmup for. \"\n",
    "    \"E.g., 0.1 = 10% of training.\")\n",
    "\n",
    "flags.DEFINE_integer(\"save_checkpoints_steps\", 1000,\n",
    "                     \"How often to save the model checkpoint.\")\n",
    "\n",
    "flags.DEFINE_integer(\"iterations_per_loop\", 1000,\n",
    "                     \"How many steps to make in each estimator call.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"n_best_size\", 20,\n",
    "    \"The total number of n-best predictions to generate in the \"\n",
    "    \"nbest_predictions.json output file.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"verbosity\", 1, \"How verbose our error messages should be\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_answer_length\", 30,\n",
    "    \"The maximum length of an answer that can be generated. This is needed \"\n",
    "    \"because the start and end predictions are not conditioned on one another.\")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"include_unknowns\", 1./3.,\n",
    "    \"If positive, probability of including answers of type `UNKNOWN`.\")\n",
    "\n",
    "flags.DEFINE_bool(\"use_tpu\", False, \"Whether to use TPU or GPU/CPU.\")\n",
    "\n",
    "flags.DEFINE_bool(\"use_one_hot_embeddings\", False, \"Whether to use use_one_hot_embeddings\")\n",
    "\n",
    "absl.flags.DEFINE_string(\n",
    "    \"gcp_project\", None,\n",
    "    \"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n",
    "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
    "    \"metadata.\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"verbose_logging\", False,\n",
    "    \"If true, all of the warnings related to data processing will be printed. \"\n",
    "    \"A number of warnings are expected for a normal NQ evaluation.\")\n",
    "\n",
    "flags.DEFINE_boolean(\n",
    "    \"skip_nested_contexts\", True,\n",
    "    \"Completely ignore context that are not top level nodes in the page.\")\n",
    "\n",
    "flags.DEFINE_integer(\"task_id\", 0,\n",
    "                     \"Train and dev shard to read from and write to.\")\n",
    "\n",
    "flags.DEFINE_integer(\"max_contexts\", 48,\n",
    "                     \"Maximum number of contexts to output for an example.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_position\", 50,\n",
    "    \"Maximum context position for which to generate special tokens.\")\n",
    "\n",
    "## Custom flags\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"n_examples\", -1,\n",
    "    \"Number of examples to read from files. Only applicable during testing\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"train_file\", \"./data/simplified-nq-train.jsonl.zip\",\n",
    "    \"NQ json for training. E.g., dev-v1.1.jsonl.gz or test-v1.1.jsonl.gz\")\n",
    "\n",
    "## Special flags - do not change\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"predict_file\", \"/home/ejmejm/MLProjects/nqa_kaggle/data/simplified-nq-test.jsonl\",\n",
    "    \"NQ json for predictions. E.g., dev-v1.1.jsonl.gz or test-v1.1.jsonl.gz\")\n",
    "flags.DEFINE_boolean(\"logtostderr\", True, \"Logs to stderr\")\n",
    "flags.DEFINE_boolean(\"undefok\", True, \"it's okay to be undefined\")\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_string('HistoryManager.hist_file', '', 'kernel')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS(sys.argv) # Parse the flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Formatted Training Data (TFRecord, Only Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Training Examples: 307373\n"
     ]
    }
   ],
   "source": [
    "def blocks(f, size=65536):\n",
    "    while True:\n",
    "        b = f.read(size)\n",
    "        if not b:\n",
    "            break\n",
    "        yield b\n",
    "    \n",
    "with zipfile.ZipFile(FLAGS.train_file) as zip_file:\n",
    "    with zip_file.open('simplified-nq-train.jsonl', 'r') as f:\n",
    "        n_train_examples = sum([bl.decode('UTF-8').count('\\n') for bl in blocks(f)])\n",
    "\n",
    "print('# Training Examples:', n_train_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(chunk_size=1000):\n",
    "    curr_pos = 0\n",
    "    last_line = False\n",
    "    with zipfile.ZipFile(FLAGS.train_file) as zip_file:\n",
    "        with zip_file.open('simplified-nq-train.jsonl', 'r') as f:\n",
    "            while not last_line:\n",
    "                examples = []\n",
    "                for i in range(curr_pos, curr_pos+chunk_size):\n",
    "                    line = f.readline().decode('UTF-8')\n",
    "                    if line is None:\n",
    "                        last_line = True\n",
    "                        break\n",
    "                    examples.append(tf2baseline.create_example_from_jsonl(line))\n",
    "                    examples[-1] = tf2baseline.read_nq_entry(examples[-1], FLAGS.do_train)[0]\n",
    "                curr_pos = i + 1\n",
    "                yield examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to read all: 4397.849643230438s\n"
     ]
    }
   ],
   "source": [
    "gen = data_generator(500)\n",
    "start_time = time.time()\n",
    "for i in range(4):\n",
    "    next(gen)\n",
    "end_time = time.time()\n",
    "print(f'Time to read all: {(end_time - start_time) * (300000. / 2000.)}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 46/615 [1:28:17<17:20:13, 109.69s/it]"
     ]
    }
   ],
   "source": [
    "chunk_size = 500\n",
    "example_gen = data_generator(chunk_size=chunk_size)\n",
    "\n",
    "train_writer = tf2baseline.FeatureWriter(\n",
    "    filename=os.path.join(FLAGS.output_dir, \"train.tf_record\"),\n",
    "    is_training=FLAGS.do_train)\n",
    "\n",
    "def append_feature(feature):\n",
    "    train_writer.process_feature(feature)\n",
    "\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
    "\n",
    "try:\n",
    "    for i in tqdm.tqdm(range(int(np.ceil(n_train_examples/chunk_size)))):\n",
    "        # If we want to change how the features are generated then this\n",
    "        # is the function\n",
    "        # Right now if an answer is split over 2 blocks, I think the\n",
    "        # end pos of the first is the last token, and the first pos of\n",
    "        # the second is the first token of the respective blocks\n",
    "        num_spans_to_ids = tf2baseline.convert_examples_to_features(\n",
    "            examples=next(example_gen),\n",
    "            tokenizer=tokenizer,\n",
    "            is_training=FLAGS.do_train,\n",
    "            output_fn=append_feature)\n",
    "\n",
    "        train_writer._writer.flush()\n",
    "        with open('output/finished_loop_idx.txt', 'w+') as f:\n",
    "            f.write(str(i))\n",
    "finally:\n",
    "    train_writer.close()\n",
    "    train_filename = train_writer.filename\n",
    "\n",
    "    print(f'# Features written: {train_writer.num_features}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
