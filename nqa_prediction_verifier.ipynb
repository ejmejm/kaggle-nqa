{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NQ&A Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import softmax\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "from scripts import tf2_0_baseline_w_bert_translated_to_tf2_0 as tf2baseline # Oliviera's script\n",
    "from scripts.tf2_0_baseline_w_bert_translated_to_tf2_0 import Answer, AnswerType\n",
    "from scripts import bert_modeling as modeling\n",
    "from scripts import bert_tokenization\n",
    "from scripts import albert\n",
    "from scripts import albert_tokenization\n",
    "\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import json\n",
    "import absl\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_partial_nq_examples(input_file, is_training, n=-1):\n",
    "    \"\"\"Read a NQ json file into a list of NqExample.\"\"\"\n",
    "    input_paths = tf.io.gfile.glob(input_file)\n",
    "    input_data = []\n",
    "\n",
    "    def _open(path):\n",
    "        if path.endswith(\".gz\"):\n",
    "            return gzip.GzipFile(fileobj=tf.io.gfile.GFile(path, \"rb\"))\n",
    "        else:\n",
    "            return tf.io.gfile.GFile(path, \"r\")\n",
    "\n",
    "    for path in input_paths:\n",
    "        absl.logging.info(\"Reading: %s\", path)\n",
    "        with _open(path) as input_file:\n",
    "            for index, line in enumerate(input_file):\n",
    "                if n > -1 and index >= n:\n",
    "                        break\n",
    "                input_data.append(tf2baseline.create_example_from_jsonl(line))\n",
    "\n",
    "    examples = []\n",
    "    for entry in input_data:\n",
    "        examples.extend(tf2baseline.read_nq_entry(entry, is_training))\n",
    "    return examples\n",
    "\n",
    "tf2baseline.read_nq_examples = read_partial_nq_examples\n",
    "\n",
    "def read_partial_candidates_from_one_split(input_path, n=-1):\n",
    "    \"\"\"Read candidates from a single jsonl file.\"\"\"\n",
    "    candidates_dict = {}\n",
    "    if input_path.endswith(\".gz\"):\n",
    "        with gzip.GzipFile(fileobj=tf.io.gfile.GFile(input_path, \"rb\")) as input_file:\n",
    "            absl.logging.info(\"Reading examples from: %s\", input_path)\n",
    "            for index, line in enumerate(input_file):\n",
    "                if n > -1 and index >= n:\n",
    "                        break\n",
    "                \n",
    "                e = json.loads(line)\n",
    "                candidates_dict[e[\"example_id\"]] = e[\"long_answer_candidates\"]\n",
    "    else:\n",
    "        with tf.io.gfile.GFile(input_path, \"r\") as input_file:\n",
    "            absl.logging.info(\"Reading examples from: %s\", input_path)\n",
    "            for index, line in enumerate(input_file):\n",
    "                if n > -1 and index >= n:\n",
    "                        break\n",
    "                        \n",
    "                e = json.loads(line)\n",
    "                candidates_dict[e[\"example_id\"]] = e[\"long_answer_candidates\"]\n",
    "                \n",
    "    return candidates_dict\n",
    "\n",
    "tf2baseline.read_candidates_from_one_split = read_partial_candidates_from_one_split\n",
    "\n",
    "def read_partial_candidates(input_pattern, n=-1):\n",
    "    \"\"\"Read candidates with real multiple processes.\"\"\"\n",
    "    input_paths = tf.io.gfile.glob(input_pattern)\n",
    "    final_dict = {}\n",
    "    for i, input_path in enumerate(input_paths):\n",
    "        final_dict.update(tf2baseline.read_candidates_from_one_split(input_path, n=n-len(final_dict.keys())))\n",
    "        if len(final_dict.keys()) >= n:\n",
    "                break\n",
    "\n",
    "    return final_dict\n",
    "\n",
    "tf2baseline.read_candidates = read_partial_candidates\n",
    "\n",
    "def raw_data_generator(path, chunk_size=1000):\n",
    "        \"\"\"Reads raw JSON examples to a DataFrame\"\"\"\n",
    "        curr_pos = 0\n",
    "        last_line = False\n",
    "        with open(path, 'rt') as f:\n",
    "                while not last_line:\n",
    "                        df = []\n",
    "                        for i in range(curr_pos, curr_pos+chunk_size):\n",
    "                                line = f.readline()\n",
    "                                if line is None:\n",
    "                                        last_line = True\n",
    "                                        break\n",
    "                                df.append(json.loads(line))\n",
    "                        curr_pos = i + 1\n",
    "                        yield pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_all_flags(FLAGS):\n",
    "    flags_dict = FLAGS._flags()\n",
    "    keys_list = [keys for keys in flags_dict]\n",
    "    for keys in keys_list:\n",
    "        FLAGS.__delattr__(keys)\n",
    "\n",
    "del_all_flags(absl.flags.FLAGS)\n",
    "\n",
    "flags = absl.flags\n",
    "\n",
    "### Main Model Flags ###\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"model\", \"bert\",\n",
    "    \"The name of model to use. Choose from ['bert', 'albert'].\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"config_file\", \"models/bert_joint_baseline/bert_config.json\",\n",
    "    \"The config json file corresponding to the pre-trained BERT/ALBERT model. \"\n",
    "    \"This specifies the model architecture.\")\n",
    "\n",
    "flags.DEFINE_string(\"vocab_file\", \"models/bert_joint_baseline/vocab-nq.txt\",\n",
    "                    \"The vocabulary file that the ALBERT/BERT model was trained on.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"init_checkpoint\", \"models/bert_joint_baseline/tf2_bert_joint.ckpt\",\n",
    "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_seq_length\", 384,\n",
    "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
    "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
    "    \"than this will be padded.\")\n",
    "\n",
    "### Verifier Model Flags ###\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"verifier_model\", \"verifier\",\n",
    "    \"The name of model to use. Choose from ['verifier'].\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"verifier_config_file\", \"models/albert_xxl/config.json\",\n",
    "    \"The config json file corresponding to the pre-trained BERT/ALBERT model. \"\n",
    "    \"This specifies the model architecture.\")\n",
    "\n",
    "flags.DEFINE_string(\"verifier_vocab_file\", \"models/albert_xxl/vocab/modified-30k-clean.model\",\n",
    "                    \"The vocabulary file that the ALBERT/BERT model was trained on.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"verifier_init_checkpoint\", \"models/albert_xxl/verifier_model.h5\",\n",
    "    \"Initial checkpoint (usually from a pre-trained BERT model).\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"verifier_max_seq_length\", 256,\n",
    "    \"The maximum total input sequence length after WordPiece tokenization. \"\n",
    "    \"Sequences longer than this will be truncated, and sequences shorter \"\n",
    "    \"than this will be padded.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"verifier_batch_size\", 4,\n",
    "    \"Batch size when running verifier predictions.\")\n",
    "\n",
    "### Other Flags ###\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"output_dir\", \"output/\",\n",
    "    \"The output directory where the model checkpoints will be written.\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"train_file\", \"data/simplified-nq-train.jsonl\",\n",
    "    \"NQ json for predictions. E.g., dev-v1.1.jsonl.gz or test-v1.1.jsonl.gz\")\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"log_dir\", \"logs/\",\n",
    "    \"Where logs, specifically Tensorboard logs, will be saved to.\")\n",
    "\n",
    "flags.DEFINE_bool(\n",
    "    \"do_lower_case\", True,\n",
    "    \"Whether to lower case the input text. Should be True for uncased \"\n",
    "    \"models and False for cased models.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"doc_stride\", 128,\n",
    "    \"When splitting up a long document into chunks, how much stride to \"\n",
    "    \"take between chunks.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_query_length\", 64,\n",
    "    \"The maximum number of tokens for the question. Questions longer than \"\n",
    "    \"this will be truncated to this length.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_train\", False, \"Whether to run training.\")\n",
    "\n",
    "flags.DEFINE_bool(\"do_predict\", True, \"Whether to run eval on the dev set.\")\n",
    "\n",
    "flags.DEFINE_integer(\"predict_batch_size\", 1,\n",
    "                     \"Total batch size for predictions.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_answer_length\", 30,\n",
    "    \"The maximum length of an answer that can be generated. This is needed \"\n",
    "    \"because the start and end predictions are not conditioned on one another.\")\n",
    "\n",
    "flags.DEFINE_float(\n",
    "    \"include_unknowns\", 1.0,\n",
    "    \"If positive, probability of including answers of type `UNKNOWN`.\")\n",
    "\n",
    "absl.flags.DEFINE_string(\n",
    "    \"gcp_project\", None,\n",
    "    \"[Optional] Project name for the Cloud TPU-enabled project. If not \"\n",
    "    \"specified, we will attempt to automatically detect the GCE project from \"\n",
    "    \"metadata.\")\n",
    "\n",
    "# TODO(Edan): Look at nested contents too at some point\n",
    "# Around 5% of long answers are nested, and around 50% of questions have\n",
    "# long answers\n",
    "# This means that this setting alone restricts us from a correct answer\n",
    "# around 2.5% of the time\n",
    "flags.DEFINE_boolean(\n",
    "    \"skip_nested_contexts\", True,\n",
    "    \"Completely ignore context that are not top level nodes in the page.\")\n",
    "\n",
    "flags.DEFINE_integer(\"max_contexts\", 48,\n",
    "                     \"Maximum number of contexts to output for an example.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"max_position\", 50,\n",
    "    \"Maximum context position for which to generate special tokens.\")\n",
    "\n",
    "flags.DEFINE_integer(\n",
    "    \"n_examples\", 200,\n",
    "    \"Number of examples to read from files.\")\n",
    "\n",
    "flags.DEFINE_boolean(\n",
    "    \"test_post_processing\", True,\n",
    "    \"If true, training data will be predicted for instead of eval data,\"\n",
    "    \"and the predictions will be used to tune the post processing algorithm.\")\n",
    "\n",
    "## Special flags - do not change\n",
    "\n",
    "flags.DEFINE_string(\n",
    "    \"predict_file\", \"/kaggle/input/tensorflow2-question-answering/simplified-nq-test.jsonl\",\n",
    "    \"NQ json for predictions. E.g., dev-v1.1.jsonl.gz or test-v1.1.jsonl.gz\")\n",
    "flags.DEFINE_boolean(\"logtostderr\", True, \"Logs to stderr\")\n",
    "flags.DEFINE_boolean(\"undefok\", True, \"it's okay to be undefined\")\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_string('HistoryManager.hist_file', '', 'kernel')\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS(sys.argv) # Parse the flags\n",
    "\n",
    "VOCAB_SIZE = 30209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TDense(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                 output_size,\n",
    "                 kernel_initializer=None,\n",
    "                 bias_initializer=\"zeros\",\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_size = output_size\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "        self.bias_initializer = bias_initializer\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        dtype = tf.as_dtype(self.dtype or tf.keras.backend.floatx())\n",
    "        if not (dtype.is_floating or dtype.is_complex):\n",
    "            raise TypeError(\"Unable to build `TDense` layer with \"\n",
    "                          \"non-floating point (and non-complex) \"\n",
    "                          \"dtype %s\" % (dtype,))\n",
    "        input_shape = tf.TensorShape(input_shape)\n",
    "        if tf.compat.dimension_value(input_shape[-1]) is None:\n",
    "            raise ValueError(\"The last dimension of the inputs to \"\n",
    "                           \"`TDense` should be defined. \"\n",
    "                           \"Found `None`.\")\n",
    "        last_dim = tf.compat.dimension_value(input_shape[-1])\n",
    "        ### tf 2.1 rc min_ndim=3 -> min_ndim=2\n",
    "        self.input_spec = tf.keras.layers.InputSpec(min_ndim=2, axes={-1: last_dim})\n",
    "        self.kernel = self.add_weight(\n",
    "            \"kernel\",\n",
    "            shape=[self.output_size,last_dim],\n",
    "            initializer=self.kernel_initializer,\n",
    "            dtype=self.dtype,\n",
    "            trainable=True)\n",
    "        self.bias = self.add_weight(\n",
    "            \"bias\",\n",
    "            shape=[self.output_size],\n",
    "            initializer=self.bias_initializer,\n",
    "            dtype=self.dtype,\n",
    "            trainable=True)\n",
    "        super(TDense, self).build(input_shape)\n",
    "    def call(self,x):\n",
    "        return tf.matmul(x,self.kernel,transpose_b=True)+self.bias\n",
    "\n",
    "def get_bert_model(config_file, max_seq_length):\n",
    "    \"\"\"Builds and returns a BERT\"\"\"\n",
    "    config = modeling.BertConfig.from_json_file(config_file)\n",
    "    input_ids = tf.keras.Input(shape=(max_seq_length,),dtype=tf.int32,name='input_ids')\n",
    "    input_mask = tf.keras.Input(shape=(max_seq_length,),dtype=tf.int32,name='input_mask')\n",
    "    segment_ids = tf.keras.Input(shape=(max_seq_length,),dtype=tf.int32,name='segment_ids')\n",
    "    \n",
    "    bert_layer = modeling.BertModel(config=config, name='bert')\n",
    "    pooled_output, sequence_output = bert_layer(input_word_ids=input_ids,\n",
    "                                                input_mask=input_mask,\n",
    "                                                input_type_ids=segment_ids)\n",
    "    \n",
    "    # Maybe try sharing the start and end logits variables\n",
    "    seq_layer = TDense(2, name='td_seq')\n",
    "    # seq_layer = tf.keras.layers.TimeDistributed(seq_layer, name='td_seq')\n",
    "    \n",
    "    seq_logits = seq_layer(sequence_output)\n",
    "    start_logits, end_logits = tf.split(seq_logits, axis=-1, num_or_size_splits=2, name='split')\n",
    "    start_logits = tf.squeeze(start_logits, axis=-1, name='start_logits')\n",
    "    end_logits = tf.squeeze(end_logits, axis=-1, name='end_logits')\n",
    "    \n",
    "    ans_type_layer = TDense(len(tf2baseline.AnswerType), name='ans_type_logits')\n",
    "    ans_type_logits = ans_type_layer(pooled_output)\n",
    "    \n",
    "    return tf.keras.Model([input_ids, input_mask, segment_ids],\n",
    "                          [start_logits, end_logits, ans_type_logits],\n",
    "                          name='bert_baseline')\n",
    "\n",
    "# this is the helper function to create the albert model\n",
    "# config_file is used to create the model\n",
    "# pretrain_ckpt is used to load the pretrain weights except for the embedding layer\n",
    "def get_albert_model(config_file, max_seq_length, vocab_size, pretrain_ckpt=None):\n",
    "    \"\"\" create albert model from pretrained configuration file with vocab_size changed to VOCAB_SIZE\n",
    "        and optionally loads the pretrained weights\n",
    "    \"\"\"\n",
    "    \n",
    "    config = albert.AlbertConfig.from_json_file(config_file)\n",
    "    config.vocab_size = vocab_size\n",
    "    albert_layer = albert.AlbertModel(config=config)\n",
    "    \n",
    "    input_ids = tf.keras.Input(shape=(max_seq_length,),dtype=tf.int32,name='input_ids')\n",
    "    input_mask = tf.keras.Input(shape=(max_seq_length,),dtype=tf.int32,name='input_mask')\n",
    "    segment_ids = tf.keras.Input(shape=(max_seq_length,),dtype=tf.int32,name='segment_ids')\n",
    "\n",
    "    pooled_output, sequence_output = albert_layer(input_word_ids=input_ids,\n",
    "                                                    input_mask=input_mask,\n",
    "                                                    input_type_ids=segment_ids)\n",
    "    \n",
    "    # Maybe try sharing the start and end logits variables\n",
    "    seq_layer = TDense(2, name='td_seq')\n",
    "    # seq_layer = tf.keras.layers.TimeDistributed(seq_layer, name='td_seq')\n",
    "    \n",
    "    seq_logits = seq_layer(sequence_output)\n",
    "    start_logits, end_logits = tf.split(seq_logits, axis=-1, num_or_size_splits=2, name='split')\n",
    "    start_logits = tf.squeeze(start_logits, axis=-1, name='start_logits')\n",
    "    end_logits = tf.squeeze(end_logits, axis=-1, name='end_logits')\n",
    "    \n",
    "    ans_type_layer = TDense(len(tf2baseline.AnswerType), name='ans_type_logits')\n",
    "    ans_type_logits = ans_type_layer(pooled_output)\n",
    "    \n",
    "    albert_model = tf.keras.Model([input_ids, input_mask, segment_ids],\n",
    "                          [start_logits, end_logits, ans_type_logits],\n",
    "                          name='albert')\n",
    "    \n",
    "    if pretrain_ckpt:\n",
    "        albert_model.load_weights(pretrain_ckpt)\n",
    "\n",
    "    return albert_model\n",
    "\n",
    "def get_albert_verifier(config_file, max_seq_length, vocab_size, pretrain_ckpt=None):\n",
    "    \"\"\" create albert model from pretrained configuration file with vocab_size changed to VOCAB_SIZE\n",
    "        and optionally loads the pretrained weights\n",
    "    \"\"\"\n",
    "    \n",
    "    config = albert.AlbertConfig.from_json_file(config_file)\n",
    "    config.vocab_size = vocab_size\n",
    "    albert_layer = albert.AlbertModel(config=config)\n",
    "    \n",
    "    input_ids = tf.keras.Input(shape=(max_seq_length,),dtype=tf.int32,name='input_ids')\n",
    "    input_mask = tf.keras.Input(shape=(max_seq_length,),dtype=tf.int32,name='input_mask')\n",
    "    segment_ids = tf.keras.Input(shape=(max_seq_length,),dtype=tf.int32,name='segment_ids')\n",
    "\n",
    "    pooled_output, sequence_output = albert_layer(input_word_ids=input_ids,\n",
    "                                                    input_mask=input_mask,\n",
    "                                                    input_type_ids=segment_ids)\n",
    "    \n",
    "    valid_layer = TDense(2, name='valid_logits')\n",
    "    valid_logits = valid_layer(pooled_output)\n",
    "    \n",
    "    albert_model = tf.keras.Model([input_ids, input_mask, segment_ids],\n",
    "                          [valid_logits],\n",
    "                          name='albert_verifier')\n",
    "    \n",
    "    if pretrain_ckpt:\n",
    "        albert_model.load_weights(pretrain_ckpt)\n",
    "\n",
    "    return albert_model\n",
    "\n",
    "def build_model(model_name, config_file, max_seq_length, init_ckpt, vocab_size=VOCAB_SIZE):\n",
    "    \"\"\" build model according to model_name\n",
    "    \n",
    "    Args:\n",
    "        model_name: ['bert', 'albert']\n",
    "        config_file: path to config file\n",
    "        max_seq_length: the maximum length for each scan\n",
    "        pretrain_ckpt: path to pretrain checkpoint (albert only)\n",
    "        vocab_size: size of the new vocab, (albert only)\n",
    "    Returns:\n",
    "        the specified model\n",
    "    \"\"\"\n",
    "\n",
    "    if model_name == 'albert':\n",
    "        model = get_albert_model(config_file=config_file, \n",
    "                                 max_seq_length=max_seq_length, \n",
    "                                 pretrain_ckpt=init_ckpt,\n",
    "                                 vocab_size=vocab_size)\n",
    "    elif model_name == 'bert':\n",
    "        model = get_bert_model(config_file, max_seq_length)\n",
    "        model.load_weights(init_ckpt)\n",
    "    elif model_name == 'verifier':\n",
    "        model = get_albert_verifier(config_file=config_file, \n",
    "                                    max_seq_length=max_seq_length, \n",
    "                                    pretrain_ckpt=init_ckpt,\n",
    "                                    vocab_size=vocab_size)\n",
    "    else:\n",
    "        raise ValueError('{} is not supported'.format(model_name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bert_baseline\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BertModel)                ((None, 1024), (None 335141888   input_ids[0][0]                  \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "td_seq (TDense)                 (None, 384, 2)       2050        bert[0][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_split (TensorFlowOp [(None, 384, 1), (No 0           td_seq[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_start_logits (Tenso [(None, 384)]        0           tf_op_layer_split[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_end_logits (TensorF [(None, 384)]        0           tf_op_layer_split[0][1]          \n",
      "__________________________________________________________________________________________________\n",
      "ans_type_logits (TDense)        (None, 5)            5125        bert[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 335,149,063\n",
      "Trainable params: 335,149,063\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(model_name=FLAGS.model,\n",
    "                    config_file=FLAGS.config_file,\n",
    "                    max_seq_length=FLAGS.max_seq_length,\n",
    "                    init_ckpt=FLAGS.init_checkpoint)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Predict File: data/simplified-nq-train.jsonl\n",
      "**Features**\n",
      "\n",
      "answer_text\n",
      "answer_type\n",
      "doc_span_index\n",
      "end_position\n",
      "example_index\n",
      "input_ids\n",
      "input_mask\n",
      "segment_ids\n",
      "start_position\n",
      "token_is_max_context\n",
      "token_to_orig_map\n",
      "tokens\n",
      "unique_id\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.do_predict:\n",
    "    if FLAGS.model == 'bert':\n",
    "        tokenizer = bert_tokenization.FullTokenizer(\n",
    "            vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
    "    elif FLAGS.model == 'albert':\n",
    "        tokenizer = albert_tokenization.FullTokenizer(\n",
    "            None, spm_model_file=FLAGS.vocab_file)\n",
    "\n",
    "    if FLAGS.test_post_processing:\n",
    "        input_file = FLAGS.train_file\n",
    "    else:\n",
    "        input_file = FLAGS.predict_file\n",
    "\n",
    "    # This is actually quite slow, but I'm not sure if it's due to tokenizing or reading from a compressed file\n",
    "    eval_examples = tf2baseline.read_nq_examples(\n",
    "          input_file=input_file, is_training=FLAGS.test_post_processing, n=FLAGS.n_examples)\n",
    "\n",
    "    print(len(eval_examples))\n",
    "\n",
    "    print(\"Predict File:\", input_file)\n",
    "\n",
    "    eval_writer = tf2baseline.FeatureWriter(\n",
    "      filename=os.path.join(FLAGS.output_dir, \"eval.tf_record\"),\n",
    "      is_training=FLAGS.test_post_processing)\n",
    "    eval_features = []\n",
    "\n",
    "    def append_feature(feature):\n",
    "        eval_features.append(feature)\n",
    "        eval_writer.process_feature(feature)\n",
    "\n",
    "    num_spans_to_ids = tf2baseline.convert_examples_to_features(\n",
    "      examples=eval_examples,\n",
    "      tokenizer=tokenizer,\n",
    "      is_training=FLAGS.test_post_processing,\n",
    "      output_fn=append_feature)\n",
    "    eval_writer.close()\n",
    "    eval_filename = eval_writer.filename\n",
    "\n",
    "    print('**Features**\\n')\n",
    "\n",
    "    for e in dir(eval_features[0]):\n",
    "        if not e.startswith('__'):\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **eval_features**\n",
    "- `doc_span_index`: Which index this span is in the set that makes up one question-article pair\n",
    "- `example_index`: Index of the example \n",
    "- `input_mask`: 0 if a token is padding, otherwise 1 for each token in the article\n",
    "- `segment_ids`: Tokens that are part of a question are 0 ([CLS], [Q], ..., [SEP])\n",
    "- `inpud_ids`: Token ids of the article\n",
    "    - 0 -> [PAD]\n",
    "    - 101 -> [CLS]\n",
    "    - 102 -> [SEP]\n",
    "    - 103 -> [MASK]\n",
    "    - 104 -> [Q]\n",
    "    - 105 -> [YES]\n",
    "    - 106 -> [NO]\n",
    "    - 107 -> [NoLongAnswer]\n",
    "    - 108 -> [NoShortAnswer]\n",
    "- `token_is_max_context`: False if this token will appear again in the next document span due to a sliding window being used, and True otherwise\n",
    "- `token_to_orig_map`: Maps the tokens in `tokens` and `input_ids` to the actual token indices in the original document\n",
    "- `tokens`: A list of tokens making up the document span\n",
    "- `unique_id`: A unique id number for this article (NOT this document span) \n",
    "\n",
    "*Note - mappings are 0 indexed and exlude tokens that are part of the question (those can be identified from segment ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_features = {\n",
    "    \"unique_ids\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    \"input_ids\": tf.io.FixedLenFeature([FLAGS.max_seq_length], tf.int64),\n",
    "    \"input_mask\": tf.io.FixedLenFeature([FLAGS.max_seq_length], tf.int64),\n",
    "    \"segment_ids\": tf.io.FixedLenFeature([FLAGS.max_seq_length], tf.int64),\n",
    "}\n",
    "if FLAGS.do_train:\n",
    "    name_to_features[\"start_positions\"] = tf.io.FixedLenFeature([], tf.int64)\n",
    "    name_to_features[\"end_positions\"] = tf.io.FixedLenFeature([], tf.int64)\n",
    "    name_to_features[\"answer_types\"] = tf.io.FixedLenFeature([], tf.int64)\n",
    "\n",
    "def decode_record(record, name_to_features):\n",
    "    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "    example = tf.io.parse_single_example(serialized=record, features=name_to_features)\n",
    "\n",
    "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "    # So cast all int64 to int32.\n",
    "    for name in list(example.keys()):\n",
    "        t = example[name]\n",
    "        if t.dtype == tf.int64:\n",
    "            t = tf.cast(t, dtype=tf.int32)\n",
    "        example[name] = t\n",
    "\n",
    "    return example\n",
    "\n",
    "def data_generator(batch_size=32, n_samples=-1, seed=42):\n",
    "    \"\"\"The actual input function.\"\"\"\n",
    "\n",
    "    # For training, we want a lot of parallel reading and shuffling.\n",
    "    # For eval, we want no shuffling and parallel reading doesn't matter.\n",
    "#     if FLAGS.test_post_processing:\n",
    "#         eval_filename = FLAGS.train_precomputed_file\n",
    "        \n",
    "    dataset = tf.data.TFRecordDataset(eval_filename)\n",
    "    if FLAGS.do_train:\n",
    "        dataset = dataset.repeat()\n",
    "        dataset = dataset.shuffle(buffer_size=5000, seed=seed)\n",
    "        \n",
    "    dataset = dataset.map(lambda r: decode_record(r, name_to_features))\n",
    "    dataset = dataset.batch(batch_size=batch_size, drop_remainder=False)\n",
    "    \n",
    "    data_iter = iter(dataset)\n",
    "    sample_idx = 0\n",
    "    while sample_idx < n_samples or n_samples == -1:\n",
    "        try:\n",
    "            examples = next(data_iter)\n",
    "        except StopIteration:\n",
    "            break\n",
    "            \n",
    "        cutoff_amt = batch_size\n",
    "        if n_samples > -1:\n",
    "            cutoff_amt = min(cutoff_amt, n_samples - sample_idx)\n",
    "        sample_idx += cutoff_amt\n",
    "    \n",
    "        for k, v in examples.items():\n",
    "            examples[k] = v[:cutoff_amt]\n",
    "        \n",
    "        inputs = {\n",
    "            # 'unique_id': examples['unique_ids'],\n",
    "            'input_ids': examples['input_ids'],\n",
    "            'input_mask': examples['input_mask'],\n",
    "            'segment_ids': examples['segment_ids']\n",
    "        }\n",
    "\n",
    "        if FLAGS.do_train:\n",
    "            targets = {\n",
    "                'tf_op_layer_start_logits': examples['start_positions'],\n",
    "                'tf_op_layer_end_logits': examples['end_positions'],\n",
    "                'ans_type_logits': examples['answer_types'],\n",
    "            }\n",
    "\n",
    "            yield inputs, targets\n",
    "        else:\n",
    "            yield inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = np.ceil(eval_writer.num_features / FLAGS.predict_batch_size)\n",
    "generator = data_generator(FLAGS.predict_batch_size)\n",
    "\n",
    "preds = model.predict_generator(generator, steps=n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer Types\n",
    "- UNKNOWN = 0\n",
    "- YES = 1\n",
    "- NO = 2\n",
    "- SHORT = 3\n",
    "- LONG = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Computing Answers from Logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_probs(x):\n",
    "    return np.exp(x) / (np.exp(x) + 1)\n",
    "\n",
    "def get_candidate_span(entry):\n",
    "    return (entry['candidates'][entry['candidate_idx']]['start_token'],\n",
    "            entry['candidates'][entry['candidate_idx']]['end_token'])\n",
    "\n",
    "def check_entry_in_candidates(entry):\n",
    "    \"\"\"Checks if the entry start and ending tokens fall into a candidate.\n",
    "        Returns the candidate index, or -1 if none is found.\"\"\"\n",
    "    if not FLAGS.skip_nested_contexts:\n",
    "        raise NotImplementedError('Nested contexts have not been implemented for predictions yet!')\n",
    "    else:\n",
    "        for cand_idx, candidate in enumerate(entry['candidates']):\n",
    "            if not candidate['top_level']:\n",
    "                continue\n",
    "            if entry['orig_start'] >= candidate['start_token'] and \\\n",
    "                entry['orig_end'] <= candidate['end_token']:\n",
    "                return cand_idx\n",
    "    return -1\n",
    "\n",
    "def compute_answers(preds, candidates_dict, features, examples, weights={}):\n",
    "    default_weights = {\n",
    "        'ans_type_conf_weight': 0.4,\n",
    "        'start_pos_conf_weight': 0.3,\n",
    "        'end_pos_conf_weight': 0.3,\n",
    "        'conf_bias': 0.0,\n",
    "        'conf_threshold': 0.98\n",
    "    }\n",
    "    \n",
    "    for k, v in default_weights.items():\n",
    "        if k not in weights:\n",
    "            weights[k] = v\n",
    "    \n",
    "    ### Get variables needed for post processing ###\n",
    "    start_token_probs = logits_to_probs(preds[0])\n",
    "    end_token_probs = logits_to_probs(preds[1])\n",
    "    ans_type_probs = logits_to_probs(preds[2])\n",
    "    candidates_dict = {int(k): v for k, v in candidates_dict.items()}\n",
    "\n",
    "    # Create a feature index to example_id mapping\n",
    "    f_idx_to_example_id = []\n",
    "    for feature in features:\n",
    "        f_idx_to_example_id.append(feature.unique_id - feature.doc_span_index)\n",
    "    \n",
    "    id_to_example = {}\n",
    "    for example in examples:\n",
    "        id_to_example[example.example_id] = example\n",
    "        \n",
    "    ### Create doc span groups ###\n",
    "    doc_span_groups = [(f_idx_to_example_id[0], [])]\n",
    "    for i in range(len(features)):\n",
    "        if f_idx_to_example_id[i] != doc_span_groups[-1][0]:\n",
    "            doc_span_groups.append((f_idx_to_example_id[i], []))\n",
    "            eval_example_idx += 1\n",
    "\n",
    "        eval_example_idx = len(doc_span_groups) - 1\n",
    "        group_data = {\n",
    "            'start_tokens_probs': start_token_probs[i],\n",
    "            'end_tokens_probs': end_token_probs[i],\n",
    "            'ans_type_probs': ans_type_probs[i],\n",
    "            'candidates': candidates_dict[f_idx_to_example_id[i]],\n",
    "            'feature': features[i],\n",
    "            'doc_tokens_map': eval_examples[eval_example_idx].doc_tokens_map\n",
    "        }\n",
    "\n",
    "        doc_span_groups[-1][1].append(group_data)\n",
    "    \n",
    "    ### Compute answers ###\n",
    "        \n",
    "    answers = {} # Maps example_ids to long and short answers\n",
    "    for example_id, group in doc_span_groups:\n",
    "        example = id_to_example[example_id]\n",
    "        doc_to_orig = example.doc_tokens_map\n",
    "        \n",
    "        assert doc_to_orig is not None\n",
    "        \n",
    "        # Reverse doc_to_orig to create orig_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_probs(x):\n",
    "    return np.exp(x) / (np.exp(x) + 1)\n",
    "\n",
    "def get_candidate_span(entry):\n",
    "    return (entry['candidates'][entry['candidate_idx']]['start_token'],\n",
    "            entry['candidates'][entry['candidate_idx']]['end_token'])\n",
    "\n",
    "def check_entry_in_candidates(entry):\n",
    "    \"\"\"Checks if the entry start and ending tokens fall into a candidate.\n",
    "        Returns the candidate index, or -1 if none is found.\"\"\"\n",
    "    if not FLAGS.skip_nested_contexts:\n",
    "        raise NotImplementedError('Nested contexts have not been implemented for predictions yet!')\n",
    "    else:\n",
    "        for cand_idx, candidate in enumerate(entry['candidates']):\n",
    "            if not candidate['top_level']:\n",
    "                continue\n",
    "            if entry['orig_start'] >= candidate['start_token'] and \\\n",
    "                entry['orig_end'] <= candidate['end_token']:\n",
    "                return cand_idx\n",
    "    return -1\n",
    "\n",
    "def compute_answers(preds, candidates_dict, features, examples, weights={}):\n",
    "    default_weights = {\n",
    "        'ans_type_conf_weight': 0.4,\n",
    "        'start_pos_conf_weight': 0.3,\n",
    "        'end_pos_conf_weight': 0.3,\n",
    "        'conf_bias': 0.0,\n",
    "        'conf_threshold': 0.98\n",
    "    }\n",
    "    \n",
    "    for k, v in default_weights.items():\n",
    "        if k not in weights:\n",
    "            weights[k] = v\n",
    "    \n",
    "    ### Get variables needed for post processing ###\n",
    "    start_token_probs = logits_to_probs(preds[0])\n",
    "    end_token_probs = logits_to_probs(preds[1])\n",
    "    ans_type_probs = logits_to_probs(preds[2])\n",
    "    candidates_dict = {int(k): v for k, v in candidates_dict.items()}\n",
    "\n",
    "    # Create a feature index to example_id mapping\n",
    "    f_idx_to_example_id = []\n",
    "    for feature in features:\n",
    "        f_idx_to_example_id.append(feature.unique_id - feature.doc_span_index)\n",
    "    \n",
    "    id_to_example = {}\n",
    "    for example in examples:\n",
    "        id_to_example[example.example_id] = example\n",
    "        \n",
    "    ### Create doc span groups ###\n",
    "    doc_span_groups = [(f_idx_to_example_id[0], [])]\n",
    "    for i in range(len(features)):\n",
    "        if f_idx_to_example_id[i] != doc_span_groups[-1][0]:\n",
    "            doc_span_groups.append((f_idx_to_example_id[i], []))\n",
    "            eval_example_idx += 1\n",
    "\n",
    "        eval_example_idx = len(doc_span_groups) - 1\n",
    "        group_data = {\n",
    "            'start_tokens_probs': start_token_probs[i],\n",
    "            'end_tokens_probs': end_token_probs[i],\n",
    "            'ans_type_probs': ans_type_probs[i],\n",
    "            'candidates': candidates_dict[f_idx_to_example_id[i]],\n",
    "            'feature': features[i],\n",
    "            'doc_tokens_map': eval_examples[eval_example_idx].doc_tokens_map\n",
    "        }\n",
    "\n",
    "        doc_span_groups[-1][1].append(group_data)\n",
    "    \n",
    "    ### Compute answers ###\n",
    "        \n",
    "    answers = {} # Maps example_ids to long and short answers\n",
    "    for example_id, group in doc_span_groups:\n",
    "        example = id_to_example[example_id]\n",
    "        doc_to_orig = example.doc_tokens_map\n",
    "        \n",
    "        assert doc_to_orig is not None\n",
    "        \n",
    "        # Reverse doc_to_orig to create orig_to_doc\n",
    "        orig_to_doc = {}\n",
    "        for doc_token_idx, orig_tok_idx in enumerate(doc_to_orig):\n",
    "            orig_to_doc[orig_tok_idx] = doc_token_idx\n",
    "        orig_to_doc[-1] = -1\n",
    "        \n",
    "        valid_entries = []\n",
    "        for entry in group:\n",
    "            # Converting logits to answer values\n",
    "            entry['start_token_idx'] = np.argmax(entry['start_tokens_probs'])\n",
    "            entry['end_token_idx'] = np.argmax(entry['end_tokens_probs'])\n",
    "            entry['ans_type_idx'] = np.argmax(entry['ans_type_probs'])\n",
    "\n",
    "            # TODO(Edan): Think about changing this to also check the probability\n",
    "            # of the token indices\n",
    "            # Calculating probability of the chosen answer type\n",
    "            entry['start_pos_prob'] = entry['start_tokens_probs'][entry['start_token_idx']]\n",
    "            entry['end_pos_prob'] = entry['end_tokens_probs'][entry['end_token_idx']]\n",
    "            entry['ans_type_prob'] = entry['ans_type_probs'][entry['ans_type_idx']]\n",
    "            \n",
    "            \n",
    "            entry['prob'] = weights['conf_bias'] + \\\n",
    "                            entry['start_pos_prob'] * weights['start_pos_conf_weight'] + \\\n",
    "                            entry['end_pos_prob'] * weights['end_pos_conf_weight'] + \\\n",
    "                            entry['ans_type_prob'] * weights['ans_type_conf_weight']\n",
    "            \n",
    "            # Filter out entries with invalid answers\n",
    "            if entry['end_token_idx'] < entry['start_token_idx'] or \\\n",
    "                (entry['end_token_idx'] - entry['start_token_idx'] > FLAGS.max_answer_length and \\\n",
    "                 entry['ans_type_idx'] == AnswerType.SHORT) or \\\n",
    "                entry['feature'].segment_ids[entry['start_token_idx']] == 0 or \\\n",
    "                entry['feature'].segment_ids[entry['end_token_idx']] == 0 or \\\n",
    "                entry['feature'].input_mask[entry['start_token_idx']] == 0 or \\\n",
    "                entry['feature'].input_mask[entry['end_token_idx']] == 0 or \\\n",
    "                entry['ans_type_idx'] == AnswerType.UNKNOWN or \\\n",
    "                entry['prob'] < weights['conf_threshold']:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Getting indices of tokens in original document\n",
    "                tok_to_orig_map = entry['feature'].token_to_orig_map\n",
    "                entry['orig_start'] = tok_to_orig_map[entry['start_token_idx']]\n",
    "                entry['orig_end'] = tok_to_orig_map[entry['end_token_idx']] + 1\n",
    "            except KeyError:\n",
    "                print('KEY ERROR BUT IGNORING FOR NOW')\n",
    "#                 print(entry['start_token_idx'])\n",
    "#                 print(entry['end_token_idx'])\n",
    "#                 print(tok_to_orig_map)\n",
    "                continue\n",
    "\n",
    "            entry['doc_tokens_start_idx'] = orig_to_doc[entry['orig_start']]\n",
    "            entry['doc_tokens_end_idx'] = orig_to_doc[entry['orig_end'] - 1] + 1\n",
    "                \n",
    "            if entry['orig_start'] == -1 or entry['orig_end'] == 0:\n",
    "                continue\n",
    "\n",
    "            entry['candidate_idx'] = check_entry_in_candidates(entry)\n",
    "            if entry['candidate_idx'] == -1:\n",
    "                continue\n",
    "\n",
    "            valid_entries.append(entry)\n",
    "\n",
    "        long_answer = None\n",
    "        short_answer = None\n",
    "        doc_tokens_span = None\n",
    "            \n",
    "        if len(valid_entries) > 0:\n",
    "            # TODO(Edan): I think I should probably prioritize short answers\n",
    "            # over long answers because both can be right, but most long answer\n",
    "            # also have short answers\n",
    "            # I could also look at if other probabilities are also high,\n",
    "            # ideally only a single entry should have a high logit\n",
    "            best_entry = max(valid_entries, key=lambda e: e['prob'])\n",
    "            if best_entry['ans_type_idx'] == AnswerType.LONG:\n",
    "                long_answer = get_candidate_span(best_entry)\n",
    "            elif best_entry['ans_type_idx'] == AnswerType.SHORT:\n",
    "                long_answer = get_candidate_span(best_entry)\n",
    "                short_answer = (best_entry['orig_start'], best_entry['orig_end'])\n",
    "            elif best_entry['ans_type_idx'] == AnswerType.YES:\n",
    "                long_answer = get_candidate_span(best_entry)\n",
    "                short_answer = 'YES'\n",
    "            elif best_entry['ans_type_idx'] == AnswerType.NO:\n",
    "                long_answer = get_candidate_span(best_entry)\n",
    "                short_answer = 'NO'\n",
    "            else:\n",
    "                raise ValueError('Entry should not have AnswerType UNKNOWN or other!')\n",
    "                \n",
    "            doc_tokens_start = best_entry['doc_tokens_start_idx']\n",
    "            doc_tokens_end = best_entry['doc_tokens_end_idx']\n",
    "            doc_tokens_span = (doc_tokens_start, doc_tokens_end)\n",
    "            \n",
    "        answers[example_id] = {'long_answer': long_answer,\n",
    "                               'short_answer': short_answer,\n",
    "                               'doc_tokens_span': doc_tokens_span}\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FLAGS.test_post_processing:\n",
    "    candidates_dict = tf2baseline.read_candidates(FLAGS.train_file, n=FLAGS.n_examples)\n",
    "else:\n",
    "    candidates_dict = tf2baseline.read_candidates(FLAGS.predict_file, n=FLAGS.n_examples)\n",
    "\n",
    "weights = {\n",
    "    'ans_type_conf_weight': 0.4,\n",
    "    'start_pos_conf_weight': 0.3,\n",
    "    'end_pos_conf_weight': 0.3,\n",
    "    'conf_bias': 0.0,\n",
    "    'conf_threshold': 0.9\n",
    "}\n",
    "answers = compute_answers(preds, candidates_dict, eval_features, eval_examples, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Verifier Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_to_verifier_feature(example, tokenizer, max_seq_length, max_query_length):\n",
    "    question_text = example.questions[0]\n",
    "    answer_text = example.answer.text\n",
    "    if answer_text == '[':\n",
    "        answer_text = None\n",
    "        \n",
    "    question_tokens = tokenizer.tokenize(question_text)\n",
    "    answer_tokens = tokenizer.tokenize(answer_text)\n",
    "    \n",
    "    if len(question_tokens) > max_query_length:\n",
    "        question_tokens = question_tokens[-max_query_length:]\n",
    "        \n",
    "    max_answer_length = max_seq_length - (max_query_length + 4)\n",
    "    if len(answer_tokens) > max_answer_length:\n",
    "        answer_tokens = answer_tokens[:max_answer_length]\n",
    "        \n",
    "    n_q_tokens = len(question_tokens) + 3\n",
    "    n_a_tokens = len(answer_tokens) + 1\n",
    "    n_pad_tokens = max_seq_length - (n_q_tokens + n_a_tokens)\n",
    "\n",
    "    input_tokens = ['[CLS]', '[Q]'] + \\\n",
    "                 question_tokens + \\\n",
    "                 ['[SEP]'] + \\\n",
    "                 answer_tokens + \\\n",
    "                 ['[SEP]'] + \\\n",
    "                 ['[PAD]'] * n_pad_tokens\n",
    "    \n",
    "    \n",
    "    \n",
    "    input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n",
    "    segment_ids = np.concatenate([np.zeros(n_q_tokens, dtype=np.int32),\n",
    "                                  np.ones(n_a_tokens, dtype=np.int32),\n",
    "                                  np.zeros(n_pad_tokens, dtype=np.int32)])\n",
    "    input_mask = np.concatenate([np.ones(max_seq_length - n_pad_tokens, dtype=np.int32),\n",
    "                                 np.zeros(n_pad_tokens, dtype=np.int32)])\n",
    "    \n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    \n",
    "    return {'input_ids': input_ids,\n",
    "            'segment_ids': segment_ids,\n",
    "            'input_mask': input_mask}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Verifier Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1691"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_examples[0].end_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'long_answer': (1315, 1431),\n",
       " 'short_answer': (1324, 1325),\n",
       " 'doc_tokens_span': (1116, 1117)}"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['which is the most common use of opt-in e-mail marketing']\n",
      "A common example of permission marketing is a newsletter sent to an advertising firm 's customers . Such newsletters inform customers of upcoming events or promotions , or new products . In this type of advertising , a company that wants to send a newsletter to their customers may ask them at the point of purchase if they would like to receive the newsletter .\n",
      "1\n",
      "[(1952, 2019)]\n",
      "((1952, 2019), (1960, 1969))\n",
      "\n",
      "['how i.met your mother who is the mother']\n",
      "Tracy McConnell\n",
      "1\n",
      "[(212, 310), (213, 215)]\n",
      "((212, 310), (213, 215))\n",
      "\n",
      "['what type of fertilisation takes place in humans']\n",
      "In vitro fertilization\n",
      "0\n",
      "[(438, 464), (439, 442)]\n",
      "((319, 438),)\n",
      "\n",
      "['who had the most wins in the nfl']\n",
      "Tom Brady\n",
      "1\n",
      "[(509, 576), (512, 514)]\n",
      "((509, 576), (512, 514))\n",
      "\n",
      "['what happened to the lost settlement of roanoke']\n",
      "The colonists disappeared during the Anglo - Spanish War , three years after the last shipment of supplies from England . Their disappearance gave rise to the nickname `` The Lost Colony '' . There is no conclusive evidence as to what happened to the colonists .\n",
      "0\n",
      "[(316, 365)]\n",
      "()\n",
      "\n",
      "['what are the different regions of africa and how do they differ']\n",
      "Region Country Northern Africa Algeria Egypt Libya Morocco Sudan Tunisia Western Sahara Eastern Africa Burundi Comoros Djibouti Eritrea Ethiopia Kenya Madagascar Malawi Mauritius Mayotte Mozambique Reunion Rwanda Seychelles Somalia South Sudan Tanzania Uganda Zambia Zimbabwe Central Africa Angola Cameroon Central African Republic Chad Democratic Republic of the Congo Republic of the Congo Equatorial Guinea Gabon São Tomé and Príncipe Western Africa Benin Burkina Faso Cape Verde Ivory Coast Gambia Ghana Guinea Guinea - Bissau Liberia Mali Mauritania Niger Nigeria Saint Helena Senegal Sierra Leone Togo Southern Africa Botswana Lesotho Namibia South Africa Swaziland\n",
      "0\n",
      "[(247, 600)]\n",
      "()\n",
      "\n",
      "['who played mantis guardians of the galaxy 2']\n",
      "Pom Klementieff\n",
      "1\n",
      "[(82, 169), (83, 85)]\n",
      "((82, 169), (83, 85))\n",
      "\n",
      "['what indian tribe did the acadians form friendships and alliances with']\n",
      "The Mi'kmaq\n",
      "0\n",
      "[(2092, 2191), (2141, 2143)]\n",
      "((562, 695),)\n",
      "\n",
      "['what is considered the outer banks in north carolina']\n",
      "The Outer Banks stretch southward from Sandbridge in Virginia Beach down the North Carolina coastline . Sources differ regarding the southern terminus of the Outer Banks . Generations of North Carolina schoolchildren have learned that the term includes the state 's three prominent capes : Cape Hatteras , Cape Lookout , and Cape Fear . Other sources limit the definition to two capes ( Cape Hatteras and Cape Lookout ) and coastal areas in four counties ( Currituck County , Dare County , Hyde County , and Carteret County ) . Some authors include Carteret 's Shackelford Banks and Bogue Banks in their descriptions , while others exclude Bogue Banks . Still other references restrict the definition to the northern three counties of Currituck , Dare , and Hyde .\n",
      "0\n",
      "[(564, 696)]\n",
      "()\n",
      "\n",
      "['who is deputy cm of j and k']\n",
      "Kavinder Gupta\n",
      "0\n",
      "[(122, 348), (328, 330)]\n",
      "((20, 82),)\n",
      "\n",
      "['actual time taken from start to finish to produce one unit of value']\n",
      "Takt time\n",
      "0\n",
      "[(90, 255), (91, 93)]\n",
      "()\n",
      "\n",
      "['i had trouble in getting to solla sellew']\n",
      "As the protagonist tries to fight off his troubles , a man on a One Wheel Wubble drawn by a camel comes up and explains that like the protagonist , he too is experiencing a troubled life and has decided to escape his troubles by going to Solla Sollew , a city on the beautiful banks of the river Wah - Hoo , and known to never have troubles ( at least very few ) . He invites the protagonist to come along with him . Eager to escape his troubles , the protagonist joins the wubble driver , but after a long night of traveling , the camel gets sick and starts to bubble . At first , the driver and protagonist pull him on the wubble , but for the rest of the day , the driver acts lazy and has the protagonist do all the hard work .\n",
      "0\n",
      "[(536, 689)]\n",
      "()\n",
      "\n",
      "['the nashville sound brought a polished and cosmopolitan sound to country music by']\n",
      "the use of lush string arrangements with a real orchestra and often , background vocals provided by a choir\n",
      "1\n",
      "[(675, 874), (758, 777)]\n",
      "((675, 874), (758, 777))\n",
      "\n",
      "['list the seven wonders of the modern world']\n",
      "Number Wonder Location Potala Palace Lhasa , Tibet , China Old City of Jerusalem Jerusalem Polar ice caps Polar regions Papahānaumokuākea Marine National Monument Hawaii , United States 5 Internet Earth 6 Mayan ruins Yucatán Peninsula , México 7 Great Migration of Serengeti and Masai Mara Tanzania and Kenya 8 Grand Canyon ( viewer - chosen eighth wonder ) Arizona , United States\n",
      "0\n",
      "[(1296, 1433)]\n",
      "()\n",
      "\n",
      "['what channel is the premier league on in france']\n",
      "SFR Sport\n",
      "1\n",
      "[(932, 1489), (1155, 1157)]\n",
      "((932, 1489), (1155, 1157))\n",
      "\n",
      "['what is the use of jdk in java']\n",
      "The Java Development Kit ( JDK ) is an implementation of either one of the Java Platform , Standard Edition , Java Platform , Enterprise Edition , or Java Platform , Micro Edition platforms released by Oracle Corporation in the form of a binary product aimed at Java developers on Solaris , Linux , macOS or Windows . The JDK includes a private JVM and a few other resources to finish the development of a Java Application . Since the introduction of the Java platform , it has been by far the most widely used Software Development Kit ( SDK ) . On 17 November 2006 , Sun announced that they would release it under the GNU General Public License ( GPL ) , thus making it free software . This happened in large part on 8 May 2007 , when Sun contributed the source code to the OpenJDK .\n",
      "1\n",
      "[(136, 288)]\n",
      "((136, 288),)\n",
      "\n",
      "[\"god's not dead a light in the darkness release date\"]\n",
      "March 30 , 2018\n",
      "1\n",
      "[(321, 393), (343, 347)]\n",
      "((321, 393), (343, 347))\n",
      "\n",
      "['who plays young flo in the progressive commercials']\n",
      "Stephanie Courtney\n",
      "0\n",
      "[(101, 233), (102, 104)]\n",
      "()\n",
      "\n",
      "['who is the current president of un general assembly']\n",
      "Miroslav Lajčák of Slovakia\n",
      "1\n",
      "[(151, 176), (152, 156)]\n",
      "((151, 176), (152, 156))\n",
      "\n",
      "['what season does chris pratt join the office']\n",
      "second season\n",
      "0\n",
      "[(1953, 2018), (1977, 1979)]\n",
      "()\n",
      "\n",
      "['when do they pull the powerball numbers 2016']\n",
      "every Wednesday and Saturday evening at 10 : 59 p.m. Eastern Time\n",
      "1\n",
      "[(208, 341), (214, 226)]\n",
      "((208, 341), (214, 226))\n",
      "\n",
      "['when do the eclipse supposed to take place']\n",
      "August 21 , 2017\n",
      "0\n",
      "[(269, 372), (274, 278)]\n",
      "((24, 269), (30, 34))\n",
      "\n",
      "['what is the name of the sea surrounding dubai']\n",
      "Persian Gulf\n",
      "1\n",
      "[(747, 876), (795, 797)]\n",
      "((747, 876), (795, 797))\n",
      "\n",
      "['who holds the nba record for most points in a career']\n",
      "Kareem Abdul - Jabbar\n",
      "1\n",
      "[(262, 3349), (329, 333)]\n",
      "((262, 3349), (329, 333))\n",
      "\n",
      "['when was all that is gold does not glitter written']\n",
      "The poem appears twice in The Fellowship of the Ring , the first volume of The Lord of the Rings . It appears first in Chapter Ten , `` Strider '' , in Gandalf 's letter to Frodo Baggins in Bree , although when Frodo reads it he does not realize that Strider ( Aragorn ) is the subject of the verse .\n",
      "0\n",
      "[(326, 391)]\n",
      "()\n",
      "\n",
      "['what is the musical term for fast tempo']\n",
      "Prestissimo\n",
      "0\n",
      "[(1661, 2167), (1961, 1962)]\n",
      "()\n",
      "\n",
      "['is there an active volcano in new zealand']\n",
      "Name Elevation Location Last eruption metres feet Coordinates Brothers volcano - 1350 - 4400 - - Clark ( volcano ) - 860 - 2800 36 ° 26 ′ 46 '' S 177 ° 50 ′ 20 '' E ﻿ / ﻿ 36.446 ° S 177.839 ° E ﻿ / - 36.446 ; 177.839 ﻿ ( Clark ) - Cole ( volcano ) - - - - Cotton ( volcano ) - 950 - 3100 35 ° 03 ′ S 178 ° 59 ′ E ﻿ / ﻿ 35.05 ° S 178.99 ° E ﻿ / - 35.05 ; 178.99 ﻿ ( Cotton ) - Curtis Island 137 449 30 ° 32 ′ 31 '' S 178 ° 33 ′ 40 '' E ﻿ / ﻿ 30.542 ° S 178.561 ° E ﻿ / - 30.542 ; 178.561 ﻿ ( Curtis Island ) - Gamble ( volcano ) - - - - Giggenbach ( volcano ) - 65 - 210 30 ° 02 ′ 10 '' S 178 ° 42 ′ 43 '' E ﻿ / ﻿ 30.036 ° S 178.712 ° E ﻿ / - 30.036 ; 178.712 ﻿ ( Giggenbach ) - Havre Seamount - - 31 ° 07 ′ 13 '' S 179 ° 58 ′ 07 '' W ﻿ / ﻿ 31.12028 ° S 179.96861 ° W ﻿ / - 31.12028 ; - 179.96861 2012 Healy ( volcano ) - 1150 - 3800 34 ° 59 ′ S 179 ° 00 ′ E ﻿ / ﻿ 34.98 ° S 179.00 ° E ﻿ / - 34.98 ; 179.00 ﻿ ( Healy ) 1360 Hinepuia ( volcano ) - - - - Hinetāpeka ( volcano ) -\n",
      "0\n",
      "[(113, 1180)]\n",
      "()\n",
      "\n",
      "['where is a georgia concealed carry permit valid']\n",
      "Georgia reciprocates in recognizing firearms licenses with the following states : Alabama , Alaska , Arizona , Arkansas , Colorado , Florida , Idaho , Indiana , Iowa , Kansas , Kentucky , Louisiana , Maine , Michigan , Mississippi , Missouri , Montana , New Hampshire , North Carolina , North Dakota , Ohio , Oklahoma , Pennsylvania , South Carolina , South Dakota , Tennessee , Texas , Utah , Virginia , West Virginia , Wisconsin , and Wyoming .\n",
      "1\n",
      "[(240, 324)]\n",
      "((240, 324),)\n",
      "\n",
      "['when does a tv show go into syndication']\n",
      "Syndication can take the form of either weekly or daily syndication . Game shows , some `` tabloid '' and entertainment news shows , and talk shows are broadcast daily on weekdays , while most other first - run syndicated shows are broadcast on a weekly basis and are usually aired on weekends only . Big discussion occurred in the 1990s and 2000s about whether previously aired episodes of a show could become syndicated while new episodes of it continued to air on its original network . There had been much opposition to this idea and it was generally viewed to lead to the death of the show . However , licensing a program for syndication actually resulted in the increased popularity for shows that remained in production . A prime example is Law & Order .\n",
      "0\n",
      "[(1639, 1778)]\n",
      "()\n",
      "\n",
      "['who was eliminated from big brother this week']\n",
      "Name Age on entry Occupation Residence Angela Rummans 26 Fitness model Playa Vista , California Angie `` Rockstar '' Lantry 34 Stay - at - home mom Columbia , Maryland Bayleigh Dayton 25 Flight attendant Atlanta , Georgia Brett Robinson 25 Cybersecurity engineer Charlestown , Massachusetts Chris `` Swaggy C '' Williams 23 Day trader Bridgeport , Connecticut Faysal Shafaat 26 Substitute teacher Orlando , Florida Haleigh Broucher 21 College student College Station , Texas Joseph `` JC '' Mounduix 28 Professional dancer West Hollywood , California Kaitlyn Herman 24 Life coach Encino , California Kaycee Clark 30 Pro-football player Tempe , Arizona Rachel Swindler 29 Vegas entertainer Las Vegas , Nevada Samantha `` Sam '' Bledsoe 27 Welder Stuarts Draft , Virginia Scottie Salton 26 Shipping manager Chicago , Illinois Stephen `` Steve '' Arienta 40 Former undercover cop Wanaque , New Jersey Tyler Crispen 23 Lifeguard Hilton Head , South Carolina Winston Hines 28 Medical sales rep Bowling Green , Kentucky\n",
      "0\n",
      "[(1759, 2094)]\n",
      "()\n",
      "\n",
      "['when did the new maze runner movie come out']\n",
      "January 26 , 2018\n",
      "1\n",
      "[(461, 536), (498, 502)]\n",
      "((461, 536), (498, 502))\n",
      "\n",
      "['where does the san andres fault start and end']\n",
      "The northern segment of the fault runs from Hollister , through the Santa Cruz Mountains , epicenter of the 1989 Loma Prieta earthquake , then up the San Francisco Peninsula , where it was first identified by Professor Lawson in 1895 , then offshore at Daly City near Mussel Rock . This is the approximate location of the epicenter of the 1906 San Francisco earthquake . The fault returns onshore at Bolinas Lagoon just north of Stinson Beach in Marin County . It returns underwater through the linear trough of Tomales Bay which separates the Point Reyes Peninsula from the mainland , runs just east of the Bodega Heads through Bodega Bay and back underwater , returning onshore at Fort Ross . ( In this region around the San Francisco Bay Area several significant `` sister faults '' run more - or-less parallel , and each of these can create significantly destructive earthquakes . ) From Fort Ross , the northern segment\n",
      "0\n",
      "[(719, 938)]\n",
      "()\n",
      "\n",
      "['who is the former co-chairman goldman sachs who became a u.s. secretary of the treasury']\n",
      "Henry Paulson\n",
      "0\n",
      "[(49, 1394), (1064, 1066)]\n",
      "()\n",
      "\n",
      "['how many players on a box lacrosse team']\n",
      "six\n",
      "1\n",
      "[(1702, 1826), (1710, 1711)]\n",
      "((1702, 1826), (1710, 1711))\n",
      "\n",
      "['where are the upcoming olympics to be held']\n",
      "Tokyo\n",
      "1\n",
      "[(22, 235), (204, 205)]\n",
      "((22, 235), (204, 210), (211, 217), (218, 224), (226, 233))\n",
      "\n",
      "['when did the nba 3 second rule start']\n",
      "1936\n",
      "1\n",
      "[(121, 161), (130, 131)]\n",
      "((121, 161), (130, 131))\n",
      "\n",
      "['when were the plus and minus signs first recorded']\n",
      "the 14th century\n",
      "0\n",
      "[(1145, 1172), (1151, 1154)]\n",
      "((1172, 1379),)\n",
      "\n",
      "[\"where does the phrase bob's your uncle come from\"]\n",
      "... And Bob 's your uncle is an expression of unknown origin\n",
      "1\n",
      "[(31, 108)]\n",
      "((31, 108),)\n",
      "\n",
      "['the one where chandler and monica get engaged']\n",
      "After searching all day , Chandler hurries back to his apartment and when he gets there , Joey meets him in the hall , claiming Monica has left him because of his commitment issues . When Chandler enters their apartment , afraid of Monica actually leaving , he discovers that it 's far from being abandoned , there are candles lit all over and Monica is kneeling to propose . In the midst of proposing to Chandler , she cries from sheer emotion , saying , `` There 's a reason why girls do n't do this ! '' Instead , Chandler gets on his knees and proposes to her and Monica says yes . They then open the door to Joey , Rachel , and Phoebe , who have been waiting to celebrate . At first , they hesitate , feeling Ross should be there to share the moment , then decide that after three marriages , Ross can afford to miss one engagement celebration . End credits play while Monica and Chandler dance to Eric Clapton 's `` Wonderful Tonight . ''\n",
      "1\n",
      "[(1024, 1210)]\n",
      "((1024, 1210),)\n",
      "\n",
      "['who won so you think you can dance 2016']\n",
      "Leon `` Kida '' Burns\n",
      "1\n",
      "[(40, 176), (118, 123)]\n",
      "((40, 176), (118, 123))\n",
      "\n",
      "['who plays norman bates in the tv show']\n",
      "Freddie Highmore\n",
      "0\n",
      "[(565, 701), (599, 601)]\n",
      "((1822, 1829), (1823, 1825))\n",
      "\n",
      "['when did usa start driving on the right']\n",
      "1792\n",
      "0\n",
      "[(1238, 1281), (1254, 1255)]\n",
      "((979, 1074), (982, 984))\n",
      "\n",
      "['into the badlands season 1 and 2 recap']\n",
      "Season Episodes Originally aired First aired Last aired 6 November 15 , 2015 ( 2015 - 11 - 15 ) December 20 , 2015 ( 2015 - 12 - 20 ) 10 March 19 , 2017 ( 2017 - 03 - 19 ) May 21 , 2017 ( 2017 - 05 - 21 ) 16 April 22 , 2018 ( 2018 - 04 - 22 ) TBA\n",
      "0\n",
      "[(2404, 2523)]\n",
      "()\n",
      "\n",
      "['name some components of the central nervous system (cns)']\n",
      "Central nervous system Brain Prosencephalon Telencephalon Rhinencephalon , Amygdala , Hippocampus , Neocortex , Basal ganglia , Lateral ventricles Diencephalon Epithalamus , Thalamus , Hypothalamus , Subthalamus , Pituitary gland , Pineal gland , Third ventricle Brain stem Mesencephalon Tectum , Cerebral peduncle , Pretectum , Mesencephalic duct Rhombencephalon Metencephalon Pons , Cerebellum Myelencephalon Medulla oblongata Spinal cord\n",
      "0\n",
      "[(3115, 3227)]\n",
      "((122, 356), (140, 141), (142, 144))\n",
      "\n",
      "[\"who's the director of the price is right\"]\n",
      "Drew Carey\n",
      "0\n",
      "[(912, 1032), (946, 948)]\n",
      "((4808, 5322), (4970, 4972))\n",
      "\n",
      "['bridge on the river kwai fact or fiction']\n",
      "fiction\n",
      "1\n",
      "[(286, 387), (346, 347)]\n",
      "((286, 387), (346, 347))\n",
      "\n",
      "['who sang the song when you say nothing at all']\n",
      "Ronan Keating\n",
      "0\n",
      "[(1956, 2124), (1977, 1979)]\n",
      "()\n",
      "\n",
      "[\"what was dennis hopper's bike in easy rider\"]\n",
      "two five - ton trucks\n",
      "0\n",
      "[(2619, 2692), (2657, 2662)]\n",
      "()\n",
      "\n",
      "['is hong kong a part of the commonwealth']\n",
      "Other eligible applicants could be any of the remaining inhabited British overseas territories , Crown dependencies , Australian external territories and the Associated States of New Zealand if they become fully independent . Many such jurisdictions are already directly represented within the Commonwealth , particularly through the Commonwealth Family . There are also former British possessions that have not become independent , for example , Hong Kong , which still participates in some of the institutions within the Commonwealth Family . All three Crown dependencies regard the existing situation as unsatisfactory and have lobbied for change . The States of Jersey have called on the UK Foreign Secretary to request that the Commonwealth Heads of Government `` consider granting associate membership to Jersey and the other Crown Dependencies as well as any other territories at a similarly advanced stage of autonomy '' . Jersey has proposed that it be accorded `` self - representation in all Commonwealth meetings ; full participation in debates and procedures , with a right to speak where relevant and the opportunity to enter into discussions with those who are full members ; and no right to vote in the Ministerial or Heads of Government meetings , which is reserved for full members '' . The States of Guernsey and the Government of the Isle of Man have made calls of a similar nature for a more integrated relationship with the Commonwealth , including more direct representation and enhanced participation in Commonwealth organisations and meetings , including Commonwealth Heads of Government Meetings . The Chief Minister of the Isle of Man has said : `` A closer connection with the Commonwealth itself would be a welcome further development of the Island 's international relationships '' .\n",
      "0\n",
      "[(5050, 5342)]\n",
      "((6539, 6646), 'NO')\n",
      "\n",
      "['where can pulse be felt in the body']\n",
      "on the outside of an artery\n",
      "0\n",
      "[(825, 857), (840, 846)]\n",
      "((243, 474),)\n",
      "\n",
      "['i was a fugitive from a georgia chain gang']\n",
      "The book tells the story of Burns ' imprisonment on a chain gang in Georgia in the 1920s , his subsequent escape , and the furor that developed . The story was first published in January 1932 , serialized in True Detective Mysteries magazine . Later that year , Burns ' story was made into the motion picture I Am a Fugitive from a Chain Gang , starring Paul Muni . The book and movie were both credited with helping to reform deplorable conditions on Deep South chain gangs under Governor Ellis Arnall in 1943 .\n",
      "0\n",
      "[(104, 202)]\n",
      "()\n",
      "\n",
      "['where was 10 things i hate about you filmed school']\n",
      "The school was the filming location for many of the scenes of the 1999 movie 10 Things I Hate About You .\n",
      "0\n",
      "[(814, 838)]\n",
      "()\n",
      "\n",
      "['who held the most wwe titles at one time']\n",
      "John Cena\n",
      "0\n",
      "[(553, 629), (565, 567)]\n",
      "()\n",
      "\n",
      "['why did argentina attack the falklands/malvinas islands']\n",
      "in an attempt to establish the sovereignty it had claimed over them\n",
      "1\n",
      "[(499, 705), (617, 629)]\n",
      "((499, 705), (618, 629))\n",
      "\n",
      "['how long does it take for the moon to go around earth']\n",
      "approximately 27.3 days\n",
      "0\n",
      "[(1047, 1096), (1060, 1063)]\n",
      "((40, 313),)\n",
      "\n",
      "['where did the name las vegas golden knights come from']\n",
      "At the league owners ' meeting on June 22 , 2016 , in Las Vegas , the Las Vegas expansion bid was approved by a unanimous vote , with play to begin in the 2017 -- 18 NHL season . The team became the first major professional sports franchise to be based in Las Vegas , and the first NHL expansion team since 2000 . Foley committed to pay the league 's $500 million expansion fee and began the process of hiring the team 's principal staff and determining its official identity . Foley announced that former Washington Capitals general manager George McPhee would be the franchise 's first general manager . On November 22 , 2016 , the name was revealed as the Vegas Golden Knights .\n",
      "0\n",
      "[(956, 1086)]\n",
      "()\n",
      "\n",
      "['where does the last name aponte come from']\n",
      "Surname : Galician and Portuguese : from a misdivision of Daponte , a topographic name from da ponte ' from the bridge '\n",
      "0\n",
      "[(19, 44)]\n",
      "()\n",
      "\n",
      "['two words used together that mean the same thing']\n",
      "tautology\n",
      "0\n",
      "[(32, 84), (40, 41)]\n",
      "()\n",
      "\n",
      "['who is the prime minister of republic of mauritius']\n",
      "Pravind Jugnauth\n",
      "0\n",
      "[(693, 789), (701, 703)]\n",
      "((14, 182), (42, 44))\n",
      "\n",
      "['where does the movie the crucifixion take place']\n",
      "the forested garden of Gethsemane\n",
      "0\n",
      "[(789, 952), (797, 802)]\n",
      "()\n",
      "\n",
      "['what teams are in the fa cup final']\n",
      "Manchester United and Chelsea\n",
      "1\n",
      "[(159, 231), (208, 212)]\n",
      "((159, 231), (208, 210), (211, 212))\n",
      "\n",
      "[\"where is a midsummer night's dream set\"]\n",
      "in the woodland and in the realm of Fairyland\n",
      "1\n",
      "[(563, 613), (595, 604)]\n",
      "((563, 613), (595, 604))\n",
      "\n",
      "['purpose of valuation determines the method of valuation']\n",
      "In finance , valuation is the process of determining the present value ( PV ) of an asset . Valuations can be done on assets ( for example , investments in marketable securities such as stocks , options , business enterprises , or intangible assets such as patents and trademarks ) or on liabilities ( e.g. , bonds issued by a company ) . Valuations are needed for many reasons such as investment analysis , capital budgeting , merger and acquisition transactions , financial reporting , taxable events to determine the proper tax liability , and in litigation .\n",
      "0\n",
      "[(461, 562)]\n",
      "()\n",
      "\n",
      "['when does the new series of black sails start']\n",
      "Black Sails is an American television drama series created by Jon Steinberg and Robert Levine for Starz that debuted on January 25 , 2014 . It is produced by Film Afrika Worldwide and Platinum Dunes . It is written as a prequel to Robert Louis Stevenson 's novel Treasure Island . The series was renewed for a fourth season on July 31 , 2015 , before the third season had premiered . On July 20 , 2016 , Starz announced that the series ' fourth season would be its last ; the season premiered on January 29 , 2017 and concluded on April 2 , 2017 . During the course of the series , 38 episodes of Black Sails aired over four seasons .\n",
      "1\n",
      "[(16, 142)]\n",
      "((16, 142),)\n",
      "\n",
      "['who has scored the most goals in a premier league season']\n",
      "Manchester City\n",
      "0\n",
      "[(1743, 2206), (1754, 1756)]\n",
      "()\n",
      "\n",
      "['god father mobster who was shot in the eye']\n",
      "In the novel , Greene is murdered shortly afterward by Al Neri . In the end of the film , Michael has Greene killed as part of his mass slaughter of the Corleone family 's enemies . An unknown assassin surprises Greene while he is getting a massage and shoots him through the eye . Greene 's casinos then become property of the Corleone family .\n",
      "0\n",
      "[(519, 587)]\n",
      "()\n",
      "\n",
      "['who is the first person who went to moon']\n",
      "Neil Alden Armstrong\n",
      "1\n",
      "[(256, 304), (257, 260)]\n",
      "((256, 304), (257, 260))\n",
      "\n",
      "['where did britain create colonies for its empire']\n",
      "Americas and Asia\n",
      "0\n",
      "[(250, 383), (310, 313)]\n",
      "()\n",
      "\n",
      "['when did the first lego movie come out']\n",
      "2014\n",
      "0\n",
      "[(2402, 2452), (2408, 2409)]\n",
      "((754, 840), (778, 781))\n",
      "\n",
      "['are pure metals made of atoms or ions']\n",
      "atoms\n",
      "1\n",
      "[(1425, 1517), (1427, 1428)]\n",
      "((1425, 1517), (1427, 1428))\n",
      "\n",
      "['what episode in victorious is give it up']\n",
      "Episode Title Performed by Single Season Soundtrack `` Pilot '' `` Make It Shine '' Tori Vega Yes Victorious `` The Birthweek Song '' `` You 're the Reason '' Tori Vega Yes Victorious `` Jade Dumps Beck '' `` Chicago '' Trina Vega No N / A `` Tori the Zombie '' `` Finally Falling '' Tori Vega and Beck Oliver Yes Victorious `` Survival of the Hottest '' `` Make It Shine '' `` Victorious '' Cast No N / A `` Wi - Fi in the Sky '' `` You 're the Reason '' Trina Vega No N / A `` The Great Ping Pong Scam '' `` Tell Me That You Love Me '' Tori Vega and Andre Harris Yes Victorious `` Freak the Freak Out '' `` Forever Baby '' Robbie Shapiro and Rex Powers No N / A `` Number One '' ( A.K.A. `` My World '' ) Hayley , Tara in a duet Sikowitz in a solo No N / A `` Give It Up '' Cat Valentine and Jade West Yes Victorious `` Hate Me , Love Me '' Hayley and Tara No N / A `` Freak the Freak Out '' Tori Vega Yes Victorious `` Rex Dies '' `` Forever Baby '' Tori Vega , Robbie Shapiro and Rex Powers No N / A `` The Diddly - Bops '' `` Broken Glass\n",
      "1\n",
      "[(81, 1656)]\n",
      "((81, 1656), (322, 326))\n",
      "\n",
      "['movement of molecules across a membrane powered by atp']\n",
      "Active transport\n",
      "1\n",
      "[(32, 119), (33, 35)]\n",
      "((32, 119), (84, 87))\n",
      "\n",
      "['who sold manhattan to the dutch in 1626']\n",
      "Minuit is generally credited with orchestrating the purchase of Manhattan Island for the Dutch from the Lenape Native Americans . Manhattan later became the site of the Dutch city of New Amsterdam , and the borough of Manhattan of modern - day New York City . A common account states that Minuit purchased Manhattan for $24 worth of trinkets . A letter written by Dutch merchant Peter Schaghen to directors of the Dutch East India Company stated that Manhattan was purchased `` for the value of 60 guilders '' in goods , an amount worth approximately $1,050 in 2015 dollars .\n",
      "0\n",
      "[(204, 307)]\n",
      "((780, 846), (816, 822))\n",
      "\n",
      "['city of stars are you shining just for me meaning']\n",
      "`` ( The song ) started at the piano with me just working on demos for Damien , sending him ideas until something really sparked . It 's so funny that that and `` Audition '' are the two songs that people seem to be responding to the most , at least so far , because they had similar processes in the sense that they had probably the least amount of fussing at the piano demo stage . ( ... ) I was just composing it from an emotional place and thinking about the tone . I would say the tone is hopeful , but melancholy at the same time . And it kind of goes back - and - forth between cadencing in major and cadencing in minor , because I think that 's kind of what the song is about . You have these great moments and then you have these less great moments in life and in Los Angeles and we see it happen in the story . I was thinking about that idea a little bit and just trying to compose a melody that I thought was shapely and beautiful . I guess it has some jazz inflections , because it 's something Sebastian plays on the piano . ''\n",
      "0\n",
      "[(395, 619)]\n",
      "((396, 618),)\n",
      "\n",
      "['who have been the winners of ink master']\n",
      "Season Contestants Winner Runner Up Third Place Prizes First Aired Last Aired Judges ( chair order ) 10 Shane O'Neill Tommy Helm James Vaughn Title of Ink Master $100,000 Feature in Inked magazine January 17 , 2012 March 6 , 2012 Oliver Peck Dave Navarro Chris Nuñez 16 Steve Tefft Sarah Miller Sebastian Murphy October 9 , 2012 December 18 , 2012 16 Joey Hamilton Jime Litwalk Katherine `` Tatu Baby '' Flores July 16 , 2013 October 8 , 2013 17 Scott Marshall Walter `` Sausage '' Frank Matti Hixson February 25 , 2014 May 20 , 2014 5 16 Jason Clay Dunn Cleen Rock One Erik Siuda September 2 , 2014 December 16 , 2014 6 18 Dave Kruseman Chris Blinston Matt O'Baugh Title of Ink Master $100,000 Feature in Inked magazine 2015 Dodge Challenger June 23 , 2015 October 13 , 2015 7 16 Anthony Michaels Cleen Rock One Christian Buckingham Title of Ink Master $100,000 Feature in Inked magazine March 1 , 2016 May 24 , 2016 8 18 Ryan Ashley Malarkey Gian\n",
      "1\n",
      "[(1467, 1973)]\n",
      "((1467, 1973),)\n",
      "\n",
      "['what percentage of the united states is forested']\n",
      "Rank State Percent 7000100000000000000 ♠ 1 Maine 89.0 % 7000200000000000000 ♠ 2 New Hampshire 77.5 % 7000300000000000000 ♠ 3 West Virginia 77.2 % 7000400000000000000 ♠ 4 Vermont 75.7 % 7000500000000000000 ♠ 5 Alabama 70.6 % 7000600000000000000 ♠ 6 Georgia 64.2 % 7000700000000000000 ♠ 7 South Carolina 63.8 % 7000800000000000000 ♠ 8 Mississippi 61.9 % 7000900000000000000 ♠ 9 Virginia 60.7 % 7001100000000000000 ♠ 10 North Carolina 59.9 % 7001110000000000000 ♠ 11 Pennsylvania 55.3 % 7001120000000000000 ♠ 12 Arkansas 55.1 % 7001130000000000000 ♠ 13 Connecticut 54.7 % 7001140000000000000 ♠ 14 Tennessee 52.9 % 7001150000000000000 ♠ 15 Massachusetts 52.5 % 7001160000000000000 ♠ 16 Michigan 51.2 % 7001170000000000000 ♠ 17 New\n",
      "0\n",
      "[(116, 839)]\n",
      "()\n",
      "\n",
      "['what year did the movie deuces come out']\n",
      "2017\n",
      "1\n",
      "[(178, 233), (230, 231)]\n",
      "((178, 233), (230, 231))\n",
      "\n",
      "['who is the present sport minister of india']\n",
      "Rajyavardhan Singh Rathore\n",
      "0\n",
      "[(916, 1049), (1037, 1040)]\n",
      "((182, 247), (243, 246))\n",
      "\n",
      "['who has the most followers on instagram in the world']\n",
      "Instagram\n",
      "0\n",
      "[(926, 1326), (970, 971)]\n",
      "((194, 884), (234, 235))\n",
      "\n",
      "['where was life or something like it filmed']\n",
      "Seattle , Washington although portions were filmed in downtown Vancouver\n",
      "1\n",
      "[(1126, 1200), (1137, 1147)]\n",
      "((1126, 1200), (1137, 1140), (1145, 1147))\n",
      "\n",
      "['the highest post in police department of karnataka state is']\n",
      "Director General and Inspector General of Police ( DG&IGP )\n",
      "1\n",
      "[(539, 609), (541, 551)]\n",
      "((539, 609), (540, 551))\n",
      "\n",
      "['is it a bank holiday today in spain']\n",
      "Autonomous communities Date English name Native name January 1 New Year 's Day ( national holiday ) Año Nuevo Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y January 6 Epiphany ( national holiday ) Día de Reyes / Epifanía del Señor Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y February 28 Regional Holiday Día de Andalucía Y March 1 Regional Holiday Dia de les Illes Balears Y March 19 St. Joseph 's Day San José ML Y Y Y Y Y Y Y Y Y March or April Maundy Thursday Jueves Santo Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Good Friday ( national holiday ) Viernes Santo Y Y Y Y Y Y Y Y Y Y Y Y Y Y\n",
      "1\n",
      "[(201, 2334)]\n",
      "((201, 2334), 'NO')\n",
      "\n",
      "['1970 world cup semi final italy vs germany']\n",
      "The semi-final of the 1970 FIFA World Cup between Italy and West Germany is known as the `` Game of the Century '' ( Spanish : Partido del Siglo ; Italian : Partita del secolo ; German : Jahrhundertspiel ) . It was played on 17 June 1970 at the Estadio Azteca in Mexico City . Italy won 4 -- 3 after five goals were scored in extra time , a record number of scored goals during any 2x15 minute extra time during a FIFA World Cup game . The record is still standing after the 2018 World Cup . Four goals in extra time were scored in the 1982 semifinal between West Germany and France .\n",
      "0\n",
      "[(190, 309)]\n",
      "()\n",
      "\n",
      "['who played the bank robber in dirty harry']\n",
      "Popwell was featured on many television series , but is perhaps best known for his appearances in films opposite Clint Eastwood , whom he acted with in five films , starting with Coogan 's Bluff and in the first four films of the Dirty Harry series . Popwell was a wounded bank robber at the receiving end of Eastwood 's `` Do you feel lucky ? '' monologue from Dirty Harry . Popwell was a murderous pimp in Magnum Force , appeared as Big Ed Mustapha in The Enforcer and as Harry 's detective colleague Horace King in Sudden Impact . He did not appear in the last film in the series , The Dead Pool , due to a scheduling conflict .\n",
      "0\n",
      "[(211, 336)]\n",
      "((393, 406),)\n",
      "\n",
      "['what is the worth of the catholic church']\n",
      "$140 billion\n",
      "1\n",
      "[(273, 386), (294, 296)]\n",
      "((273, 386), (294, 297))\n",
      "\n",
      "['how many classes do u have to fail to get held back']\n",
      "more than 114\n",
      "0\n",
      "[(1522, 1568), (1555, 1558)]\n",
      "()\n",
      "\n",
      "['where is the best farming soil in the us and where did all the dirt come from']\n",
      "The Black Dirt Region takes its name from the dark , extremely fertile soil left over from an ancient glacial lake bottom augmented by decades of past flooding of the Wallkill River . The 26,000 acres ( 10,400 ha ) of muck left over is the largest concentration of such soil in the United States outside the Florida Everglades .\n",
      "1\n",
      "[(141, 203)]\n",
      "((141, 203), (142, 146), (158, 174))\n",
      "\n",
      "['the pair of hand drums used in indian classical music is called']\n",
      "tabla\n",
      "0\n",
      "[(106, 226), (108, 109)]\n",
      "((226, 449), (228, 229))\n",
      "\n",
      "['where does the term petty officer come from']\n",
      "The modern petty officer dates back to the Age of Sail . Petty officers rank between naval officers ( both commissioned and warrant ) and most enlisted sailors . These were men with some claim to officer rank , sufficient to distinguish them from ordinary ratings , without raising them so high as the sea officers . Several were warrant officers , in the literal sense of being appointed by warrant , and like the warrant sea officers , their superiors , they were usually among the specialists of the ship 's company . The Oxford English Dictionary suggests that the title derives from the Anglo - Norman and Middle French `` petit '' , meaning `` of small size , small , little '' .\n",
      "1\n",
      "[(493, 621)]\n",
      "((493, 621), (502, 505))\n",
      "\n",
      "['what is the name of god the father']\n",
      "God the Father is a title given to God in various religions , most prominently in Christianity . In mainstream trinitarian Christianity , God the Father is regarded as the first person of the Trinity , followed by the second person God the Son ( Jesus Christ ) and the third person God the Holy Spirit . Since the second century , Christian creeds included affirmation of belief in `` God the Father ( Almighty ) '' , primarily as his capacity as `` Father and creator of the universe '' . Yet , in Christianity the concept of God as the father of Jesus Christ goes metaphysically further than the concept of God as the Creator and father of all people , as indicated in the Apostle 's Creed where the expression of belief in the `` Father almighty , creator of heaven and earth '' is immediately , but separately followed by in `` Jesus Christ , his only Son , our Lord '' , thus expressing both senses of fatherhood .\n",
      "0\n",
      "[(828, 1004)]\n",
      "()\n",
      "\n",
      "['what does the name erica mean in hebrew']\n",
      "`` sole ruler , autocrat '' or `` eternal ruler , ever powerful ''\n",
      "0\n",
      "[(129, 275), (259, 273)]\n",
      "()\n",
      "\n",
      "['what do the colors of the olympic rings mean']\n",
      "The current view of the International Olympic Committee ( IOC ) is that the symbol `` reinforces the idea '' that the Olympic Movement is international and welcomes all countries of the world to join . As can be read in the Olympic Charter , the Olympic symbol represents the union of the `` five continents '' of the world and the meeting of athletes from throughout the world at the Olympic Games . However , no continent is represented by any specific ring . Prior to 1951 , the official handbook stated that each colour corresponded to a particular continent : blue for Europe , yellow for Asia , black for Africa , green for Australia and Oceania and red for the Americas ; this was removed because there was no evidence that Coubertin had intended it ( the quotation above was probably an afterthought ) . Nevertheless , the logo of the Association of National Olympic Committees places the logo of each of its five continental associations inside the ring of the corresponding colour .\n",
      "0\n",
      "[(1067, 1246)]\n",
      "((515, 629),)\n",
      "\n",
      "['where is israel located on the world map']\n",
      "Israel ( / ˈɪzreɪəl / ; Hebrew : יִשְׂרָאֵל ‎ , Arabic : إِسْرَائِيل ‎ ‎ ) , officially the State of Israel ( Hebrew : מְדִינַת יִשְׂרָאֵל ‎ , Arabic : دَوْلَة إِسْرَائِيل ‎ ‎ ) , is a country in the Middle East , on the southeastern shore of the Mediterranean Sea and the northern shore of the Red Sea . It has land borders with Lebanon to the north , Syria to the northeast , Jordan on the east , the Palestinian territories of the West Bank and Gaza Strip to the east and west , respectively , and Egypt to the southwest . The country contains geographically diverse features within its relatively small area . Israel 's economy and technology center is Tel Aviv , while its seat of government and proclaimed capital is Jerusalem , although the state 's sovereignty over East Jerusalem is not recognised internationally .\n",
      "1\n",
      "[(677, 832)]\n",
      "((677, 832), (720, 740))\n",
      "\n",
      "['who played smiley in tinker tailor soldier spy']\n",
      "Gary Oldman\n",
      "1\n",
      "[(341, 448), (386, 388)]\n",
      "((341, 448), (386, 388))\n",
      "\n",
      "['is the micrometer screw gauge used for measurement of inner diameter of tube']\n",
      "A micrometer ( / maɪˈkrɒmɪtər / my - KROM - i - tər ) , sometimes known as a micrometer screw gauge , is a device incorporating a calibrated screw widely used for precise measurement of components in mechanical engineering and machining as well as most mechanical trades , along with other metrological instruments such as dial , vernier , and digital calipers . Micrometers are usually , but not always , in the form of calipers ( opposing ends joined by a frame ) , which is why micrometer caliper is another common name . In Newton 's second law of motion , he clearly stated that the solution to appropriating micrometer methods was to assume that the change in momentum is brought about by and external resultant force and this resultant force is proportional to the change in momentum which it constitutes . The spindle is a very accurately machined screw and the object to be measured is placed between the spindle and the anvil . The spindle is moved by turning the ratchet knob or thimble until the object to be measured is lightly touched by both the spindle and the anvil .\n",
      "0\n",
      "[(59, 257)]\n",
      "((1353, 1376), 'YES')\n",
      "\n",
      "['who opened and closed the 1960 winter olympics']\n",
      "VIII Olympic Winter Games The emblem represents a star or snowflake , and the Olympic rings . Host city Squaw Valley , California , United States Nations participating 30 Athletes participating 665 ( 521 men , 144 women ) Events 27 in 4 sports ( 8 disciplines ) Opening ceremony 18 February Closing ceremony 28 February Officially opened by Vice President Richard Nixon Athlete 's Oath Carol Heiss Olympic Torch Ken Henry Stadium Blyth Arena Winter Cortina 1956 Innsbruck 1964 > Summer Melbourne 1956 Rome 1960 >\n",
      "0\n",
      "[(16, 203)]\n",
      "()\n",
      "\n",
      "['when does brennan get pregnant the first time']\n",
      "episode 7 , `` The Prisoner in the Pipe ''\n",
      "0\n",
      "[(6760, 7255), (6944, 6954)]\n",
      "((2794, 2865), (2844, 2847))\n",
      "\n",
      "['a bandage is a sterile covering for a wound']\n",
      "A dressing is a sterile pad or compress applied to a wound to promote healing and protect the wound from further harm . A dressing is designed to be in direct contact with the wound , as distinguished from a bandage , which is most often used to hold a dressing in place . Many modern dressings are self - adhesive .\n",
      "0\n",
      "[(40, 104)]\n",
      "()\n",
      "\n",
      "[\"when did season 2 of handmaid's tale start\"]\n",
      "April 25 , 2018\n",
      "0\n",
      "[(445, 493), (487, 491)]\n",
      "((2597, 2691), (2664, 2668))\n",
      "\n",
      "['i see the river tiber foaming with much blood']\n",
      "On 20 April 1968 , British Member of Parliament Enoch Powell addressed a meeting of the Conservative Political Centre in Birmingham , UK . His speech strongly criticised Commonwealth immigration to the United Kingdom and the then - proposed Race Relations Bill , and became known as the `` Rivers of Blood '' speech , although Powell always referred to it as `` the Birmingham speech '' . The expression `` rivers of blood '' , which did not appear in the original speech , is an allusion to a line from Virgil 's Aeneid quoted by Powell ( `` As I look ahead , I am filled with foreboding ; like the Roman , I seem to see the River Tiber foaming with much blood '' ) .\n",
      "0\n",
      "[(49, 180)]\n",
      "()\n",
      "\n",
      "['what causes a dead zone in the ocean']\n",
      "an increase in chemical nutrients ( particularly nitrogen and phosphorus ) in the water , known as eutrophication\n",
      "0\n",
      "[(680, 771), (690, 708)]\n",
      "((108, 214), (131, 145))\n",
      "\n",
      "['who is the present governor of puerto rico']\n",
      "Alejandro Javier García Padilla\n",
      "1\n",
      "[(316, 448), (317, 321)]\n",
      "((316, 448), (317, 321))\n",
      "\n",
      "['what affect does acetylcholine have on the sarcolemma']\n",
      "depolarize the muscle fiber , causing a cascade that eventually results in muscle contraction\n",
      "1\n",
      "[(421, 593), (577, 591)]\n",
      "((421, 593), (576, 591))\n",
      "\n",
      "[\"who plays claire underwood's mom on house of cards\"]\n",
      "Ellen Burstyn\n",
      "1\n",
      "[(480, 612), (595, 597)]\n",
      "((480, 612), (595, 597))\n",
      "\n",
      "['who won the all ireland football final 2017']\n",
      "Dublin\n",
      "1\n",
      "[(388, 427), (389, 390)]\n",
      "((388, 427), (389, 390))\n",
      "\n",
      "['who played robbie douglas wife on my three sons']\n",
      "Tina Cole\n",
      "1\n",
      "[(1944, 2269), (2093, 2095)]\n",
      "((1944, 2269), (2093, 2095))\n",
      "\n",
      "['who hit the most 3 pointers in a nba game']\n",
      "Stephen Curry\n",
      "1\n",
      "[(922, 954), (928, 930)]\n",
      "((922, 954), (926, 927))\n",
      "\n",
      "['what type of fish live in the pacific ocean']\n",
      "Ablabys macracanthus Abyssobrotula Abyssobrotula galatheae Acantholiparis caecus Acantholiparis opercularis Alaska blackfish Alaska pollock Albula argentea Albula pacifica Alcichthys elongatus Alfonsino Amblygaster clupeoides Amur stickleback Anarchias Anarchias allardicei Anarchias cantonensis Anarchias exulatus Anarchias galapagensis Anarchias leucurus Anarchias schultzi Anarchias seychellensis Anarchias supremus Anchoviella Pacific angelshark Arc - eye hawkfish Arctic grayling Arctoscopus japonicus Argentina elongata Arius subrostratus Arius sumatranus Arrow dragonet Arrowtooth lizardfish Artedius corallinus Artedius fenestralis Artedius harringtoni Artedius lateralis Artedius notospilotus Aulastomatomorpha phospherops Aulotrachichthys heptalepis Australian anchovy Awaous guamensis Azurio tuskfin\n",
      "0\n",
      "[(149, 317)]\n",
      "()\n",
      "\n",
      "[\"who dies in season 2 grey's anatomy\"]\n",
      "Jeffrey Dean Morgan\n",
      "0\n",
      "[(3748, 4156), (3909, 3912)]\n",
      "()\n",
      "\n",
      "['the most common system of land title in australia']\n",
      "Torrens title\n",
      "1\n",
      "[(407, 531), (408, 410)]\n",
      "((407, 531), (408, 410))\n",
      "\n",
      "['who sings with jackson brown on the load out']\n",
      "David Lindley\n",
      "1\n",
      "[(334, 443), (381, 383)]\n",
      "((334, 443), (428, 430), (381, 383))\n",
      "\n",
      "['who has scored most runs in t20 international innings']\n",
      "Brendon McCullum\n",
      "0\n",
      "[(5250, 5388), (5278, 5280)]\n",
      "((9456, 9698),)\n",
      "\n",
      "[\"what happens to dr shepherd on grey's\"]\n",
      "a fatal car accident\n",
      "1\n",
      "[(2060, 2239), (2069, 2073)]\n",
      "((2060, 2239), (2069, 2073))\n",
      "\n",
      "['what is the t rex name in land before time']\n",
      "Littlefoot\n",
      "0\n",
      "[(1139, 1356), (1140, 1141)]\n",
      "()\n",
      "\n",
      "['who recorded the song i love rock and roll']\n",
      "the Arrows\n",
      "0\n",
      "[(311, 380), (332, 334)]\n",
      "()\n",
      "\n",
      "['when does book 2 of the 100 come out']\n",
      "September 25 , 2014\n",
      "1\n",
      "[(132, 214), (184, 188)]\n",
      "((132, 214), (183, 188))\n",
      "\n",
      "['when did the nissan armada body style change']\n",
      "early 2007 for the 2008 model year\n",
      "0\n",
      "[(552, 792), (783, 790)]\n",
      "((1575, 1736), (1580, 1581))\n",
      "\n",
      "['who plays allens mom on this is us']\n",
      "Nancy Ann Travis\n",
      "0\n",
      "[(133, 212), (134, 137)]\n",
      "()\n",
      "\n",
      "['where does the name down syndrome come from']\n",
      "John Langdon Down , the British doctor who fully described the syndrome in 1866\n",
      "1\n",
      "[(495, 606), (548, 562)]\n",
      "((495, 606), (548, 562))\n",
      "\n",
      "['what does the red stripe on the marine uniform mean']\n",
      "Tradition holds that in the Battle of Chapultepec in Mexico on September 1847 , Marine officers and NCOs sustained an unusually high casualty rate during the battle . In 1849 , uniform regulations dictated that the stripes be changed to a solid red in honor of the numerous Marine deaths . Ten years later , a scarlet cord was inserted into the outer seams for noncommissioned officers and musicians , while a scarlet welt was added for officers . Finally , in 1904 , the simple scarlet stripe seen today was adopted , with the varying widths prescribed for different ranks .\n",
      "1\n",
      "[(348, 452)]\n",
      "((348, 452),)\n",
      "\n",
      "['the number on kiss me thru the phone']\n",
      "678 - 999 - 8212\n",
      "1\n",
      "[(1522, 1625), (1527, 1532)]\n",
      "((1522, 1625), (1527, 1532))\n",
      "\n",
      "['when does the regular football season start for nfl']\n",
      "September 7 , 2017\n",
      "1\n",
      "[(191, 278), (218, 222)]\n",
      "((191, 278), (218, 222))\n",
      "\n",
      "['who does oregon state play in the college world series']\n",
      "Arkansas\n",
      "1\n",
      "[(1421, 3559), (3548, 3549)]\n",
      "((1421, 3559), (3548, 3549))\n",
      "\n",
      "['who played in the last 3 nba finals']\n",
      "Golden State Warriors\n",
      "1\n",
      "[(1273, 3106), (3083, 3086)]\n",
      "((1273, 3106),)\n",
      "\n",
      "['uk national debt as percentage of gdp by year']\n",
      "81.58 %\n",
      "0\n",
      "[(622, 761), (644, 646)]\n",
      "()\n",
      "\n",
      "['how many solar eclipses are there in usa']\n",
      "Future total solar eclipses will cross the United States in April 2024 ( 12 states ) and August 2045 ( 10 states ) , and annular solar eclipses -- wherein the Moon appears smaller than the Sun -- will occur in October 2023 ( 9 states ) and June 2048 ( 9 states ) .\n",
      "0\n",
      "[(682, 739)]\n",
      "()\n",
      "\n",
      "['in order to be a new state a territory had to have a population of at least']\n",
      "sixty thousand\n",
      "0\n",
      "[(1356, 1509), (1505, 1507)]\n",
      "()\n",
      "\n",
      "['who sold more albums elvis or micheal jackson']\n",
      "Michael Jackson\n",
      "1\n",
      "[(205, 230), (206, 208)]\n",
      "((205, 230), (206, 208))\n",
      "\n",
      "['who plays officer garcia in santa clarita diet']\n",
      "Natalie Morales\n",
      "1\n",
      "[(834, 1213), (994, 996)]\n",
      "((993, 1025), (994, 996))\n",
      "\n",
      "['when was the great pyramid of giza created']\n",
      "over a 10 to 20 - year period concluding around 2560 BC\n",
      "1\n",
      "[(401, 565), (434, 446)]\n",
      "((401, 565), (436, 446))\n",
      "\n",
      "['who plays ridge forrester on the bold and the beautiful']\n",
      "In 2012 , Kaye began appearing in the role of Nick , a recurring character on the NBC series Smash . In October 2013 , it was announced that Kaye was cast to portray Ridge Forrester on The Bold and the Beautiful , replacing originator Ronn Moss , who departed the series in 2012 after 25 years in the role .\n",
      "0\n",
      "[(809, 872)]\n",
      "()\n",
      "\n",
      "['who sang theres a rat in my kitchen']\n",
      "UB40\n",
      "1\n",
      "[(211, 272), (230, 231)]\n",
      "((211, 272), (230, 231))\n",
      "\n",
      "[\"the contribution of agriculture in india's gross domestic product is\"]\n",
      "13.7 %\n",
      "1\n",
      "[(158, 270), (203, 205)]\n",
      "((158, 270), (203, 208))\n",
      "\n",
      "[\"who's doing the halftime show in 2018\"]\n",
      "Justin Timberlake\n",
      "1\n",
      "[(151, 224), (193, 195)]\n",
      "((151, 224), (193, 195))\n",
      "\n",
      "['reasons why south africa should include renewable energy in its energy mix']\n",
      "The two main barriers accompanying renewable energy in South Africa are ; the energy innovation system , and the high cost of renewable energy technologies . The Renewable Energy Independent Power Producers Procurement Programme ( REI4P ) suggests that the cost associated with renewable energy will equal the cost of non-renewable energy by 2030 . Renewable energy is becoming more efficient , inexpensive , and widely used . South Africa has an abundance of renewable resources that can effectively supply the country 's energy .\n",
      "1\n",
      "[(339, 426)]\n",
      "((339, 426),)\n",
      "\n",
      "['who was the former army chief of staff who was elected president of syria']\n",
      "Adib Bin Hassan Al - Shishakli\n",
      "0\n",
      "[(246, 291), (247, 253)]\n",
      "()\n",
      "\n",
      "['what are the functions of the lok sabha']\n",
      "The Lok Sabha ( House of the People ) is the lower house of India 's bicameral Parliament , with the upper house being the Rajya Sabha . Members of the Lok Sabha are elected by adult universal suffrage and a first - past - the - post system to represent their respective constituencies , and they hold their seats for five years or until the body is dissolved by the President on\n",
      "0\n",
      "[(723, 822)]\n",
      "((2658, 3284),)\n",
      "\n",
      "['when was the first freeway built in los angeles']\n",
      "1940\n",
      "1\n",
      "[(452, 565), (501, 502)]\n",
      "((452, 565), (501, 502))\n",
      "\n",
      "['where is a good year filmed with russell crowe']\n",
      "The film was shot throughout nine weeks in 2005 , mostly in locations Scott described as `` eight minutes from my house '' . French locations were filmed at Bonnieux , Cucuron and Gordes in Vaucluse , Marseille Provence Airport , and the rail station in Avignon . London locations included Albion Riverside in Battersea , Broadgate , the Bluebird Cafe on King 's Road in Chelsea , and Criterion Restaurant in Piccadilly Circus . The scene with the tennis match between Max and Duflot was added on the set , replacing an argument at the vines to provide `` a battle scene '' . As the swimming pool on Chateau La Canorgue did not fit the one Scott had envisioned from the scene , only the scenes outside the pool were filmed there . The one after Max had fallen was dug and concreted nearby , and the original one had its bottom replaced digitally to match . The production team could not film the wine cave from La Canorgue as they shot during the period where it was being used , so the wine cellar from a nearby hotel was turned into a cave . While southern France does not have clay courts as the weather makes them hard to maintain , Scott wanted one for its dirty and beaten up aspect , so the tennis court was built from scratch , including posts straight from the Wimbledon courts . Fanny 's cafe was shot in a Gordes restaurant , with designer Sonja Klaus decorating it\n",
      "1\n",
      "[(2010, 2356)]\n",
      "((2010, 2356),)\n",
      "\n",
      "['who is running for govenor of south carolina']\n",
      "Henry McMaster James Smith\n",
      "0\n",
      "[(16, 128), (67, 73)]\n",
      "()\n",
      "\n",
      "['landmark supreme court cases dealing with the first amendment']\n",
      "United States v. O'Brien ( 1968 ) Cohen v. California ( 1972 ) Texas v. Johnson ( 1989 ) United States v. Eichman ( 1990 ) City of Erie v. Pap 's A.M. ( 2000 ) Virginia v. Black ( 2003\n",
      "0\n",
      "[(2138, 2194)]\n",
      "()\n",
      "\n",
      "['when was the wizard of oz made in technicolor']\n",
      "October 1938 to March 1939\n",
      "0\n",
      "[(5083, 5255), (5106, 5111)]\n",
      "((443, 559), (529, 530))\n",
      "\n",
      "['when did penny and leonard first get together']\n",
      "During dinner Leonard asks Penny whether there is a name for a first - date with someone you used to date and Penny replies `` awkward . '' They decide to make - believe like they are on a real first date . Leonard tells Penny about his work and that he built a Bat - Signal . Penny laughs and asks him if he is some kind of nerd . Leonard says that he is the `` King of the Nerds '' . If anyone displeases him , he will not help them set - up their printer . Leonard then asks Penny whether they are going to get back together . Shocked Penny confesses that she will always have feelings for him and that he always over thinks everything .\n",
      "0\n",
      "[(539, 673)]\n",
      "()\n",
      "\n",
      "['number of red card in world cup 2018']\n",
      "4\n",
      "1\n",
      "[(292, 652), (318, 319)]\n",
      "((292, 652), (318, 319))\n",
      "\n",
      "['where did the name of the black panther party come from']\n",
      "In 1968 , the group shortened its name to the Black Panther Party and sought to focus directly on political action . Members were encouraged to carry guns and to defend themselves against violence . An influx of college students joined the group , which had consisted chiefly of `` brothers off the block '' . This created some tension in the group . Some members were more interested in supporting the Panthers ' social programs , while others wanted to maintain their `` street mentality '' .\n",
      "0\n",
      "[(5247, 5337)]\n",
      "()\n",
      "\n",
      "['where does the solar eclipse start and end']\n",
      "The total eclipse had a magnitude of 1.0306 and was visible within a narrow corridor 70 miles ( 110 km ) wide , crossing fourteen of the contiguous United States : Oregon , Idaho , Montana , Wyoming , Nebraska , Kansas , Iowa , Missouri , Illinois , Kentucky , Tennessee , Georgia , North Carolina , and South Carolina . It was first seen from land in the U.S. shortly after 10 : 15 a.m. PDT ( 17 : 15 UTC ) at Oregon 's Pacific coast , and then it progressed eastward through Salem , Oregon ; Idaho Falls , Idaho ; Casper , Wyoming ; Lincoln , Nebraska ; Kansas City , Missouri ; St. Louis , Missouri ; Hopkinsville , Kentucky ; Nashville , Tennessee ; Columbia , South Carolina about 2 : 41 p.m. ; and finally Charleston , South Carolina . A partial eclipse was seen for a greater time period , beginning shortly after 9 : 00 a.m. PDT along the Pacific Coast of Oregon . Weather forecasts predicted clear skies in Western U.S. and some Eastern states , but clouds in the Midwest and East Coast .\n",
      "0\n",
      "[(1044, 1242)]\n",
      "((269, 370), (308, 313))\n",
      "\n",
      "['who sings nobody loves you like i do']\n",
      "Anne Murray and singer - songwriter Dave Loggins\n",
      "0\n",
      "[(244, 301), (271, 279)]\n",
      "()\n",
      "\n",
      "['where is the movie call me by your name filmed']\n",
      "Crema , Italy\n",
      "0\n",
      "[(519, 620), (598, 601)]\n",
      "()\n",
      "\n",
      "['where did the laguna cast go to college']\n",
      "Fashion Institute of Design & Merchandising\n",
      "0\n",
      "[(2474, 2651), (2564, 2570)]\n",
      "()\n",
      "\n",
      "['when was the last time ferrari won at monza']\n",
      "2010\n",
      "0\n",
      "[(5721, 6003), (5780, 5781)]\n",
      "()\n",
      "\n",
      "['lab rats elite force why did it end']\n",
      "No . Title Directed by Written by Original air date Prod . code U.S. viewers ( millions ) `` The Rise of Five '' Guy Distad Chris Peterson & Bryan Moore March 2 , 2016 ( 2016 - 03 - 02 ) 101 0.52 Following the events of the Lab Rats series finale , Davenport introduces Chase and Bree to their new team 's headquarters and teammates , Kaz , Oliver , and Skylar , in Centium City , who together form the Elite Force . Kaz immediately wants to find the people who recently destroyed Mighty Med , while the others want to come up with a plan first . A mysterious box then breaks through the window , which contains a flash drive that shows a video of the people responsible for the destruction of Mighty Med , who declare that Kaz , Oliver , and Skylar will be eliminated as well as anyone else who protects them . Kaz runs off to find the culprits and meets them in an alley , but he is surprised to find out that they are shapeshifters Roman and Riker , the sons of a former superhero named Rodissius , whose superpowers Kaz and Oliver had earlier taken away in order to save his life . As such , Roman and Riker want to eliminate Kaz and Oliver to get revenge . A confrontation between them and the Elite Force ensues , but the Elite Force is eventually knocked out cold and Roman and Riker take Skylar away . The rest of the team later locates Skylar , Roman , and Riker , and Oliver freezes the cloud that Roman and Riker\n",
      "0\n",
      "[(978, 5619)]\n",
      "()\n",
      "\n",
      "['where does the last name vigil come from']\n",
      "Vigil ( Vee - HILL ) is a Spanish surname . Notable people with the surname include :\n",
      "1\n",
      "[(18, 38), (19, 37)]\n",
      "((18, 38),)\n",
      "\n",
      "['who has laid in state at the capitol']\n",
      "Ex-governors general\n",
      "0\n",
      "[(196, 354), (243, 245)]\n",
      "((2034, 2481),)\n",
      "\n",
      "['who was president of the united states in 1938']\n",
      "Franklin D. Roosevelt\n",
      "1\n",
      "[(201, 277), (205, 208)]\n",
      "((202, 215), (205, 208))\n",
      "\n",
      "['what is the meaning of the name melanesia']\n",
      "`` islands of black ( people ) '' , in reference to the dark skin of the inhabitants\n",
      "0\n",
      "[(250, 288), (268, 286)]\n",
      "((142, 183),)\n",
      "\n",
      "['who played warren in orange is the new black']\n",
      "Uzoamaka Nwanneka `` Uzo '' Aduba\n",
      "1\n",
      "[(87, 231), (88, 94)]\n",
      "((87, 231), (88, 94))\n",
      "\n",
      "['who played tre in boyz in the hood']\n",
      "Cuba Gooding Jr.\n",
      "1\n",
      "[(1840, 2025), (1842, 1845)]\n",
      "((1840, 2025),)\n",
      "\n",
      "['who plays marka nichols on orange is the new black']\n",
      "She played the role of Margaret Craig McNamara in the HBO biographical film Path to War ( 2002 ) and appeared as Mel Gibson 's character 's wife in the science - fiction thriller , Signs that same year . She had guest roles on such television series as Touched by an Angel , Gossip Girl , The Good Wife , Blue Bloods , and Orange Is the New Black . Kalember played two different characters\n",
      "0\n",
      "[(546, 680)]\n",
      "((1205, 1736),)\n",
      "\n",
      "['where does progesterone come from in the body']\n",
      "ovaries\n",
      "0\n",
      "[(1587, 1677), (1660, 1661)]\n",
      "()\n",
      "\n",
      "['when was the last wolf killed in scotland']\n",
      "1743\n",
      "0\n",
      "[(1614, 1637), (1634, 1635)]\n",
      "((1404, 1499),)\n",
      "\n",
      "['when was last time england were in a world cup semi final']\n",
      "qualification\n",
      "0\n",
      "[(73, 185), (98, 99)]\n",
      "((7607, 8173), (8098, 8099))\n",
      "\n",
      "['what is the value of null in c']\n",
      "In C , two null pointers of any type are guaranteed to compare equal . The preprocessor macro NULL is defined as an implementation - defined null pointer constant , which in C99 can be portably expressed as the integer value 0 converted implicitly or explicitly to the type void * ( pointer to void ) . The C standard does not say that the null pointer is the same as the pointer to memory address 0 , though that may be the case in practice . Dereferencing a null pointer is undefined behavior in C , and a conforming implementation is allowed to assume that any pointer that is dereferenced is not null .\n",
      "1\n",
      "[(196, 313)]\n",
      "((196, 313),)\n",
      "\n",
      "['where did the bataan death march take place']\n",
      "Camp O'Donnell , Capas , Tarlac , via San Fernando , Pampanga\n",
      "1\n",
      "[(135, 336), (192, 204)]\n",
      "((135, 336), (182, 212))\n",
      "\n",
      "['who made up the first second and third estates']\n",
      "free peasants\n",
      "0\n",
      "[(2164, 2289), (2240, 2242)]\n",
      "()\n",
      "\n",
      "['vince carter career high points in a game']\n",
      "23.4\n",
      "0\n",
      "[(3541, 3601), (3583, 3584)]\n",
      "((6804, 6813), (6807, 6808))\n",
      "\n",
      "['where do they put the chip in dogs']\n",
      "below the skin at the back of the neck between the shoulder blades on the dorsal midline\n",
      "1\n",
      "[(1123, 1196), (1133, 1150)]\n",
      "((1123, 1196), (1131, 1150))\n",
      "\n",
      "['what is the meaning of spectacle in drama']\n",
      "an event that is memorable for the appearance it creates\n",
      "0\n",
      "[(73, 165), (80, 90)]\n",
      "()\n",
      "\n",
      "['what do you call the top of a column']\n",
      "capital\n",
      "1\n",
      "[(1315, 1431), (1324, 1325)]\n",
      "((1315, 1431),)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = albert_tokenization.FullTokenizer(\n",
    "    None, spm_model_file=FLAGS.verifier_vocab_file)\n",
    "\n",
    "if FLAGS.test_post_processing:\n",
    "    actual_answers = get_actual_answers(FLAGS.train_file, FLAGS.n_examples)\n",
    "    actual_has_answer = []\n",
    "example_ids = []\n",
    "features = {'input_ids': [],\n",
    "            'segment_ids': [],\n",
    "            'input_mask': []}\n",
    "for example in eval_examples:\n",
    "    example_id = example.example_id\n",
    "    answer = answers[example_id]\n",
    "    \n",
    "    doc_answer_range = answer['doc_tokens_span']\n",
    "    \n",
    "    if doc_answer_range:\n",
    "        answer_text = ' '.join(example.doc_tokens[doc_answer_range[0]:doc_answer_range[1]])\n",
    "        example.answer = Answer(None, text=answer_text, offset=None)\n",
    "        feature = example_to_verifier_feature(example, tokenizer,\n",
    "            FLAGS.verifier_max_seq_length, FLAGS.max_query_length)\n",
    "        for key in features.keys():\n",
    "            features[key].append(feature[key])\n",
    "        example_ids.append(example_id)\n",
    "        if FLAGS.test_post_processing:\n",
    "            actual_ranges = actual_answers[example_id]['long_answers'] + \\\n",
    "                            actual_answers[example_id]['short_answers']\n",
    "            actual_ranges = tuple(actual_ranges)\n",
    "            orig_ranges = []\n",
    "            orig_ranges.append(answer['long_answer'])\n",
    "            if answer['short_answer'] not in (None, 'YES', 'NO'):\n",
    "                orig_ranges.append(answer['short_answer'])\n",
    "                \n",
    "            correct_answer = 0\n",
    "            for orig_range in orig_ranges:\n",
    "                if orig_range in actual_ranges:\n",
    "                    correct_answer = 1\n",
    "                    break\n",
    "                    \n",
    "            print(example.questions)\n",
    "            print(example.answer.text)\n",
    "            print(correct_answer)\n",
    "            print(orig_ranges)\n",
    "            print(actual_ranges)\n",
    "            print()\n",
    "                    \n",
    "            actual_has_answer.append(correct_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Verifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"albert_verifier\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "albert_model (AlbertModel)      ((None, 4096), (None 222622336   input_ids[0][0]                  \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "valid_logits (TDense)           (None, 2)            8194        albert_model[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 222,630,530\n",
      "Trainable params: 222,630,530\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "verifier_model = build_model(model_name=FLAGS.verifier_model,\n",
    "                             config_file=FLAGS.verifier_config_file,\n",
    "                             max_seq_length=FLAGS.verifier_max_seq_length,\n",
    "                             init_ckpt=FLAGS.verifier_init_checkpoint)\n",
    "verifier_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Verifier Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifier Accuracy: 0.429\n"
     ]
    }
   ],
   "source": [
    "inputs = (features['input_ids'], features['input_mask'], features['segment_ids'])\n",
    "verifier_preds = verifier_model.predict(inputs, batch_size=FLAGS.verifier_batch_size)\n",
    "verifier_preds = softmax(verifier_preds, axis=1)\n",
    "valid_answers = []\n",
    "for pred in verifier_preds:\n",
    "    if pred[1] > 0.99:\n",
    "        valid_answers.append(0)\n",
    "    else:\n",
    "        valid_answers.append(1)\n",
    "valid_answers = np.array(valid_answers)\n",
    "\n",
    "if FLAGS.test_post_processing:\n",
    "    n_incorrect = sum(abs(actual_has_answer - valid_answers))\n",
    "    verifier_accuracy = 1 - (n_incorrect / len(valid_answers))\n",
    "    print('Verifier Accuracy: {:.3f}'.format(verifier_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4258064516129032\n",
      "0.9041095890410958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifier Accuracy: 0.411\n",
      "0.40714285714285714\n",
      "0.7808219178082192\n"
     ]
    }
   ],
   "source": [
    "valid_answers = []\n",
    "for pred in verifier_preds:\n",
    "    if pred[1] > 0.95:\n",
    "        valid_answers.append(0)\n",
    "    else:\n",
    "        valid_answers.append(1)\n",
    "valid_answers = np.array(valid_answers)\n",
    "\n",
    "if FLAGS.test_post_processing:\n",
    "    n_incorrect = sum(abs(actual_has_answer - valid_answers))\n",
    "    verifier_accuracy = 1 - (n_incorrect / len(valid_answers))\n",
    "    print('Verifier Accuracy: {:.3f}'.format(verifier_accuracy))\n",
    "    \n",
    "print(precision_score(actual_has_answer, valid_answers))\n",
    "print(recall_score(actual_has_answer, valid_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (0, 0),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1)]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(valid_answers, actual_has_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_id, valid in zip(example_ids, valid_answers):\n",
    "    if valid:\n",
    "        continue\n",
    "    \n",
    "    answers[example_id]['long_answer'] = None\n",
    "    answers[example_id]['short_answer'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Computing the Micro-F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_answers(file_path, n):\n",
    "    raw_generator = raw_data_generator(file_path, n)\n",
    "    raw_data = next(raw_generator)\n",
    "    \n",
    "    actual_answers = {}\n",
    "    for _, entry in raw_data.iterrows():\n",
    "        long_answer = entry['annotations'][0]['long_answer']\n",
    "        short_answers = entry['annotations'][0]['short_answers']\n",
    "        \n",
    "        la_spans = []\n",
    "        if long_answer['start_token'] != -1 and long_answer['end_token'] != -1:\n",
    "            la_spans = [(long_answer['start_token'], long_answer['end_token'])]\n",
    "        \n",
    "        sa_spans = []\n",
    "        for short_answer in short_answers:\n",
    "            sa_spans.append((short_answer['start_token'], short_answer['end_token']))\n",
    "            \n",
    "        if entry['annotations'][0]['yes_no_answer'] != 'NONE':\n",
    "            sa_spans.append(entry['annotations'][0]['yes_no_answer'])\n",
    "        \n",
    "        answer_entry = {\n",
    "            'long_answers': la_spans,\n",
    "            'short_answers': sa_spans\n",
    "        }\n",
    "        actual_answers[entry['example_id']] = answer_entry\n",
    "        \n",
    "    return actual_answers\n",
    "\n",
    "def score_preds(actual_answers, pred_answers):\n",
    "    if set(actual_answers.keys()) != set(answers.keys()):\n",
    "        raise ValueError('Actual answers and answers must contain the same example_id keys!')\n",
    "    \n",
    "    TP = 0 # True positives\n",
    "    FP = 0 # False positives\n",
    "    FN = 0 # False negatives\n",
    "    \n",
    "    FP_NA = 0 # False positives where there was no answer\n",
    "    FP_WA = 0 # False positives where an answer existed\n",
    "    for example_id in actual_answers.keys():\n",
    "        actual_las = actual_answers[example_id]['long_answers']\n",
    "        actual_sas = actual_answers[example_id]['short_answers']\n",
    "        \n",
    "        pred_la = pred_answers[example_id]['long_answer']\n",
    "        pred_sa = pred_answers[example_id]['short_answer']\n",
    "        \n",
    "        if pred_la in actual_las:\n",
    "            TP += 1\n",
    "        elif pred_la and pred_la not in actual_las:\n",
    "            FP += 1\n",
    "            if actual_las:\n",
    "                FP_WA += 1\n",
    "            else:\n",
    "                FP_NA += 1\n",
    "        elif not pred_la and actual_las:\n",
    "            FN += 1\n",
    "            \n",
    "        if pred_sa in actual_sas:\n",
    "            TP += 1\n",
    "        elif pred_sa and pred_sa not in actual_las:\n",
    "            FP += 1\n",
    "            if actual_sas:\n",
    "                FP_WA += 1\n",
    "            else:\n",
    "                FP_NA += 1\n",
    "        elif not pred_sa and actual_sas:\n",
    "            FN += 1\n",
    "\n",
    "    details = {\n",
    "        'TP': TP,\n",
    "        'FP': FP,\n",
    "        'FN': FN,\n",
    "        'FP_WA': FP_WA,\n",
    "        'FP_NA': FP_NA\n",
    "    }\n",
    "    \n",
    "    if TP == 0:\n",
    "        return 0, 0, 0, details\n",
    "    \n",
    "    recall = TP / (TP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    micro_f1 = 2 * precision * recall / (precision + recall)\n",
    "    return micro_f1, recall, precision, details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search to Select the Best Parameters for Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    default_range = np.arange(0, 1.05, 0.5)\n",
    "\n",
    "    weight_ranges = OrderedDict({\n",
    "            'ans_type_conf_weight': [0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "            'start_pos_conf_weight': [0, 0.25, 0.5, 0.75, 1.0],\n",
    "            'end_pos_conf_weight': [0, 0.25, 0.5, 0.75, 1.0],\n",
    "            'conf_bias': [-0.5, -0.25, 0, 0.25, 0.5],\n",
    "            'conf_threshold': [0.5]\n",
    "        })\n",
    "\n",
    "    combinations = list(itertools.product(*[weight_ranges[k] for k in weight_ranges.keys()]))\n",
    "\n",
    "    actual_answers = get_actual_answers(FLAGS.train_file, FLAGS.n_examples)\n",
    "\n",
    "    results = {}\n",
    "    for weight_vals in tqdm.tqdm(combinations):\n",
    "        weights = {}\n",
    "        for weight_name, weight_val in zip(weight_ranges.keys(), weight_vals):\n",
    "                weights[weight_name] = weight_val\n",
    "\n",
    "        tmp_answers = compute_answers(preds, candidates_dict, eval_features, weights)\n",
    "        micro_f1, recall, precision, _ = score_preds(actual_answers, tmp_answers)\n",
    "        results[weight_vals] = (micro_f1, recall, precision)\n",
    "        \n",
    "    sr = sorted(results.items(), key=lambda x: x[1][0], reverse=True)\n",
    "    print(sr[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5639686684073107,\n",
       " 0.8503937007874016,\n",
       " 0.421875,\n",
       " {'TP': 108, 'FP': 148, 'FN': 19, 'FP_WA': 65, 'FP_NA': 83})"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_answers = compute_answers(preds, candidates_dict, eval_features, eval_examples, {\n",
    "        'ans_type_conf_weight': 0.4,\n",
    "        'start_pos_conf_weight': 0.3,\n",
    "        'end_pos_conf_weight': 0.3,\n",
    "        'conf_bias': 0,\n",
    "        'conf_threshold': 0.98\n",
    "    })\n",
    "score_preds(actual_answers, tmp_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5584415584415585 0.41030534351145037 0.8739837398373984\n"
     ]
    }
   ],
   "source": [
    "TP, FP, FN = 215, 460 - int(189*.8), 31\n",
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "micro_f1 = 2 * precision * recall / (precision + recall)\n",
    "print(micro_f1, precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Micro-F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Joint Baseline\n",
    "    - F1: 0.564\n",
    "    - Recall: 0.850\n",
    "    - Precision: 0.422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.503896103896104\n",
      "Recall: 0.7886178861788617\n",
      "Precision: 0.3702290076335878\n",
      "{'TP': 97, 'FP': 165, 'FN': 26, 'FP_WA': 69, 'FP_NA': 96}\n"
     ]
    }
   ],
   "source": [
    "if FLAGS.test_post_processing:\n",
    "    actual_answers = get_actual_answers(FLAGS.train_file, FLAGS.n_examples)\n",
    "    micro_f1, recall, precision, details = score_preds(actual_answers, answers)\n",
    "\n",
    "    print(f'Micro F1 Score: {micro_f1}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Create a Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(answers):\n",
    "    submission_data = []\n",
    "\n",
    "    # Loop through answers in alphabetic order of example_ids\n",
    "    # This is how it's sorted in the sample submission\n",
    "    for example_id, answer in sorted(answers.items(), key=lambda x: x[0]):\n",
    "        long_answer_text = ''\n",
    "        if isinstance(answer['long_answer'], tuple):\n",
    "            long_answer_text = f'{answer[\"long_answer\"][0]}:{answer[\"long_answer\"][1]}'\n",
    "        else:\n",
    "            assert answer['long_answer'] is None, 'Invalid type of long answer!'\n",
    "            assert answer['short_answer'] is None, 'Cannot have a short answer with no long answer!'\n",
    "        long_answer_row = [f'{example_id}_long', long_answer_text]\n",
    "\n",
    "        short_answer_text = ''\n",
    "        if isinstance(answer['short_answer'], tuple):\n",
    "            short_answer_text = f'{answer[\"short_answer\"][0]}:{answer[\"short_answer\"][1]}'\n",
    "        elif answer['short_answer'] in ('YES', 'NO'):\n",
    "            short_answer_text = answer['short_answer']\n",
    "        else:\n",
    "            assert answer['short_answer'] is None, 'Invalid type of short answer!'\n",
    "        short_answer_row = [f'{example_id}_short', short_answer_text]\n",
    "\n",
    "        submission_data.append(long_answer_row)\n",
    "        submission_data.append(short_answer_row)\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_data, columns=['example_id', 'PredictionString'])\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Save the Submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   example_id PredictionString\n",
      "0   -9111510312671706854_long        2000:2187\n",
      "1  -9111510312671706854_short        2087:2095\n",
      "2   -9100123296297706673_long          519:620\n",
      "3  -9100123296297706673_short          598:601\n",
      "4   -9070556881023521969_long        2882:3126\n"
     ]
    }
   ],
   "source": [
    "if not FLAGS.test_post_processing:\n",
    "    submission_df = create_submission(answers)\n",
    "    print(submission_df.head())\n",
    "    submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
